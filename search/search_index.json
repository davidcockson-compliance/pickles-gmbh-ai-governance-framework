{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Pickles GmbH \u2014 AI Governance Framework","text":"<p>An open-source AI governance framework for German legal AI providers, covering EU AI Act, GDPR, BDSG, and BRAK professional standards.</p> <p>Full documentation: Documentation site</p> <p>This framework exists because there weren't clear worked examples of what EU AI Act compliance documentation looks like in practice for a legal AI company. Rather than write documents manually, I designed a multi-agent system to produce them \u2014 with regulatory research, assumption tracking, and quality controls built into the generation process.</p> <p>The result is 22 documents across five stages, a worked example showing a fictional contract review tool walked through the complete framework, and a reusable methodology that other organisations can adapt.</p> <p>Licence: CC BY 4.0 \u2014 use and adapt freely, attribution required. Status: Framework proposal. Not a legal compliance certification. Legal review: Required before operational use.</p>"},{"location":"#contents","title":"Contents","text":"Stage First document Count 1 \u2014 Regulatory Orientation Regulatory Orientation Note 1 2 \u2014 Governance Foundation AI System Inventory 4 3 \u2014 Regulatory Alignment EU AI Act Risk Mapping 6 4 \u2014 Monitoring &amp; Controls AI Monitoring Framework 3 5 \u2014 Commercial Packaging Governance Information Pack 2 Worked Example (Phase 2) System Profile \u2014 Vertrag.AI 6 <p>See <code>ASSUMPTIONS-LOG.md</code> for all unverified assumptions embedded in the framework. See <code>DISCLAIMER.md</code> for full scope and limitations notice.</p>"},{"location":"#framework-architecture","title":"Framework Architecture","text":"<p>The framework is organised across four governance layers:</p> Layer Coverage AI System Foundation System inventory, risk classification, intake workflow, human oversight policy EU AI Act &amp; Regulatory Alignment Risk mapping, technical documentation, transparency, GDPR/DPIA, vendor risk Monitoring &amp; Operational Controls Monitoring framework, incident response, model change management Client-Facing Assurance Governance information pack, enterprise sales enablement"},{"location":"#stage-dependency-map","title":"Stage dependency map","text":"<pre><code>Stage 0 \u2500\u2500\u25b6 Stage 1 \u2500\u2500\u25b6 Stage 2 \u2500\u2500\u25b6 Stage 3 \u2500\u2500\u25b6 Stage 4 \u2500\u2500\u25b6 Phase 2\n Setup       Reg.         Gov.         Reg.              \u2502    Worked\n             Orient.      Found.       Align.            \u2502    Example\n                                                    Stage 5\n                                               (parallel with 4)\n</code></pre>"},{"location":"#worked-example-vertragai","title":"Worked Example \u2014 Vertrag.AI","text":"<p>Phase 2 takes a fictional contract review tool, Vertrag.AI, through the complete framework end to end. Every key template is populated with realistic content, and the risk classification reasoning is made explicit at each decision gate.</p> <p>The worked example demonstrates: - How the risk classification decision tree produces traceable, defensible outputs - Why the EU Act classification (limited risk) and the internal classification (Medium-High) diverge, and why that gap matters - What the human oversight gate looks like in a professional-liability context - How the monitoring framework handles legally privileged material</p> <p>See the System Profile and the Reflection Note for the full worked example and a first-person account of what the exercise revealed about the framework's design.</p>"},{"location":"#methodology","title":"Methodology","text":"<p>The framework was produced by a multi-agent Claude Code system with five defined agent roles: Orchestrator, Research Reader, Document Drafter, Assumptions Tracker, and Run Summariser. The system runs autonomously from regulatory source documents placed in an input folder, producing audit-ready Markdown documentation with explicit assumption flagging throughout.</p> <p>The documents are the output. The system design is the methodology.</p> <p>The next stage is testing whether this approach transfers to a different jurisdiction and regulatory architecture.</p> <p>Estimated build cost for Phase 1 (16 documents): $4\u201310 USD using Claude Sonnet with prompt caching.</p>"},{"location":"#regulatory-coverage","title":"Regulatory Coverage","text":"Regulation Coverage EU AI Act (Regulation (EU) 2024/1689) Risk classification, Article 52 transparency obligations, Annex III mapping, Article 11 technical documentation structure GDPR (Regulation (EU) 2016/679) Data flow mapping, DPIA, sub-processor obligations, data subject rights BDSG (Bundesdatenschutzgesetz) German national data protection overlay BRAK professional standards Lawyer obligations when using AI tools, client confidentiality"},{"location":"#using-this-framework","title":"Using This Framework","text":"<p>This framework is designed to be adapted, not copied verbatim. Before operational use:</p> <ol> <li>Replace all fictional Pickles GmbH / Vertrag.AI content with your actual system data</li> <li>Resolve all <code>[ASSUMPTION]</code> flags against real company information</li> <li>Have the framework reviewed by a qualified lawyer in your jurisdiction</li> <li>Update regulatory references if the EU AI Act or related guidance has been updated since this was produced</li> </ol> <p>The <code>ASSUMPTIONS-LOG.md</code> lists every unverified assumption across the framework. Start there.</p>"},{"location":"#licence","title":"Licence","text":"<p>CC BY 4.0 \u2014 you are free to use, adapt, and distribute this framework, including commercially, provided you give appropriate credit.</p>"},{"location":"#author","title":"Author","text":"<p>Built by David Cockson \u2014 compliance and governance professional with a background in financial services and igaming RegTech.</p> <p>Pickles GmbH does not exist. All company characteristics, systems, and scenarios in this framework are fictional and produced for educational and demonstration purposes only.</p>"},{"location":"ASSUMPTIONS-LOG/","title":"Assumptions Log","text":"<p>Project: Pickles GmbH \u2014 AI Governance Framework Version: v1 Date: 2026-02-28</p>"},{"location":"ASSUMPTIONS-LOG/#about-this-document","title":"About This Document","text":"<p>This framework was built using a fictional company \u2014 Pickles GmbH \u2014 as the demonstration vehicle. Because no real company data was available during the build, every claim about Pickles GmbH's systems, operations, or characteristics is an assumption, not a verified fact.</p> <p>This log records all of those assumptions in one place. Every document in the framework also flags its own assumptions inline using the marker <code>[ASSUMPTION]</code>.</p> <p>If you are adapting this framework for a real organisation: this log is your starting point. Work through every assumption listed here and validate each one against your actual company data before treating any framework document as complete.</p>"},{"location":"ASSUMPTIONS-LOG/#status-key","title":"Status Key","text":"Status Meaning \ud83d\udd34 Unverified Not confirmed against real data \u2014 placeholder only \ud83d\udfe1 Partial Partially confirmed \u2014 still needs full verification \ud83d\udfe2 Confirmed Verified against real company data"},{"location":"ASSUMPTIONS-LOG/#company-profile-assumptions","title":"Company Profile Assumptions","text":"# Assumption Source Document Status A-001 The company provides legal AI tools covering drafting, research, summarisation, and analysis Framework outline \ud83d\udd34 Unverified A-002 Clients are German legal professionals or in-house legal departments Framework outline \ud83d\udd34 Unverified A-003 The company operates under the EU AI Act, GDPR, and German professional confidentiality standards (BRAK) Framework outline \ud83d\udd34 Unverified A-004 Third-party AI model providers may be in use Framework outline \ud83d\udd34 Unverified A-005 Hosting location is EU-based Framework outline \ud83d\udd34 Unverified"},{"location":"ASSUMPTIONS-LOG/#system-level-assumptions-phase-2-vertragai","title":"System-Level Assumptions (Phase 2 \u2014 Vertrag.AI)","text":"<p>These assumptions relate to the fictional Vertrag.AI system used in the Phase 2 worked example.</p> # Assumption Source Document Status A-006 EU hosting confirmed; specific cloud provider not named P2-Worked-Example-System-Profile-v1.md \ud83d\udd34 Unverified A-007 Anthropic DPA in place; prompts not used for model training P2-Worked-Example-System-Profile-v1.md \ud83d\udd34 Unverified A-008 No fine-tuning applied to base model P2-Worked-Example-System-Profile-v1.md \ud83d\udd34 Unverified A-009 RAG corpus quarterly review cycle P2-Worked-Example-System-Profile-v1.md \ud83d\udd34 Unverified A-010 Output labelling and UI disclaimer behaviour as described P2-Worked-Example-System-Profile-v1.md \ud83d\udd34 Unverified A-011 Audit trail logging per session P2-Worked-Example-System-Profile-v1.md \ud83d\udd34 Unverified A-012 EU AI Act classification confirmed as limited risk P2-Worked-Example-System-Profile-v1.md \ud83d\udd34 Unverified \u2014 requires qualified lawyer review A-013 BRAK obligations assessed and addressed in product design P2-Worked-Example-System-Profile-v1.md \ud83d\udd34 Unverified"},{"location":"ASSUMPTIONS-LOG/#how-to-resolve-assumptions","title":"How to Resolve Assumptions","text":"<p>For each assumption, the validation process requires:</p> <ol> <li>Identifying the relevant data source (CTO, Head of Engineering, Legal Counsel, etc.)</li> <li>Obtaining written confirmation of the actual position</li> <li>Updating the relevant framework document to replace the assumed value with the confirmed value</li> <li>Removing the <code>[ASSUMPTION]</code> flag from that field</li> <li>Updating this log with status \ud83d\udfe2 Confirmed and the date confirmed</li> </ol> <p>Some assumptions (particularly A-012 regarding EU AI Act risk classification) require review by a qualified lawyer, not just internal verification.</p>"},{"location":"ASSUMPTIONS-LOG/#resolved-assumptions","title":"Resolved Assumptions","text":"<p>None \u2014 this framework was built entirely on fictional company data. All assumptions remain unverified. Confirm against real company data before operational use.</p> <p>Last updated: 2026-02-28. This log should be maintained and updated whenever the framework is adapted for a real organisation.</p>"},{"location":"DISCLAIMER/","title":"Disclaimer","text":"<p>Project: Pickles GmbH \u2014 AI Governance Framework Version: v1 Date: 2026-02-28</p>"},{"location":"DISCLAIMER/#this-framework-is-not-legal-advice","title":"This Framework Is Not Legal Advice","text":"<p>The Pickles GmbH AI Governance Framework is an educational and demonstration resource. It does not constitute legal advice, regulatory guidance, or a compliance certification of any kind.</p> <p>Nothing in this framework should be relied upon as a substitute for advice from a qualified lawyer with expertise in EU AI Act, GDPR, German data protection law, or the professional conduct rules applicable to your organisation.</p>"},{"location":"DISCLAIMER/#pickles-gmbh-does-not-exist","title":"Pickles GmbH Does Not Exist","text":"<p>Pickles GmbH is a fictional company created for the purpose of demonstrating how an AI governance framework might be structured for a German legal AI provider. All company characteristics, system descriptions, personnel references, and scenarios in this framework are entirely fictional.</p> <p>Vertrag.AI, referenced in the Phase 2 worked example, is also fictional. No actual contract review tool, AI system, or legal AI product is described or implied.</p>"},{"location":"DISCLAIMER/#this-is-a-framework-proposal-not-a-compliance-certification","title":"This Is a Framework Proposal, Not a Compliance Certification","text":"<p>This framework represents one approach to structuring AI governance documentation under the EU AI Act, GDPR, BDSG, and BRAK professional standards. It has not been:</p> <ul> <li>Reviewed or approved by any regulatory authority</li> <li>Reviewed by a qualified German lawyer</li> <li>Tested against any real company's actual systems or data</li> <li>Certified as meeting any specific compliance standard</li> </ul> <p>Compliance with the EU AI Act, GDPR, or any other regulation requires assessment of your specific systems, operations, and context by qualified professionals. This framework cannot and does not make that assessment for you.</p>"},{"location":"DISCLAIMER/#regulatory-references","title":"Regulatory References","text":"<p>Regulatory references in this framework (EU AI Act articles, GDPR provisions, BDSG sections, BRAK guidelines) were made in good faith based on source documents available at the time of drafting. They do not constitute authoritative legal interpretation.</p> <p>The EU AI Act and related guidance are subject to ongoing development. Provisions, timelines, and obligations may have changed since this framework was produced. Always verify regulatory content against current official sources before relying on it.</p>"},{"location":"DISCLAIMER/#assumptions","title":"Assumptions","text":"<p>This framework was built on a set of unverified assumptions about the fictional Pickles GmbH company. Every document flags these assumptions using the marker <code>[ASSUMPTION]</code>. A complete list is maintained in <code>ASSUMPTIONS-LOG.md</code>.</p> <p>Before this framework is adapted for operational use by a real organisation, every assumption must be validated against actual company data, systems, and practices.</p>"},{"location":"DISCLAIMER/#limitation-of-liability","title":"Limitation of Liability","text":"<p>The author of this framework accepts no liability for any loss, damage, regulatory action, or other consequence arising from the use, adaptation, or reliance on any part of this framework.</p>"},{"location":"DISCLAIMER/#licence","title":"Licence","text":"<p>This framework is published under CC BY 4.0. You are free to use and adapt it, but you do so at your own risk and responsibility. Attribution is required.</p> <p>If you are considering using this framework operationally, please engage a qualified lawyer before doing so.</p>"},{"location":"phase-2-worked-example/P2-Reflection-Note-v1/","title":"P2 Reflection Note \u2014 What the Worked Example Revealed","text":"<p>Project: Pickles GmbH \u2014 AI Governance Framework Stage: Phase 2 \u2014 Worked Example Document: P2-Reflection-Note-v1.md Status: Draft Version: v1 Date: 2026-02-28 Assumptions: This document reflects on the Phase 2 worked example process. It is written in first person as a genuine methodological reflection.</p>"},{"location":"phase-2-worked-example/P2-Reflection-Note-v1/#purpose","title":"Purpose","text":"<p>This note records what the Phase 2 worked example exercise revealed about the Pickles GmbH governance framework \u2014 what held up under realistic content, what needed adjustment, what the exercise surfaced that templates alone would not, and what would change if Vertrag.AI were a real system rather than a fictional one.</p> <p>It is intended for two audiences: reviewers of this framework who want to understand how it performs under pressure, and practitioners considering adapting the framework for their own use.</p>"},{"location":"phase-2-worked-example/P2-Reflection-Note-v1/#what-the-exercise-was-testing","title":"What the Exercise Was Testing","text":"<p>Phase 1 produced 16 governance documents: inventory templates, risk classification criteria, regulatory mapping matrices, a DPIA framework, vendor risk assessment, monitoring framework, incident playbook, and commercial packaging. Every document was built on assumed characteristics of a fictional legal AI company.</p> <p>The risk with any template-first approach is that it produces documents that look complete but haven't been stress-tested against real-feeling content. A risk classification framework is easy to write; applying it to a specific system, with explicit reasoning at every step, is where the gaps show.</p> <p>Phase 2 asked: does this framework actually work when you put a realistic system through it?</p>"},{"location":"phase-2-worked-example/P2-Reflection-Note-v1/#what-held-up-well","title":"What Held Up Well","text":"<p>The decision tree structure for risk classification worked. Walking Vertrag.AI through five sequential gates \u2014 prohibited practices, Annex III, GPAI, Article 52, internal criteria \u2014 produced a traceable, defensible result. The value wasn't just arriving at \"limited risk.\" It was the documented reasoning that shows why the system doesn't fall into Annex III, which categories were seriously considered, and what design features keep it on the right side of the line. That reasoning is what a regulator or enterprise client would actually want to see.</p> <p>The distinction between EU Act classification and internal classification proved its worth. Vertrag.AI came out as limited risk under the EU AI Act but Medium-High on the internal scale. This gap exists because the framework is deliberately more conservative than the regulatory minimum \u2014 and that conservatism is defensible and appropriate for a professional-context legal tool. Having two separate classification outputs, rather than collapsing them into one, gives the framework more useful precision.</p> <p>The human oversight gate proved to be load-bearing across multiple documents. It appeared in the risk classification (as the factor that keeps the system out of high-risk), in the technical documentation (as a hard architectural requirement, not just a policy), in the EU AI Act mapping (as the primary control mitigating Article 52(3) uncertainty), and in the monitoring design (as the source of the acceptance rate metric). This cross-document coherence suggests the framework's architecture is structurally sound \u2014 the oversight requirement isn't just stated once and forgotten, it propagates correctly.</p> <p>The assumptions discipline held. Every document flagged assumptions consistently, and the assumptions accumulated into a coherent picture of what a real company would need to do before treating any of this as operational. That's the right outcome for an open-source educational resource \u2014 the framework is useful precisely because it's honest about what it doesn't know.</p>"},{"location":"phase-2-worked-example/P2-Reflection-Note-v1/#what-the-exercise-surfaced-that-templates-alone-did-not","title":"What the Exercise Surfaced That Templates Alone Did Not","text":"<p>The GDPR/confidentiality monitoring constraint is a real design problem, not a footnote. When I reached the monitoring entry, it became clear that standard LLM monitoring approaches \u2014 logging prompt/completion pairs, reviewing output samples freely \u2014 are structurally unavailable in the legal market context. You cannot retain full contract text in monitoring logs without violating GDPR and legal professional privilege simultaneously. The monitoring document had to be redesigned around metadata-only logging, outcome proxies, and consented sampling. This constraint wasn't visible in the Phase 1 monitoring framework template, which was written at a level of abstraction that didn't surface it. A practitioner adapting this framework for a real legal AI company would hit this constraint immediately \u2014 and the worked example now flags it explicitly.</p> <p>The Anthropic sub-processor relationship cascades further than expected. By the time I reached the technical documentation and monitoring entry, the Anthropic DPA gap \u2014 identified as a single compliance item in the EU AI Act mapping \u2014 had become a dependency for: the GDPR legal basis analysis, the data flow description, the log retention design, the client-facing DPA structure, and the monitoring consent framework. A single unresolved vendor relationship creates a thread that runs through almost every downstream document. The worked example makes this visible in a way that the template couldn't.</p> <p>Article 52(4) \u2014 machine-readable labelling of AI-generated text \u2014 is genuinely unclear for document-based output. The EU AI Act mapping flagged this as a gap (GAP-001), and it remained open throughout the exercise. Article 52(4) requires machine-readable labelling of AI-generated content, but the practical form of that obligation for a tool that produces a DOCX file is not settled. This is a live regulatory uncertainty, not a drafting gap in the framework. Identifying it is more valuable than pretending it's resolved.</p> <p>The RAG corpus is a governance object in its own right. The Phase 1 framework treats the knowledge base as a component of the system. The worked example revealed that it needs to be treated as a governed asset with its own version control, curation policy, update cadence, and quality monitoring. A knowledge base that drifts \u2014 through outdated legal sources or inconsistent curation \u2014 can degrade output quality systematically and silently, in a way that the acceptance rate metric alone might not catch quickly. This deserved more emphasis in Phase 1's technical documentation template than it received.</p>"},{"location":"phase-2-worked-example/P2-Reflection-Note-v1/#what-would-change-with-real-company-data","title":"What Would Change With Real Company Data","text":"<p>The most significant changes when moving from fictional to real would fall into four areas.</p> <p>Architecture verification. The entire technical documentation is built on an assumed RAG + Claude API architecture derived from Anthropic's legal productivity GitHub examples. A real implementation might differ materially \u2014 different chunking strategy, different retrieval approach, a different model, fine-tuning that fundamentally changes the training data section. The framework documents the right questions; real system data provides the answers.</p> <p>Baseline establishment. The monitoring framework cannot be operationalised until production data exists. The suggestion acceptance rate target (\u226560%) is a reasonable starting hypothesis, but it needs 90 days of real usage to validate. Some metrics \u2014 particularly the sampled quality review \u2014 cannot even begin until a consent model is in place with real law firm clients. Phase 2 establishes the monitoring architecture; live operation establishes the baselines.</p> <p>Regulatory classification confirmation. The Annex III analysis for Categories 5 and 8 involves interpretive judgment that needs review by a qualified EU AI Act lawyer. The reasoning in the risk classification document is defensible, but \"defensible\" and \"confirmed\" are not the same thing. A real company would need external legal sign-off on this before relying on the limited-risk classification operationally.</p> <p>Vendor relationships. The Anthropic DPA, the sub-processor disclosure in client contracts, and the GPAI compliance documentation request are all unresolved because they require real commercial engagement with Anthropic. In a real deployment, these would be among the first actions taken \u2014 they gate several other compliance activities.</p>"},{"location":"phase-2-worked-example/P2-Reflection-Note-v1/#what-this-means-for-practitioners-adapting-the-framework","title":"What This Means for Practitioners Adapting the Framework","text":"<p>If you are using this framework as a starting point for a real legal AI product, the Phase 2 worked example suggests four prioritisation decisions:</p> <p>First, resolve the model provider relationship before anything else. The DPA, data residency confirmation, and sub-processor disclosure structure underpin a large proportion of the GDPR and EU AI Act compliance work. Nothing downstream is fully settled until this is in place.</p> <p>Second, treat the human oversight gate as an architectural requirement, not a policy statement. The worked example shows how much load it carries across the regulatory framework. If your product roadmap ever contemplates reducing or removing mandatory review, re-run the entire risk classification \u2014 you may be moving into a high-risk AI system category.</p> <p>Third, design your monitoring framework around the confidentiality constraint from the start. Do not assume you can monitor output quality the same way you would for a general-purpose LLM product. The legal market's confidentiality requirements reshape what data you can retain and how you can use it. Build the consent and confidentiality framework for sampled review early, because without it your quality monitoring has a significant blind spot.</p> <p>Fourth, get legal sign-off on the Annex III classification before you publish any compliance claims. The reasoning in this framework is educational; it is not a legal opinion.</p>"},{"location":"phase-2-worked-example/P2-Reflection-Note-v1/#a-note-on-the-framework-as-methodology","title":"A Note on the Framework as Methodology","text":"<p>The worked example validated the framework's core purpose: that it is most valuable as an embedded governance process, not as a standalone compliance exercise. Each document generated findings that shaped subsequent documents. The risk classification informed the EU AI Act mapping. The mapping identified gaps that surfaced in the technical documentation. The technical documentation's logging constraints reshaped the monitoring design. The monitoring gaps fed back into open items that a real company would need to resolve before go-live.</p> <p>This is what governance documentation should do \u2014 create a coherent, interdependent record that forces each compliance question to be answered in relation to the others. Template collections that live in a folder don't do this. A worked example that runs a real system through the framework end to end does.</p> <p>That is the methodological claim this project is making, and the worked example supports it.</p> <p>This reflection note is part of the Pickles GmbH AI Governance Framework \u2014 a fictional demonstration case. All observations are based on the process of building and applying the framework, not on operational experience with a real AI product.</p>"},{"location":"phase-2-worked-example/P2-Worked-Example-EU-AI-Act-Mapping-v1/","title":"P2 Worked Example \u2014 EU AI Act Mapping: Vertrag.AI","text":"<p>Project: Pickles GmbH \u2014 AI Governance Framework Stage: Phase 2 \u2014 Worked Example Document: P2-Worked-Example-EU-AI-Act-Mapping-v1.md Status: Draft Version: v1 Date: 2026-02-28 Assumptions: Built on Phase 2 fictional system design \u2014 Vertrag.AI does not exist. All regulatory analysis is illustrative. Not verified against real company data or reviewed by a qualified lawyer.</p>"},{"location":"phase-2-worked-example/P2-Worked-Example-EU-AI-Act-Mapping-v1/#about-this-document","title":"About This Document","text":"<p>This document maps Vertrag.AI against the applicable provisions of Regulation (EU) 2024/1689 (the EU AI Act). It draws on the classification established in P2-Worked-Example-Risk-Classification-v1.md and populates the mapping matrix format defined in L2-4.1-EU-AI-Act-Risk-Mapping-Matrix-v1.md with specific content for this system.</p> <p>The document is structured in three parts:</p> <ol> <li>Applicable provisions matrix \u2014 articles that apply to Vertrag.AI, with obligations and current status</li> <li>Non-applicable provisions \u2014 Annex III and other provisions assessed and confirmed as not applicable, with reasoning</li> <li>Compliance gap analysis \u2014 obligations not yet fully addressed and actions required</li> </ol> <p>All article references are to Regulation (EU) 2024/1689 as published in the Official Journal of the European Union (OJ L, 2024/1689, 12.7.2024).</p>"},{"location":"phase-2-worked-example/P2-Worked-Example-EU-AI-Act-Mapping-v1/#1-system-and-classification-reference","title":"1. System and Classification Reference","text":"Field Entry System Vertrag.AI System ID PKL-SYS-003 EU AI Act classification Limited risk (Article 52 transparency obligations) Pickles GmbH internal tier Medium-High Pickles GmbH role Deployer (Article 3(4)) Anthropic role Provider of underlying GPAI model (Claude API) Classification source document P2-Worked-Example-Risk-Classification-v1.md Legal review required Yes \u2014 before classification and obligations are treated as final"},{"location":"phase-2-worked-example/P2-Worked-Example-EU-AI-Act-Mapping-v1/#2-applicable-provisions-matrix","title":"2. Applicable Provisions Matrix","text":""},{"location":"phase-2-worked-example/P2-Worked-Example-EU-AI-Act-Mapping-v1/#21-general-provisions","title":"2.1 General Provisions","text":"Article Title / Subject Obligation for Pickles GmbH Status Notes Article 3(4) Definition \u2014 deployer Pickles GmbH is a deployer: a natural or legal person that uses an AI system under its authority Confirmed Anthropic is the provider of the Claude model; Pickles GmbH deploys it within Vertrag.AI Article 3(8) Definition \u2014 intended purpose System must be operated within its intended purpose as defined by Pickles GmbH Confirmed Intended purpose documented in system profile (P2-Worked-Example-System-Profile-v1.md) Article 4 AI literacy Deployers must ensure staff working with AI systems have sufficient AI literacy Partially addressed [ASSUMPTION] Training programme not yet confirmed; flag for HR/product team"},{"location":"phase-2-worked-example/P2-Worked-Example-EU-AI-Act-Mapping-v1/#22-transparency-obligations-article-52","title":"2.2 Transparency Obligations (Article 52)","text":"<p>This is the primary regulatory article applicable to Vertrag.AI at its current risk classification.</p> Sub-article Obligation How Addressed by Vertrag.AI Status Gap / Action Article 52(1) Where an AI system interacts directly with natural persons, those persons must be informed they are interacting with an AI system Vertrag.AI interacts with qualified lawyers as professional users, not with natural persons who might believe they are speaking with a human. Chatbot disclosure obligation does not apply in the standard use case. Not applicable to standard use case Monitor: if a client-facing chat or advisory interface is added to the product, Article 52(1) would apply Article 52(2) Operators of emotion recognition or biometric categorisation systems must inform natural persons Vertrag.AI does not perform emotion recognition or biometric categorisation Not applicable N/A Article 52(3) Persons deploying AI that generates synthetic content must disclose that content is AI-generated, except where the content has undergone human review and been significantly modified by a natural person AI-generated clause suggestions in the redlined DOCX output are labelled as AI-drafted. Lawyer review and acceptance/rejection of each suggestion is required before use. Partially addressed Gap: The product design includes labelling, but the precise form of Article 52(3) disclosure \u2014 and whether the mandatory lawyer review constitutes \"significant modification\" \u2014 requires legal review. Disclosure language in product UI should be reviewed against Article 52(3) requirements. Article 52(4) Providers and deployers of AI systems generating synthetic audio, image, video, or text content must label the output in a machine-readable format Vertrag.AI produces text output (redlined DOCX). Machine-readable labelling of AI-generated text content may be required. Gap \u2014 not yet addressed Action: Assess whether machine-readable labelling is technically feasible in DOCX output format. Legal review required on scope of Article 52(4) for document-based AI output."},{"location":"phase-2-worked-example/P2-Worked-Example-EU-AI-Act-Mapping-v1/#23-deployer-obligations-article-16-applied-proportionately","title":"2.3 Deployer Obligations (Article 16 applied proportionately)","text":"<p>Article 16 sets out obligations for providers of high-risk AI systems. Where Vertrag.AI is classified as limited risk, these obligations do not apply in full. However, several represent good governance practice that Pickles GmbH applies as deployer at the Medium-High internal tier.</p> Obligation Article 16 Reference Applicability to Vertrag.AI Approach Taken Technical documentation Article 16(b), Article 11 Mandatory for high-risk only; applied voluntarily at Medium-High internal tier Full technical documentation produced \u2014 see P2-Worked-Example-Technical-Documentation-v1.md Logging and traceability Article 16(c), Article 12 Mandatory for high-risk only; applied voluntarily Session-level audit logging implemented [ASSUMPTION] Transparency to deployers Article 16(d), Article 13 Not applicable (Pickles GmbH is deployer, not a downstream deployer) N/A Human oversight measures Article 16(f), Article 14 Mandatory for high-risk only; applied as core product design principle Mandatory lawyer review gate; see Human Oversight Policy (L1-3.4) Accuracy, robustness, cybersecurity Article 16(g), Article 15 Mandatory for high-risk only; applied as operational standard Addressed in monitoring framework and model change management protocol"},{"location":"phase-2-worked-example/P2-Worked-Example-EU-AI-Act-Mapping-v1/#24-obligations-applicable-to-deployers-generally-article-26","title":"2.4 Obligations Applicable to Deployers Generally (Article 26)","text":"<p>Article 26 sets out obligations specifically for deployers of AI systems (as distinct from providers). These apply to Pickles GmbH regardless of risk tier.</p> Article 26 Sub-provision Obligation Status Notes Article 26(1) Deployers must use AI systems in accordance with the instructions for use provided by the provider Partially addressed [ASSUMPTION] Anthropic's API terms of service and usage policies govern permitted use of the Claude model. Pickles GmbH must ensure Vertrag.AI's use case is within permitted scope. Flag for Legal Counsel to confirm. Article 26(2) Deployers must assign human oversight to a natural person with the competence, training and authority to oversee the AI system Partially addressed System owner role assigned (Head of Product). Competence and training requirements not yet formally documented. Article 26(3) Deployers must ensure input data is relevant and sufficiently representative Partially addressed Contract documents uploaded by law firm users constitute the input data. Pickles GmbH does not control input quality directly; guidance to users on appropriate use is required. Article 26(4) Where the deployer is aware the AI system presents risk, they must notify the provider Not yet formally addressed Incident response pathway to Anthropic not yet documented. Flag for Incident Response Playbook (L3-6.2). Article 26(5) Deployers of high-risk AI systems must conduct a fundamental rights impact assessment before deployment Not applicable at current classification Would apply if classification is revised to high-risk. Article 26(6) Deployers must keep logs for the period specified by the provider, minimum 6 months Partially addressed [ASSUMPTION] Log retention period not confirmed. Flag for CTO to confirm retention policy against this requirement. Article 26(7) Deployers that are public authorities must register in the EU database Not applicable Pickles GmbH is a private company"},{"location":"phase-2-worked-example/P2-Worked-Example-EU-AI-Act-Mapping-v1/#25-gpai-model-downstream-deployer-considerations-articles-5155","title":"2.5 GPAI Model \u2014 Downstream Deployer Considerations (Articles 51\u201355)","text":"<p>Vertrag.AI deploys the Claude API, which is a General Purpose AI (GPAI) model provided by Anthropic. Anthropic holds GPAI provider obligations. Pickles GmbH's obligations as a downstream deployer of a GPAI model are addressed below.</p> Obligation Area Article Reference Assessment GPAI provider obligations Articles 53\u201354 Held by Anthropic, not Pickles GmbH. Pickles GmbH should obtain and retain a copy of Anthropic's GPAI model compliance documentation (summary or transparency report) as evidence that the upstream provider obligations are being met. Downstream deployer \u2014 using GPAI for specific purpose Article 28(2) Where a deployer uses a GPAI model for a specific purpose (here: contract review), and makes the system available to downstream users (law firms), the deployer takes on obligations proportionate to the specific use case. Pickles GmbH's Article 52 and Article 26 obligations are the primary expression of this. GPAI systemic risk Article 55 Applies to GPAI models with systemic risk (above the compute threshold). Pickles GmbH should confirm with Anthropic whether the deployed Claude model version is designated as a systemic risk model, and what (if any) downstream obligations this creates. [Flag for Legal Counsel / Anthropic account review.]"},{"location":"phase-2-worked-example/P2-Worked-Example-EU-AI-Act-Mapping-v1/#3-non-applicable-provisions-confirmed-and-reasoned","title":"3. Non-Applicable Provisions \u2014 Confirmed and Reasoned","text":"<p>These provisions were assessed in the risk classification walkthrough (P2-Worked-Example-Risk-Classification-v1.md) and confirmed as not applicable to Vertrag.AI at its current design and deployment context.</p> Provision Reason Not Applicable Article 5 \u2014 Prohibited AI practices Vertrag.AI does not employ subliminal manipulation, biometric surveillance, social scoring, or any other prohibited practice Chapter III Section 2 \u2014 High-risk AI system obligations (Articles 8\u201315) Vertrag.AI is classified as limited risk; Annex III high-risk categories do not apply in the current design Article 49 \u2014 CE marking CE marking applies to high-risk AI systems only Article 50 \u2014 Registration in EU database (provider) Registration applies to providers of high-risk systems and certain GPAI models; Pickles GmbH is a deployer at limited risk Article 26(5) \u2014 Fundamental rights impact assessment Applies to deployers of high-risk AI systems only <p>Conditional note: If a product change increases automation level, or if legal review concludes that Annex III Category 5 or 8 applies, Vertrag.AI would become a high-risk AI system. At that point, all Chapter III Section 2 obligations would apply, including: conformity assessment (Article 43), technical documentation to Annex IV standard (Article 11), EU database registration (Article 49), and fundamental rights impact assessment (Article 26(5)). This document would require a full revision.</p>"},{"location":"phase-2-worked-example/P2-Worked-Example-EU-AI-Act-Mapping-v1/#4-compliance-gap-analysis","title":"4. Compliance Gap Analysis","text":"<p>Summary of gaps identified in Section 2, with priority and ownership.</p> # Gap Article Priority Owner Action GAP-001 Machine-readable labelling of AI-generated text output not yet addressed Article 52(4) High Head of Engineering / Head of Product Assess technical feasibility in DOCX output; obtain legal view on scope of obligation GAP-002 Article 52(3) disclosure form not legally reviewed Article 52(3) High Legal Counsel Review current product UI labelling against Article 52(3) requirements; confirm whether mandatory lawyer review constitutes \"significant modification\" GAP-003 AI literacy training programme not confirmed Article 4 Medium Head of Product / HR Document and deliver AI literacy training for all staff interacting with Vertrag.AI; record completion GAP-004 Incident notification pathway to Anthropic not documented Article 26(4) Medium Legal Counsel / Head of Engineering Add Anthropic notification pathway to Incident Response Playbook (L3-6.2) GAP-005 Log retention period not confirmed against 6-month minimum Article 26(6) Medium CTO / Head of Engineering Confirm retention policy; update infrastructure documentation GAP-006 Human oversight competence and training requirements not formally documented Article 26(2) Medium Head of Product Document competence requirements for the system owner role; link to training records GAP-007 Anthropic GPAI compliance documentation not yet obtained Articles 51\u201355 Low Legal Counsel Request Anthropic's GPAI transparency documentation or model card; retain on file GAP-008 User guidance on appropriate input data not yet produced Article 26(3) Low Head of Product Produce and publish guidance for law firm users on appropriate contract document inputs"},{"location":"phase-2-worked-example/P2-Worked-Example-EU-AI-Act-Mapping-v1/#5-mapping-to-other-governance-documents","title":"5. Mapping to Other Governance Documents","text":"<p>The obligations identified in this document are addressed across the Pickles GmbH governance framework as follows.</p> Obligation Area Primary Governance Document Transparency and output labelling L2-4.3-Transparency-Disclosure-Framework-v1.md Human oversight design L1-3.4-Human-Oversight-Policy-v1.md Technical documentation P2-Worked-Example-Technical-Documentation-v1.md Logging and traceability L3-6.1-AI-Monitoring-Framework-v1.md Incident response and provider notification L3-6.2-Incident-Response-Playbook-v1.md Model change management L3-6.3-Model-Change-Management-Protocol-v1.md Vendor and GPAI model risk L2-5.3-Vendor-Model-Risk-Assessment-v1.md DPIA and data processing L2-5.2-DPIA-Assessment-v1.md"},{"location":"phase-2-worked-example/P2-Worked-Example-EU-AI-Act-Mapping-v1/#6-review-and-update-triggers","title":"6. Review and Update Triggers","text":"<p>This mapping should be reviewed and updated when any of the following occur:</p> <ul> <li>[ ] EU AI Office publishes updated guidance on Article 52 obligations for document-based AI output</li> <li>[ ] Product roadmap introduces automation features that reduce or remove the mandatory lawyer review gate</li> <li>[ ] Legal Counsel completes review of Annex III classification (RC-001 from risk classification document)</li> <li>[ ] Anthropic provides GPAI compliance documentation that creates new downstream obligations</li> <li>[ ] Any Annex III category is amended by delegated act under Article 7 of the EU AI Act</li> </ul> <p>This document is a fictional worked example produced for educational and demonstration purposes. Vertrag.AI does not exist. All regulatory analysis is illustrative and does not constitute legal advice. Professional legal review is required before any obligations mapping is relied upon operationally.</p>"},{"location":"phase-2-worked-example/P2-Worked-Example-Monitoring-Entry-v1/","title":"P2 Worked Example \u2014 Monitoring Framework Entry: Vertrag.AI","text":"<p>Project: Pickles GmbH \u2014 AI Governance Framework Stage: Phase 2 \u2014 Worked Example Document: P2-Worked-Example-Monitoring-Entry-v1.md Status: Draft Version: v1 Date: 2026-02-28 Assumptions: Built on Phase 2 fictional system design \u2014 Vertrag.AI does not exist. All metrics, thresholds, and dashboard designs are illustrative. Requires population with real operational data before use.</p>"},{"location":"phase-2-worked-example/P2-Worked-Example-Monitoring-Entry-v1/#about-this-document","title":"About This Document","text":"<p>This document populates the Pickles GmbH AI Monitoring Framework (L3-6.1) with a fully worked entry for Vertrag.AI. It defines the specific metrics to be tracked, how they are measured, what thresholds trigger action, the review cadence, and the dashboard design for this system.</p> <p>The monitoring design reflects Vertrag.AI's internal classification as Medium-High risk, professional liability exposure, and the particular challenge of monitoring an AI system that processes legally privileged material \u2014 which limits what can be logged.</p>"},{"location":"phase-2-worked-example/P2-Worked-Example-Monitoring-Entry-v1/#1-system-reference","title":"1. System Reference","text":"Field Entry System Vertrag.AI System ID PKL-SYS-003 Internal risk tier Medium-High Monitoring tier Active \u2014 quarterly formal review; continuous automated monitoring Monitoring owner Head of Product Technical monitoring lead Head of Engineering Entry last reviewed 2026-02-28 (initial)"},{"location":"phase-2-worked-example/P2-Worked-Example-Monitoring-Entry-v1/#2-monitoring-constraints","title":"2. Monitoring Constraints","text":"<p>Before defining metrics, the key constraint shaping Vertrag.AI's monitoring design must be stated clearly.</p> <p>The GDPR/confidentiality constraint: Contract documents uploaded to Vertrag.AI are legally privileged material and contain personal data. Full contract text, full prompt content, and matter-identifying information cannot be retained in monitoring logs. This means standard LLM monitoring techniques \u2014 such as reviewing full prompt/completion pairs for quality \u2014 are not available.</p> <p>This constraint is inherent to the legal market context and cannot be resolved without compromising the confidentiality obligations that make the product viable. The monitoring design works around it through:</p> <ul> <li>Metadata-only logging \u2014 events and outcomes are logged without content</li> <li>Sampled review \u2014 a small, consented sample of sessions used for quality testing</li> <li>Outcome-based signals \u2014 lawyer accept/reject patterns as a proxy for output quality</li> <li>User-reported signals \u2014 structured error and concern reporting by lawyers</li> </ul> <p>All monitoring design decisions below reflect this constraint.</p>"},{"location":"phase-2-worked-example/P2-Worked-Example-Monitoring-Entry-v1/#3-metrics-register","title":"3. Metrics Register","text":""},{"location":"phase-2-worked-example/P2-Worked-Example-Monitoring-Entry-v1/#31-output-quality-metrics","title":"3.1 Output Quality Metrics","text":"Metric ID Metric Name Description Measurement Method Frequency Target Alert Threshold MQ-01 Suggestion acceptance rate Percentage of AI-generated redline suggestions accepted by reviewing lawyers without modification Derived from review action logs (accept/reject/modify counts per session) Continuous; weekly aggregate \u226560% acceptance [ASSUMPTION: baseline to be established in first 90 days] &lt;40% acceptance in any rolling 7-day window MQ-02 Suggestion modification rate Percentage of accepted suggestions that were modified before acceptance Derived from review action logs Weekly aggregate Informational only \u2014 no threshold initially Significant change from baseline (&gt;\u00b115%) MQ-03 Clause identification miss rate (user-reported) Number of sessions where lawyer reports a significant clause issue was missed by the system User-reported via in-product feedback mechanism Per report; monthly aggregate 0 per month [ASSUMPTION] Any single report triggers review; \u22653 in a month triggers incident MQ-04 Citation accuracy (sampled) Percentage of specific legal provision citations (BGB articles, AGB standards) that are accurate when spot-checked Quarterly sampled review by legal content team \u2014 minimum 20 sessions reviewed Quarterly \u226595% accuracy on cited provisions &lt;90% triggers urgent review and potential system suspension MQ-05 False positive rate (sampled) Percentage of suggestions in sampled sessions assessed as spurious by reviewing lawyers Quarterly sampled review Quarterly \u226415% of suggestions assessed as spurious &gt;25% triggers product review <p>Note on sampling: Quarterly sampled reviews (MQ-04, MQ-05) require law firm users to opt in to having a session reviewed by Pickles GmbH's legal content team. Session content reviewed under sampling must be subject to confidentiality obligations equivalent to those governing the original matter. Consent and confidentiality framework for sampling must be established before this metric can be collected. [ASSUMPTION: consent framework does not yet exist \u2014 flag for Legal Counsel.]</p>"},{"location":"phase-2-worked-example/P2-Worked-Example-Monitoring-Entry-v1/#32-system-performance-metrics","title":"3.2 System Performance Metrics","text":"Metric ID Metric Name Description Measurement Method Frequency Target Alert Threshold SP-01 API error rate Percentage of Anthropic API calls that return an error or timeout Application error logs Continuous &lt;1% error rate &gt;3% in any 1-hour window SP-02 Processing latency (p95) 95th percentile end-to-end processing time from upload to redlined output available Application performance logs Continuous &lt;120 seconds [ASSUMPTION] &gt;300 seconds sustained for &gt;30 minutes SP-03 RAG retrieval failure rate Percentage of queries where RAG layer returns zero relevant results RAG system logs Continuous &lt;2% of queries &gt;5% in any 24-hour window SP-04 Document processing failure rate Percentage of uploaded documents that fail to parse or process Application error logs Continuous &lt;0.5% &gt;2% triggers engineering review SP-05 System availability Uptime percentage measured against agreed SLA Infrastructure monitoring Continuous \u226599.5% monthly [ASSUMPTION] Any unplanned downtime &gt;2 hours triggers incident log entry"},{"location":"phase-2-worked-example/P2-Worked-Example-Monitoring-Entry-v1/#33-usage-and-adoption-metrics","title":"3.3 Usage and Adoption Metrics","text":"<p>These metrics are informational \u2014 they support product understanding and help contextualise quality signals rather than triggering direct governance actions.</p> Metric ID Metric Name Description Frequency UA-01 Active law firm accounts Number of firms with at least one session in the period Monthly UA-02 Sessions per firm Average sessions per active firm per month Monthly UA-03 Contract types processed Distribution of contract categories processed (commercial, employment, real estate, etc.) Quarterly UA-04 Rejection-only sessions Sessions where the lawyer rejected all AI suggestions \u2014 potential indicator of poor output or inappropriate use case Monthly UA-05 Pre-signature vs post-signature split Proportion of sessions in each use case Monthly"},{"location":"phase-2-worked-example/P2-Worked-Example-Monitoring-Entry-v1/#34-user-reported-signal-metrics","title":"3.4 User-Reported Signal Metrics","text":"Metric ID Metric Name Description Measurement Method Frequency Alert Threshold UR-01 User error reports Structured reports submitted by lawyers via in-product feedback on output quality issues In-product report form; tracked in issue log Per report; monthly aggregate Any report categorised as \"material error with client impact\" triggers incident review UR-02 Support tickets related to output quality Help desk tickets where the reported issue relates to AI output accuracy or relevance Support ticket tagging Monthly \u22653 in a month triggers product review UR-03 Net Promoter Score (NPS) \u2014 governance signal NPS data filtered for comments mentioning accuracy, reliability, or trust Quarterly NPS survey Quarterly Significant drop (&gt;10 points) or cluster of negative accuracy comments triggers review"},{"location":"phase-2-worked-example/P2-Worked-Example-Monitoring-Entry-v1/#35-model-and-infrastructure-change-signals","title":"3.5 Model and Infrastructure Change Signals","text":"Metric ID Metric Name Description Measurement Method Frequency MC-01 Model version in use Current Claude model version deployed Deployment log Continuous \u2014 logged on change MC-02 RAG corpus version Current version of German legal knowledge base Knowledge base version log Continuous \u2014 logged on update MC-03 Post-change quality delta Change in MQ-01 (acceptance rate) in 30 days following any model or corpus change Derived from MQ-01 data, segmented by deployment date Within 30 days of any change MC-04 Prompt version Current system prompt version in production Deployment log Continuous \u2014 logged on change"},{"location":"phase-2-worked-example/P2-Worked-Example-Monitoring-Entry-v1/#4-review-cadence","title":"4. Review Cadence","text":"Review Type Frequency Trigger Participants Output Automated alert review As triggered Alert threshold breached (see Section 3) Head of Engineering; on-call engineer Incident log entry or resolution note Weekly metrics review Weekly Standing Head of Product Dashboard review; flag anomalies Monthly monitoring report Monthly Calendar Head of Product; Head of Engineering Written summary of MQ, SP, UR metrics; trends; any open issues Quarterly formal review Quarterly Calendar Head of Product; Head of Engineering; Legal Counsel Full review of all metrics including sampled quality review (MQ-04, MQ-05); review of assumptions; update monitoring entry if thresholds need adjustment Post-incident review Within 14 days of any incident Incident closure Head of Product; Head of Engineering; Legal Counsel (if legal dimension) Root cause analysis; corrective actions; monitoring update if gaps identified Post-change review 30 days after model or corpus change MC-03 trigger Head of Product; Head of Engineering Quality delta assessment; decision to maintain, adjust, or rollback"},{"location":"phase-2-worked-example/P2-Worked-Example-Monitoring-Entry-v1/#5-dashboard-design","title":"5. Dashboard Design","text":""},{"location":"phase-2-worked-example/P2-Worked-Example-Monitoring-Entry-v1/#51-dashboard-purpose-and-audience","title":"5.1 Dashboard Purpose and Audience","text":"<p>The Vertrag.AI monitoring dashboard provides a single-view summary of system health for the Head of Product and Head of Engineering. It is not a client-facing document. It feeds into the monthly monitoring report and quarterly formal review.</p>"},{"location":"phase-2-worked-example/P2-Worked-Example-Monitoring-Entry-v1/#52-dashboard-layout","title":"5.2 Dashboard Layout","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  VERTRAG.AI \u2014 MONITORING DASHBOARD          [Last updated: live] \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  SYSTEM STATUS          \u2502  MODEL VERSION      \u2502  CORPUS VERSION  \u2502\n\u2502  \u25cf OPERATIONAL          \u2502  claude-sonnet-4-6  \u2502  v1.2 (Feb 2026) \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  OUTPUT QUALITY                       \u2502  SYSTEM PERFORMANCE      \u2502\n\u2502                                       \u2502                          \u2502\n\u2502  Suggestion acceptance rate (7d)      \u2502  API error rate (24h)    \u2502\n\u2502  \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2591\u2591  64%  \u2713               \u2502  0.4%  \u2713                 \u2502\n\u2502                                       \u2502                          \u2502\n\u2502  User error reports (30d)             \u2502  Processing latency p95  \u2502\n\u2502  2 reports \u2014 0 material  \u2713            \u2502  87s  \u2713                  \u2502\n\u2502                                       \u2502                          \u2502\n\u2502  Citation accuracy (last sample)      \u2502  RAG retrieval failures  \u2502\n\u2502  97%  \u2713  [Q4 2025]                    \u2502  1.1%  \u2713                 \u2502\n\u2502                                       \u2502                          \u2502\n\u2502  False positive rate (last sample)    \u2502  System availability     \u2502\n\u2502  11%  \u2713  [Q4 2025]                    \u2502  99.8%  \u2713                \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  TREND \u2014 SUGGESTION ACCEPTANCE RATE (12 weeks)                   \u2502\n\u2502                                                                  \u2502\n\u2502  70% \u2524                                                           \u2502\n\u2502  65% \u2524    \u25cf   \u25cf       \u25cf   \u25cf   \u25cf                                  \u2502\n\u2502  60% \u2524\u25cf       \u25cf   \u25cf       \u25cf       \u25cf   \u25cf                          \u2502\n\u2502  55% \u2524                                \u25cf                          \u2502\n\u2502  50% \u2524                                                           \u2502\n\u2502      \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500    \u2502\n\u2502        W1  W2  W3  W4  W5  W6  W7  W8  W9  W10 W11 W12          \u2502\n\u2502                                                 \u2191 alert zone     \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  OPEN ALERTS          \u2502  NEXT REVIEW                             \u2502\n\u2502  None                 \u2502  Monthly: 31 Mar 2026                    \u2502\n\u2502                       \u2502  Quarterly: 30 Apr 2026                  \u2502\n\u2502                       \u2502  Sampled review due: 30 Apr 2026         \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>[ASSUMPTION] Dashboard above is illustrative. Technical implementation (tooling, data connections, refresh frequency) to be confirmed by engineering team. Candidate tooling includes internal BI dashboard, Grafana, or a purpose-built product health screen within the Pickles GmbH operations interface.</p>"},{"location":"phase-2-worked-example/P2-Worked-Example-Monitoring-Entry-v1/#53-alert-states","title":"5.3 Alert States","text":"Status Indicator Meaning \u2713 Green \u2014 within target No action required \u26a0 Amber \u2014 approaching threshold Monitor closely; review at next scheduled meeting \u2717 Red \u2014 threshold breached Immediate review required; escalate per incident response playbook (L3-6.2)"},{"location":"phase-2-worked-example/P2-Worked-Example-Monitoring-Entry-v1/#6-monitoring-gaps-and-open-actions","title":"6. Monitoring Gaps and Open Actions","text":"# Gap Priority Owner Action MON-001 Consent and confidentiality framework for sampled quality review (MQ-04, MQ-05) not yet established High Legal Counsel Design consent model for sampling; obtain legal sign-off before quarterly sampled review begins MON-002 Baseline acceptance rate (MQ-01 target) not yet established \u2014 no production data High Head of Product Run 90-day baseline period before alert threshold is enforced; set threshold from baseline data MON-003 In-product user error report mechanism not yet confirmed Medium Head of Product / Engineering Confirm UR-01 and UR-02 reporting mechanisms are built into product MON-004 Dashboard tooling not yet selected or implemented Medium Head of Engineering Select tooling; implement initial dashboard before system goes live MON-005 RAG corpus version control logging not yet confirmed Medium Head of Engineering Confirm MC-02 logging is implemented; version history maintained"},{"location":"phase-2-worked-example/P2-Worked-Example-Monitoring-Entry-v1/#7-connection-to-other-governance-documents","title":"7. Connection to Other Governance Documents","text":"Area Document Incident response (when thresholds are breached) L3-6.2-Incident-Response-Playbook-v1.md Model change management (MC-01 to MC-04) L3-6.3-Model-Change-Management-Protocol-v1.md Testing methodology (MQ-04, MQ-05 sampled reviews) P2-Worked-Example-Technical-Documentation-v1.md Section 4 Human oversight design (MQ-01 to MQ-03 depend on) L1-3.4-Human-Oversight-Policy-v1.md GDPR logging constraints (Section 2) L2-5.1-Data-Flow-Map-v1.md; L2-5.2-DPIA-Assessment-v1.md <p>This document is a fictional worked example produced for educational and demonstration purposes. Vertrag.AI does not exist. All metrics, thresholds, and dashboard designs are illustrative and do not constitute operational monitoring specifications. Professional review is required before any monitoring framework is applied operationally.</p>"},{"location":"phase-2-worked-example/P2-Worked-Example-Risk-Classification-v1/","title":"P2 Worked Example \u2014 Risk Classification Walkthrough: Vertrag.AI","text":"<p>Project: Pickles GmbH \u2014 AI Governance Framework Stage: Phase 2 \u2014 Worked Example Document: P2-Worked-Example-Risk-Classification-v1.md Status: Draft Version: v1 Date: 2026-02-28 Assumptions: Built on Phase 2 fictional system design \u2014 Vertrag.AI does not exist. All classification reasoning is illustrative. Not verified against real company data or reviewed by a qualified lawyer.</p>"},{"location":"phase-2-worked-example/P2-Worked-Example-Risk-Classification-v1/#about-this-document","title":"About This Document","text":"<p>This document walks Vertrag.AI through the Pickles GmbH Risk Classification Framework (L1-3.2), making the decision-tree reasoning explicit at every step. The purpose is twofold: to assign a classification to Vertrag.AI for use across the Phase 2 worked example documents, and to demonstrate that the framework produces defensible, traceable reasoning when applied to a realistic system.</p> <p>All classification decisions are flagged where professional legal review would be required before treating them as final.</p>"},{"location":"phase-2-worked-example/P2-Worked-Example-Risk-Classification-v1/#1-system-under-review","title":"1. System Under Review","text":"Field Entry System Vertrag.AI System ID PKL-SYS-003 System Profile reference P2-Worked-Example-System-Profile-v1.md Classification conducted by [Governance function \u2014 fictional] Classification date 2026-02-28 Review required from Qualified German lawyer before operational use"},{"location":"phase-2-worked-example/P2-Worked-Example-Risk-Classification-v1/#2-decision-tree-walkthrough","title":"2. Decision Tree Walkthrough","text":"<p>The Pickles GmbH Risk Classification Framework uses a sequential decision tree. Each gate must be answered before proceeding. The first gate that results in a definitive classification terminates the tree; remaining gates are documented for completeness and audit traceability.</p>"},{"location":"phase-2-worked-example/P2-Worked-Example-Risk-Classification-v1/#gate-1-eu-ai-act-prohibited-practices-article-5","title":"Gate 1 \u2014 EU AI Act Prohibited Practices (Article 5)","text":"<p>Question: Does the system employ any AI practice prohibited under EU AI Act Article 5?</p> <p>Prohibited practices under Article 5 include: subliminal manipulation, exploitation of vulnerabilities, real-time biometric surveillance in public spaces, social scoring by public authorities, and certain emotion recognition and biometric categorisation applications.</p> <p>Assessment for Vertrag.AI:</p> <p>Vertrag.AI analyses uploaded contract documents and produces redlined suggested amendments. It does not: - Manipulate users subliminally or exploit psychological vulnerabilities - Conduct any form of biometric processing - Perform emotion recognition - Operate as a social scoring mechanism - Function autonomously in a manner that bypasses human will</p> <p>None of the Article 5 prohibited categories apply to a contract review tool of this design.</p> <p>Decision: \u274c No prohibited practice present \u2192 proceed to Gate 2</p>"},{"location":"phase-2-worked-example/P2-Worked-Example-Risk-Classification-v1/#gate-2-eu-ai-act-high-risk-classification-annex-iii","title":"Gate 2 \u2014 EU AI Act High-Risk Classification (Annex III)","text":"<p>Question: Does the system fall within one of the high-risk categories listed in EU AI Act Annex III?</p> <p>Annex III lists eight areas of high-risk AI systems. The most relevant to a legal AI tool are examined below.</p> Annex III Category Description Assessment for Vertrag.AI 1 \u2014 Biometric systems Remote biometric identification, categorisation Not applicable \u2014 no biometric processing 2 \u2014 Critical infrastructure Safety components of critical infrastructure Not applicable 3 \u2014 Education and vocational training Determining access to education, assessment of learners Not applicable 4 \u2014 Employment and workers management Recruitment, promotion, task allocation, performance monitoring affecting employment Not applicable \u2014 system reviews contracts, not employment decisions 5 \u2014 Essential private and public services Credit scoring, emergency services dispatch, risk assessment in life/health insurance Potentially relevant: contract review could include financial contracts, insurance contracts, or credit agreements. Analysis below. 6 \u2014 Law enforcement Risk assessment of natural persons, polygraph, profiling Not applicable \u2014 Vertrag.AI is not used by law enforcement 7 \u2014 Migration, asylum, border control Risk assessment, document authentication, visa applications Not applicable 8 \u2014 Administration of justice and democratic processes AI assisting courts or tribunals; influencing elections Potentially relevant: if Vertrag.AI output is used in litigation support or dispute resolution. Analysis below. <p>Detailed analysis \u2014 Annex III Category 5 (Essential private services):</p> <p>Annex III, point 5(b) covers AI systems used to evaluate creditworthiness or establish credit scores, except where used to detect financial fraud. Vertrag.AI reviews contracts that may include financial or credit agreements, but it does not itself score creditworthiness or make credit decisions. The system analyses the legal text of a contract and flags legal risk in the document \u2014 it does not produce a creditworthiness assessment of any natural person. On this basis, Category 5 does not apply to Vertrag.AI as designed.</p> <p>However: if a future product iteration were to produce a risk score about a counterparty rather than a risk analysis of a document, this classification would need to be revisited. [Flag for product roadmap review.]</p> <p>Detailed analysis \u2014 Annex III Category 8 (Administration of justice):</p> <p>Annex III, point 8(a) covers AI systems intended to assist judicial authorities in researching and interpreting facts and law and applying the law to a concrete set of facts. Vertrag.AI is used by lawyers at law firms, not by courts or tribunals. Its output is an input to lawyer advice, not a direct input to judicial decision-making. On this basis, Category 8 does not apply in the system's current deployment context.</p> <p>However: if Vertrag.AI output were used directly in court submissions without further independent legal analysis \u2014 for example, if a solicitor presented the AI redline as their own advice without review \u2014 this boundary would become less clear. The mandatory human review gate in the product design, and the explicit labelling of output as AI-drafted, are the key controls mitigating this risk. [Flag for legal review; reinforce in Human Oversight Policy application.]</p> <p>Decision: \u274c No Annex III high-risk category confirmed \u2192 proceed to Gate 3</p> <p>[LEGAL REVIEW FLAG] The Annex III analysis above involves interpretive judgment on the scope of EU AI Act categories as applied to a contract review tool. This reasoning should be reviewed by a qualified lawyer with EU AI Act expertise before any final classification is relied upon operationally. EU AI Act guidance from the European AI Office may also provide further clarity as it develops.</p>"},{"location":"phase-2-worked-example/P2-Worked-Example-Risk-Classification-v1/#gate-3-general-purpose-ai-gpai-model-assessment-articles-5155","title":"Gate 3 \u2014 General Purpose AI (GPAI) Model Assessment (Articles 51\u201355)","text":"<p>Question: Is Vertrag.AI itself a General Purpose AI model, or does it deploy one in a way that requires specific GPAI obligations?</p> <p>Vertrag.AI is a deployer of a GPAI model (the Claude API, provided by Anthropic). Anthropic, as the provider of the underlying Claude model, holds the GPAI provider obligations under Articles 51\u201355 of the EU AI Act. Pickles GmbH, as deployer, is not a GPAI provider and does not trigger GPAI provider obligations.</p> <p>Pickles GmbH does, however, have deployer obligations under Article 16 (where applicable to the risk tier of the system as deployed) and transparency obligations under Article 52.</p> <p>Decision: \u2705 Pickles GmbH is a deployer, not a GPAI provider \u2192 GPAI provider obligations do not apply \u2192 proceed to Gate 4</p>"},{"location":"phase-2-worked-example/P2-Worked-Example-Risk-Classification-v1/#gate-4-transparency-obligations-article-52","title":"Gate 4 \u2014 Transparency Obligations (Article 52)","text":"<p>Question: Does the system trigger transparency obligations under EU AI Act Article 52?</p> <p>Article 52 obligations apply to: - AI systems that interact with natural persons (chatbot disclosure requirement) - AI systems that generate synthetic content (deepfake disclosure) - Emotion recognition systems - Biometric categorisation systems</p> <p>Vertrag.AI produces AI-generated contract analysis and clause suggestions. The output is reviewed by a lawyer before reaching any client. The system does not directly interact with natural persons (law firm clients); it interacts with qualified lawyers as professional users.</p> <p>Assessment:</p> <p>Article 52(1) (chatbot disclosure) does not apply \u2014 the system is not a conversational interface used by natural persons who might otherwise believe they are interacting with a human.</p> <p>Article 52(3) (synthetic content disclosure) may apply to the AI-drafted clause suggestions in the redlined output, to the extent they constitute AI-generated text that could be presented as human-authored. The mandatory output labelling in the product design (all AI-generated amendments marked as AI-drafted) addresses this obligation. [Flag for legal review \u2014 whether Article 52(3) applies to AI-generated contract clauses and what disclosure form is required.]</p> <p>Decision: \u2705 Article 52 transparency obligations apply \u2014 specifically in relation to labelling of AI-generated clause suggestions \u2192 to be addressed in Transparency &amp; Disclosure Framework</p>"},{"location":"phase-2-worked-example/P2-Worked-Example-Risk-Classification-v1/#gate-5-internal-risk-criteria","title":"Gate 5 \u2014 Internal Risk Criteria","text":"<p>Having completed the regulatory gates, the system is now assessed against Pickles GmbH's internal risk criteria to assign an internal tier.</p> <p>Internal criteria assessment:</p> Criterion Weight Assessment Score Impact on legal outcomes affecting natural persons High High \u2014 contract review directly influences advice given to clients on legally binding documents \u2b06 Elevates Level of automation in output High Medium \u2014 output requires mandatory lawyer review; no autonomous action \u2192 Neutral Client-facing exposure High Indirect \u2014 output goes to lawyer, not directly to client \u2192 Neutral Processing of legally privileged material Medium High \u2014 all uploaded contracts are likely privileged material \u2b06 Elevates Processing of personal data Medium High \u2014 contracts frequently contain personal data of third parties \u2b06 Elevates Professional regulatory overlay Medium High \u2014 BRAK obligations on lawyers using AI; professional liability consequences \u2b06 Elevates RAG dependency risk Medium Medium \u2014 output quality dependent on corpus accuracy and freshness \u2b06 Elevates Third-party model provider dependency Low Present \u2014 Claude API; DPA required; model updates must be managed \u2b06 Elevates <p>Aggregate assessment: Multiple elevating factors with no strong mitigating factors. The mandatory human review gate is the single most significant risk control and prevents classification as High risk, but it does not reduce the system to Low risk given the professional liability context and data sensitivity.</p>"},{"location":"phase-2-worked-example/P2-Worked-Example-Risk-Classification-v1/#3-classification-result","title":"3. Classification Result","text":""},{"location":"phase-2-worked-example/P2-Worked-Example-Risk-Classification-v1/#31-eu-ai-act-classification","title":"3.1 EU AI Act Classification","text":"Dimension Classification Basis EU AI Act risk tier Limited risk Does not fall within Annex III; no prohibited practice; Article 52 transparency obligations apply Primary obligation Transparency (Article 52) \u2014 labelling of AI-generated output Addressed in product design via AI-drafted output marking Secondary obligation Deployer obligations under Article 16 apply to the extent required for the risk tier To be confirmed on legal review GPAI deployer obligations Applicable \u2014 Pickles GmbH as deployer of a GPAI-based system See Article 16 and relevant GPAI provisions <p>Conditional flag: If the EU AI Act classification is revisited and Annex III Category 5 or 8 is found to apply, the system would become a High Risk AI system subject to the full suite of Chapter III Section 2 obligations (conformity assessment, technical documentation, human oversight requirements, registration, etc.). This document should be rerun through the decision tree if the product design or deployment context changes materially.</p>"},{"location":"phase-2-worked-example/P2-Worked-Example-Risk-Classification-v1/#32-pickles-gmbh-internal-classification","title":"3.2 Pickles GmbH Internal Classification","text":"Dimension Classification Internal tier Medium-High Tier definition Decision-support AI system in a regulated professional context, processing sensitive data, with indirect client exposure and professional liability consequences Required documentation Full technical documentation pack; DPIA; vendor risk assessment; monitoring framework entry Required review level Head of Product sign-off; Legal Counsel sign-off; qualified lawyer review of EU AI Act classification Monitoring intensity Active \u2014 quarterly monitoring review; error and complaint tracking; RAG corpus refresh on defined schedule Escalation pathway Product incident \u2192 Head of Product \u2192 Legal Counsel \u2192 CEO if regulatory dimension"},{"location":"phase-2-worked-example/P2-Worked-Example-Risk-Classification-v1/#33-classification-summary","title":"3.3 Classification Summary","text":"<pre><code>Vertrag.AI \u2014 PKL-SYS-003\n\nEU AI Act:   Limited Risk (Article 52 transparency obligations)\nInternal:    Medium-High\n             \u2193\nObligations triggered:\n  \u2022 AI-generated output labelling (Article 52)\n  \u2022 Deployer obligations (Article 16 \u2014 proportionate to risk tier)\n  \u2022 Full technical documentation\n  \u2022 DPIA required\n  \u2022 Vendor/model risk assessment required\n  \u2022 Active monitoring programme\n  \u2022 Mandatory human oversight gate (existing product design)\n\nLegal review required before classification is treated as final.\n</code></pre>"},{"location":"phase-2-worked-example/P2-Worked-Example-Risk-Classification-v1/#4-what-this-classification-means-for-subsequent-documents","title":"4. What This Classification Means for Subsequent Documents","text":"<p>The classification result feeds directly into the remaining Phase 2 worked example documents:</p> Document Impact of Classification P2-Worked-Example-EU-AI-Act-Mapping-v1.md Article 52 obligations mapped in full; deployer obligations under Article 16 included; Annex III analysis documented P2-Worked-Example-Technical-Documentation-v1.md Full technical documentation pack required at Medium-High tier P2-Worked-Example-Monitoring-Entry-v1.md Active monitoring tier applies; quarterly review cycle; defined metrics"},{"location":"phase-2-worked-example/P2-Worked-Example-Risk-Classification-v1/#5-open-items-and-review-flags","title":"5. Open Items and Review Flags","text":"# Item Action Required Owner RC-001 EU AI Act Annex III analysis \u2014 interpretive judgment on Categories 5 and 8 Legal review before classification treated as final Qualified German lawyer RC-002 Article 52(3) applicability to AI-generated contract clause suggestions Legal review of disclosure form required Legal Counsel RC-003 Product roadmap check \u2014 any planned feature increasing automation level Reassessment if automation level rises Head of Product RC-004 Deployer obligations under Article 16 \u2014 precise scope at limited-risk tier Legal review Legal Counsel RC-005 EU AI Office guidance on GPAI deployer obligations Monitor for updated guidance as EU AI Act implementation matures Governance function <p>This document is a fictional worked example produced for educational and demonstration purposes. Vertrag.AI does not exist. All regulatory analysis is illustrative and does not constitute legal advice. Professional legal review is required before any classification is relied upon operationally.</p>"},{"location":"phase-2-worked-example/P2-Worked-Example-System-Profile-v1/","title":"P2 Worked Example \u2014 System Profile: Vertrag.AI","text":"<p>Project: Pickles GmbH \u2014 AI Governance Framework Stage: Phase 2 \u2014 Worked Example Document: P2-Worked-Example-System-Profile-v1.md Status: Draft Version: v1 Date: 2026-02-28 Assumptions: Built on Phase 2 fictional system design \u2014 Vertrag.AI does not exist. All system characteristics are illustrative. Not verified against real company data.</p>"},{"location":"phase-2-worked-example/P2-Worked-Example-System-Profile-v1/#about-this-document","title":"About This Document","text":"<p>This document populates the Pickles GmbH AI System Inventory template (L1-3.1) with a fully worked entry for Vertrag.AI, a fictional contract review tool operated by Pickles GmbH for German law firm clients. It demonstrates how the inventory framework functions against realistic system content.</p> <p>All fields follow the structure defined in L1-3.1-AI-System-Inventory-v1.md. Where that template requires [ASSUMPTION] flags, they are carried through here with content populated.</p>"},{"location":"phase-2-worked-example/P2-Worked-Example-System-Profile-v1/#1-system-identification","title":"1. System Identification","text":"Field Entry System Name Vertrag.AI System ID PKL-SYS-003 System Owner Head of Product, Pickles GmbH Technical Lead Senior ML Engineer, Pickles GmbH [ASSUMPTION: role exists; name not assigned in fictional design] Date Registered 2026-02-28 Record Last Updated 2026-02-28 Deployment Status Production"},{"location":"phase-2-worked-example/P2-Worked-Example-System-Profile-v1/#2-system-description","title":"2. System Description","text":""},{"location":"phase-2-worked-example/P2-Worked-Example-System-Profile-v1/#21-purpose-and-function","title":"2.1 Purpose and Function","text":"<p>Vertrag.AI is a B2B SaaS contract review tool designed for German law firms reviewing contracts on behalf of clients. The system analyses uploaded contract documents, identifies legally significant clauses, surfaces risk flags, and produces a redlined output with AI-drafted suggested clause amendments. Lawyer review and approval is required before any amended output is used or shared with clients.</p> <p>The system supports two primary workflow positions:</p> <ul> <li>Pre-signature review: The law firm uploads a contract prior to client execution. Vertrag.AI produces a risk-flagged analysis and redlined suggested amendments. The supervising lawyer reviews, accepts or rejects suggested changes, and provides final advice to the client.</li> <li>Post-signature audit: The law firm uploads an existing contract from a client's portfolio. Vertrag.AI analyses obligations, risk exposure, and potential issues for ongoing portfolio management or dispute preparation.</li> </ul>"},{"location":"phase-2-worked-example/P2-Worked-Example-System-Profile-v1/#22-user-population","title":"2.2 User Population","text":"User Type Description Primary users Qualified lawyers (Rechtsanw\u00e4lte) and legal assistants at German law firms Indirect affected parties Law firm clients (natural persons and legal entities) whose contracts are reviewed using the system Excluded users Members of the public; individuals without a law firm account"},{"location":"phase-2-worked-example/P2-Worked-Example-System-Profile-v1/#23-operational-context","title":"2.3 Operational Context","text":"<p>Vertrag.AI is accessed via a web application hosted on EU-based cloud infrastructure [ASSUMPTION: EU hosting confirmed in fictional design; hosting provider not specified]. Law firm users authenticate via single sign-on (SSO) linked to the firm's Pickles GmbH account. Contracts are uploaded as PDF or DOCX files. The system processes the document, returns analysis and a redlined DOCX output, and stores both within the user's account workspace. No AI-generated output is transmitted directly to the law firm's clients \u2014 output is intermediated by the supervising lawyer.</p>"},{"location":"phase-2-worked-example/P2-Worked-Example-System-Profile-v1/#3-technical-architecture","title":"3. Technical Architecture","text":""},{"location":"phase-2-worked-example/P2-Worked-Example-System-Profile-v1/#31-system-type","title":"3.1 System Type","text":"Field Entry AI System Category Generative AI \u2014 Large Language Model (LLM) with Retrieval-Augmented Generation (RAG) Model Provider Anthropic (Claude API) [ASSUMPTION: API access via standard commercial agreement; data processing agreement in place] Model Version Policy Pinned to a specific Claude model version; version changes require internal change management sign-off before deployment RAG Layer Yes \u2014 retrieval layer over a curated corpus of German legal sources (see Section 3.3) Fine-tuning No fine-tuning applied to base model [ASSUMPTION] Self-hosted components RAG retrieval infrastructure, document pre-processing pipeline, output formatting layer"},{"location":"phase-2-worked-example/P2-Worked-Example-System-Profile-v1/#32-data-flow-summary","title":"3.2 Data Flow Summary","text":"<pre><code>User uploads contract (PDF/DOCX)\n        \u2193\nDocument pre-processing pipeline\n(extraction, chunking, format normalisation)\n        \u2193\nRAG retrieval layer\n(relevant German legal corpus passages retrieved)\n        \u2193\nPrompt construction\n(system prompt + contract content + retrieved legal context)\n        \u2193\nClaude API (Anthropic)\n(analysis generated; clause amendments drafted)\n        \u2193\nOutput post-processing\n(redlined DOCX generated; risk flags structured)\n        \u2193\nResult stored in user workspace\n        \u2193\nLawyer reviews, accepts/rejects amendments\n        \u2193\nFinal document used or discarded \u2014 lawyer's decision\n</code></pre> <p>[ASSUMPTION: Data flow above reflects intended architectural design. Actual implementation details would require verification with CTO/engineering lead.]</p>"},{"location":"phase-2-worked-example/P2-Worked-Example-System-Profile-v1/#33-rag-corpus-german-legal-sources","title":"3.3 RAG Corpus \u2014 German Legal Sources","text":"<p>The retrieval layer draws from a curated corpus maintained by Pickles GmbH. [ASSUMPTION: Corpus composition below is illustrative; actual sources would require verification.]</p> Source Type Examples German statutory law BGB (B\u00fcrgerliches Gesetzbuch), HGB (Handelsgesetzbuch), selected sector statutes German case law summaries BGH (Bundesgerichtshof) case summaries \u2014 selected landmark decisions Standard contract clause libraries BRAK guidance on standard terms; AGB (Allgemeine Gesch\u00e4ftsbedingungen) reference materials Academic commentary summaries Curated excerpts from major German civil law commentaries <p>Corpus maintenance: The corpus is reviewed and updated on a defined schedule. [ASSUMPTION: Quarterly review cycle \u2014 requires confirmation.] Updates follow the Model Change Management Protocol (L3-6.3).</p>"},{"location":"phase-2-worked-example/P2-Worked-Example-System-Profile-v1/#34-hosting-and-infrastructure","title":"3.4 Hosting and Infrastructure","text":"Field Entry Primary hosting location EU (Germany) [ASSUMPTION] Cloud provider Not specified in fictional design [ASSUMPTION: major EU-compliant provider] Data residency All contract data remains within EEA [ASSUMPTION] Anthropic API data processing Governed by Anthropic's data processing agreement; prompts not used for model training under commercial API terms [ASSUMPTION: DPA reviewed and confirms this] Encryption TLS 1.2+ in transit; AES-256 at rest [ASSUMPTION]"},{"location":"phase-2-worked-example/P2-Worked-Example-System-Profile-v1/#4-data-categories-processed","title":"4. Data Categories Processed","text":"Data Category Description GDPR Relevance Contract documents PDF/DOCX files uploaded by law firm users May contain personal data of third parties (counterparties, individuals named in contracts) Personal data of natural persons Names, addresses, signatures, identification references within contract documents Article 4(1) GDPR \u2014 personal data Potentially sensitive personal data Some contracts may reference health, employment, family, or financial matters Article 9 GDPR \u2014 special categories possible depending on contract type Legal professional privilege material Contracts reviewed in the context of a lawyer-client relationship BRAK professional confidentiality obligations apply Law firm user account data Login credentials, usage logs, account metadata Standard personal data under GDPR Article 4(1) <p>Key data protection note: Contract documents uploaded to Vertrag.AI are processed by the Claude API (Anthropic). This constitutes a transfer of potentially personal data to a sub-processor. A Data Processing Agreement must be in place with Anthropic, and the law firm client must be informed of sub-processor involvement via Pickles GmbH's data processing terms. [Requires review by qualified lawyer before operational use.]</p>"},{"location":"phase-2-worked-example/P2-Worked-Example-System-Profile-v1/#5-risk-classification","title":"5. Risk Classification","text":""},{"location":"phase-2-worked-example/P2-Worked-Example-System-Profile-v1/#51-preliminary-classification","title":"5.1 Preliminary Classification","text":"Classification Dimension Assessment EU AI Act risk tier Limited risk (Article 52) \u2014 transparency obligations apply; system does not fall within Annex III high-risk categories as currently designed [see note below] Pickles GmbH internal risk tier Medium-High Professional liability exposure High \u2014 output feeds into legal advice given to clients of a regulated profession Automation level Assisted decision-making \u2014 all outputs require mandatory human review and approval before use <p>EU AI Act classification note: Vertrag.AI does not appear to fall within the Annex III high-risk categories as defined in EU AI Act Regulation (EU) 2024/1689. The system does not make autonomous decisions affecting individuals' legal rights; all output is reviewed by a qualified lawyer before any client-facing use. However, the system processes legal content that could, if misused, influence legal outcomes affecting natural persons. This classification should be reviewed by a qualified lawyer and reassessed if the product roadmap moves toward greater automation. [Flag for legal review before operational use.]</p>"},{"location":"phase-2-worked-example/P2-Worked-Example-System-Profile-v1/#52-internal-risk-factors","title":"5.2 Internal Risk Factors","text":"<p>The following factors elevate Vertrag.AI's internal risk rating above low:</p> <ul> <li>Output is used in legal advice to clients \u2014 errors carry professional liability consequences for the law firm</li> <li>The system processes legally privileged material and potentially sensitive personal data</li> <li>German professional conduct rules (BRAK) impose obligations on lawyers using AI tools</li> <li>RAG corpus quality directly affects output accuracy \u2014 corpus drift or gaps could produce systematically incorrect advice</li> <li>Law firm clients may not be independently aware that AI has been used in their matter unless disclosed</li> </ul>"},{"location":"phase-2-worked-example/P2-Worked-Example-System-Profile-v1/#6-human-oversight-design","title":"6. Human Oversight Design","text":"Oversight Element Design Mandatory review gate All Vertrag.AI output is presented as a draft requiring lawyer review \u2014 no output is transmitted to clients without a supervising lawyer's approval Output labelling All AI-generated suggested amendments are visually marked as AI-drafted in the redlined DOCX; the system does not produce clean documents without lawyer action Disclaimer in product UI Persistent UI notice confirms that output constitutes AI-assisted analysis only and does not constitute legal advice Audit trail All system outputs, lawyer actions (accept/reject), and timestamps are logged per session Override capability Lawyers can reject any or all AI-suggested amendments; the system cannot override lawyer decisions <p>[ASSUMPTION: Oversight design above reflects intended product behaviour. Verification against actual product specification required.]</p>"},{"location":"phase-2-worked-example/P2-Worked-Example-System-Profile-v1/#7-monitoring-status","title":"7. Monitoring Status","text":"Field Entry Monitoring in place Yes \u2014 see P2-Worked-Example-Monitoring-Entry-v1.md for full monitoring framework entry Key metrics tracked Clause amendment acceptance rate; risk flag accuracy (sampled); user-reported error rate; API error rate; RAG retrieval quality indicators Incident log Active \u2014 no incidents recorded in fictional design Last monitoring review Not yet established (system newly registered in fictional design)"},{"location":"phase-2-worked-example/P2-Worked-Example-System-Profile-v1/#8-regulatory-and-compliance-cross-references","title":"8. Regulatory and Compliance Cross-References","text":"Framework Relevance Cross-Reference Document EU AI Act (Regulation (EU) 2024/1689) Transparency obligations (Article 52); provider obligations (Article 16 if high-risk classification confirmed) P2-Worked-Example-EU-AI-Act-Mapping-v1.md GDPR (Regulation (EU) 2016/679) Personal data in contracts; sub-processor relationship with Anthropic; data subject rights L2-5.1-GDPR-Alignment-Framework-v1.md BDSG (Bundesdatenschutzgesetz) German national data protection overlay L2-5.1-GDPR-Alignment-Framework-v1.md BRAK professional standards Lawyer obligations when using AI tools; client confidentiality L2-4.3-Transparency-Disclosure-Framework-v1.md Technical Documentation (EU AI Act Article 11) Required if high-risk classification applies or is confirmed on review P2-Worked-Example-Technical-Documentation-v1.md"},{"location":"phase-2-worked-example/P2-Worked-Example-System-Profile-v1/#9-open-assumptions-items-requiring-validation","title":"9. Open Assumptions \u2014 Items Requiring Validation","text":"<p>The following assumptions are embedded in this document and must be validated against real system data before this profile is used operationally.</p> # Assumption Section Validation Required From A-001 EU hosting confirmed; specific cloud provider not named 3.4 CTO / Head of Engineering A-002 Anthropic DPA in place; prompts not used for model training 3.4 Legal Counsel / CTO A-003 No fine-tuning applied to base model 3.1 Head of Engineering A-004 RAG corpus quarterly review cycle 3.3 Head of Product / Engineering A-005 Output labelling and UI disclaimer behaviour 6 Head of Product A-006 Audit trail logging per session 6 Head of Engineering A-007 EU AI Act classification confirmed as limited risk 5.1 Qualified German lawyer A-008 BRAK obligations assessed and addressed in product design 5.2, 6 Legal Counsel"},{"location":"phase-2-worked-example/P2-Worked-Example-System-Profile-v1/#10-document-notes","title":"10. Document Notes","text":"<p>This system profile is the first Phase 2 worked example document. Subsequent Phase 2 documents will use this profile as their authoritative source for Vertrag.AI system characteristics. If any field in this profile is revised, all dependent documents should be reviewed for consistency.</p> <p>Dependent documents: - P2-Worked-Example-Risk-Classification-v1.md - P2-Worked-Example-EU-AI-Act-Mapping-v1.md - P2-Worked-Example-Technical-Documentation-v1.md - P2-Worked-Example-Monitoring-Entry-v1.md - P2-Reflection-Note-v1.md</p> <p>This document is a fictional worked example produced for educational and demonstration purposes. Vertrag.AI does not exist. All regulatory references are made in good faith for illustrative purposes and do not constitute legal advice. Professional legal review is required before any governance framework is applied operationally.</p>"},{"location":"phase-2-worked-example/P2-Worked-Example-Technical-Documentation-v1/","title":"P2-Worked-Example-Technical-Documentation-v1.md","text":"<p>Project: Pickles GmbH \u2014 AI Governance Framework Stage: Phase 2 \u2014 Worked Example Document type: Technical Documentation Pack (EU AI Act Article 11 / Annex IV) System: Vertrag.AI \u2014 Contract Review Assistant Status: Draft Version: v1 Date: 2026-02-28 Assumptions: Built on Phase 2 worked example assumptions \u2014 Vertrag.AI is a fictional system. All technical parameters are illustrative. Requires population with real system data before operational use.</p>"},{"location":"phase-2-worked-example/P2-Worked-Example-Technical-Documentation-v1/#document-purpose","title":"Document Purpose","text":"<p>This document constitutes the Technical Documentation Pack for Vertrag.AI, prepared in accordance with the obligations framework established in <code>P2-Worked-Example-EU-AI-Act-Mapping-v1.md</code>.</p> <p>Vertrag.AI is classified as limited risk under the EU AI Act (Article 52 transparency obligations apply) with an internal classification of Medium-High due to professional liability exposure in the German legal market. This documentation pack is maintained as a proportionate governance control aligned with that internal classification, and as preparation for potential reclassification if the system's scope or capabilities expand.</p> <p>The structure follows the Annex IV template from the EU AI Act, adapted for a limited-risk system. Sections are populated with realistic illustrative content. Where real system data would be required, this is explicitly flagged.</p> <p>Note for implementers: If Vertrag.AI or an equivalent system were classified as high risk under Annex III, this document would become a mandatory compliance artefact. At limited-risk classification, it is a voluntary governance control. The decision to maintain it regardless reflects the professional liability context of the German legal market and the internal Medium-High risk rating.</p>"},{"location":"phase-2-worked-example/P2-Worked-Example-Technical-Documentation-v1/#section-1-system-description-and-intended-purpose","title":"Section 1 \u2014 System Description and Intended Purpose","text":""},{"location":"phase-2-worked-example/P2-Worked-Example-Technical-Documentation-v1/#11-system-name-and-version","title":"1.1 System Name and Version","text":"Field Value System name Vertrag.AI Current version v1.0 (illustrative) Deployment type B2B SaaS \u2014 cloud-hosted, multi-tenant System owner [Product Lead \u2014 to be confirmed] Technical owner [Head of Engineering \u2014 to be confirmed] Documentation maintained by Compliance function Last reviewed 2026-02-28"},{"location":"phase-2-worked-example/P2-Worked-Example-Technical-Documentation-v1/#12-intended-purpose","title":"1.2 Intended Purpose","text":"<p>Vertrag.AI is a contract review assistant designed for use by qualified lawyers at German law firms. The system assists with the review of commercial contracts, identifying potentially problematic clauses and producing a redlined version of the contract document.</p> <p>Primary use case: Pre-signature review of commercial contracts on behalf of a law firm's clients. The system analyses a contract uploaded by a lawyer, identifies clauses that warrant attention (non-standard terms, missing provisions, unfavourable risk allocation), and produces a redlined DOCX output. The lawyer reviews and accepts or rejects redline suggestions before any output is used or shared.</p> <p>Secondary use case: Post-signature contract analysis \u2014 reviewing executed contracts to identify obligations, deadlines, and renewal triggers.</p> <p>Intended user population: Qualified German lawyers (Rechtsanw\u00e4lte) operating within German law firms. The system is not intended for use by non-lawyers, legal assistants without lawyer supervision, or clients directly.</p> <p>Intended use context: The system operates as a professional support tool. It does not provide legal advice. All outputs require mandatory lawyer review before use. The responsible lawyer retains full professional responsibility for any advice given to the client.</p>"},{"location":"phase-2-worked-example/P2-Worked-Example-Technical-Documentation-v1/#13-what-the-system-is-not-intended-to-do","title":"1.3 What the System Is Not Intended To Do","text":"<ul> <li>Provide legal advice directly to clients</li> <li>Generate final client-deliverable documents without lawyer review</li> <li>Make autonomous decisions about contract acceptability</li> <li>Replace the professional judgment of the reviewing lawyer</li> <li>Operate without a qualified lawyer in the review loop</li> </ul>"},{"location":"phase-2-worked-example/P2-Worked-Example-Technical-Documentation-v1/#section-2-model-architecture-and-technical-design","title":"Section 2 \u2014 Model Architecture and Technical Design","text":""},{"location":"phase-2-worked-example/P2-Worked-Example-Technical-Documentation-v1/#21-architecture-overview","title":"2.1 Architecture Overview","text":"<p>Vertrag.AI is built on a retrieval-augmented generation (RAG) architecture combining a commercial large language model API with a curated legal knowledge base.</p> <pre><code>[Lawyer uploads contract DOCX]\n        |\n        v\n[Document Parser \u2014 extract text, structure, clause segmentation]\n        |\n        v\n[RAG Retrieval Layer \u2014 query German legal corpus for relevant standards/precedents]\n        |\n        v\n[Prompt Construction \u2014 system prompt + contract text + retrieved context]\n        |\n        v\n[LLM API Call \u2014 Claude claude-sonnet-4-20250514 via Anthropic API]\n        |\n        v\n[Output Parser \u2014 structure redline suggestions, assign clause references]\n        |\n        v\n[DOCX Generator \u2014 produce redlined contract document]\n        |\n        v\n[Lawyer review interface \u2014 accept / reject / modify each suggestion]\n        |\n        v\n[Final DOCX export \u2014 accepted changes only]\n</code></pre> <p>Assumption: Architecture is illustrative based on Anthropic's legal productivity GitHub examples adapted for German law context. Real system architecture to be confirmed and documented.</p>"},{"location":"phase-2-worked-example/P2-Worked-Example-Technical-Documentation-v1/#22-model-provider","title":"2.2 Model Provider","text":"Field Value Model provider Anthropic Model Claude (claude-sonnet-4-20250514 or equivalent at time of deployment) Access method Anthropic API Fine-tuning applied No \u2014 base model with structured prompting System prompt Yes \u2014 governs output format, task framing, and professional context <p>Assumption: Anthropic is the model provider. Data Processing Agreement with Anthropic required \u2014 flagged as Compliance Gap 6 in the EU AI Act Mapping document. Model selection and versioning policy to be confirmed.</p>"},{"location":"phase-2-worked-example/P2-Worked-Example-Technical-Documentation-v1/#23-rag-knowledge-base","title":"2.3 RAG Knowledge Base","text":"Field Value Knowledge base content German civil law standards, standard commercial contract terms, BGB provisions, common clause formulations Knowledge base format Indexed vector store Update frequency [To be confirmed \u2014 assumed quarterly] Curation responsibility [Legal content team \u2014 to be confirmed] Version control [To be confirmed] <p>Assumption: The RAG knowledge base is maintained by Pickles GmbH. Its composition, update cadence, and quality controls require documentation. This is a significant governance gap \u2014 knowledge base quality directly affects output accuracy.</p>"},{"location":"phase-2-worked-example/P2-Worked-Example-Technical-Documentation-v1/#24-hosting-and-infrastructure","title":"2.4 Hosting and Infrastructure","text":"Field Value Hosting provider [EU-based cloud provider \u2014 to be confirmed] Hosting region [EU \u2014 assumed, unconfirmed] Data residency [EU \u2014 assumed, unconfirmed] Multi-tenancy model Logical separation \u2014 dedicated data store per client organisation Authentication [SSO / MFA \u2014 to be confirmed] <p>Assumption: EU hosting assumed. This affects GDPR adequacy position and client data handling obligations. Must be confirmed before client-facing documentation is finalised.</p>"},{"location":"phase-2-worked-example/P2-Worked-Example-Technical-Documentation-v1/#section-3-training-data-and-knowledge-base","title":"Section 3 \u2014 Training Data and Knowledge Base","text":""},{"location":"phase-2-worked-example/P2-Worked-Example-Technical-Documentation-v1/#31-base-model-training-data","title":"3.1 Base Model Training Data","text":"<p>Vertrag.AI uses the Anthropic Claude base model without fine-tuning. Anthropic's model training data documentation governs this component. Pickles GmbH does not have direct visibility into base model training data composition.</p> <p>Implication: Pickles GmbH should maintain reference to Anthropic's published model cards and usage policies as part of its vendor documentation. Any changes to the underlying model (version updates, architecture changes) should trigger review under the Model Change Management Protocol.</p>"},{"location":"phase-2-worked-example/P2-Worked-Example-Technical-Documentation-v1/#32-rag-knowledge-base-provenance-and-curation","title":"3.2 RAG Knowledge Base \u2014 Provenance and Curation","text":"<p>The RAG knowledge base constitutes the primary domain-specific knowledge layer of the system. Its quality directly determines the relevance and accuracy of retrieved context used in generating redline suggestions.</p> Field Value Content categories BGB statutory text, standard AGB formulations, BRAK professional guidance, sector-specific contract templates Source types Official German legal publications, publicly available legal standards, internally curated precedent library Language German (primary), English (secondary for international contract review) Coverage scope Commercial contracts \u2014 M&amp;A, service agreements, supply chain, employment, real estate Exclusions Consumer contracts, regulatory matters, court filings Curation process [To be defined \u2014 legal content review before indexing] Quality controls [To be defined] <p>Assumption: Knowledge base composition is assumed. Formal curation policy, source documentation, and version control for the knowledge base are required governance artefacts. These do not currently exist (assumed).</p>"},{"location":"phase-2-worked-example/P2-Worked-Example-Technical-Documentation-v1/#33-known-data-gaps-and-limitations","title":"3.3 Known Data Gaps and Limitations","text":"<p>The following limitations are assumed to apply and should be confirmed and documented:</p> <ul> <li>Coverage of highly specialist contract types (e.g. joint ventures, complex financial instruments) may be incomplete</li> <li>Knowledge base reflects a point-in-time view \u2014 recently enacted legislation or case law may not be indexed</li> <li>English-language contracts may receive less accurate review due to German-corpus bias</li> <li>Non-standard contract structures may not retrieve well from the vector index</li> </ul>"},{"location":"phase-2-worked-example/P2-Worked-Example-Technical-Documentation-v1/#section-4-testing-and-validation-methodology","title":"Section 4 \u2014 Testing and Validation Methodology","text":""},{"location":"phase-2-worked-example/P2-Worked-Example-Technical-Documentation-v1/#41-pre-deployment-testing-requirements","title":"4.1 Pre-Deployment Testing Requirements","text":"<p>The following testing categories are required before any new version of Vertrag.AI is deployed to production. This section documents the required methodology; actual test results should be maintained as a separate test log.</p> <p>Assumption: Testing methodology described here is proposed. Actual test protocols to be designed and confirmed by the engineering team.</p>"},{"location":"phase-2-worked-example/P2-Worked-Example-Technical-Documentation-v1/#functional-accuracy-testing","title":"Functional Accuracy Testing","text":"Test type Description Pass criterion Clause identification accuracy Sample contracts with known issues reviewed; system output compared to lawyer-prepared baseline \u226585% of known issues identified False positive rate Clean contracts reviewed; count of spurious redline suggestions \u226415% of suggestions flagged as spurious by reviewing lawyers Citation accuracy BGB and legal standard references in system output checked against source texts 100% of cited provisions must exist and be correctly described Output format validation Redlined DOCX output verified for structural integrity 100% of outputs open correctly in Microsoft Word and LibreOffice"},{"location":"phase-2-worked-example/P2-Worked-Example-Technical-Documentation-v1/#adversarial-and-edge-case-testing","title":"Adversarial and Edge Case Testing","text":"Test type Description Unusual contract structures Non-standard formatting, missing clause headings, very long documents Mixed language contracts German/English bilingual contracts Contracts with deliberate errors Test whether system identifies genuine issues or generates noise Empty or corrupt inputs System behaviour on invalid file uploads"},{"location":"phase-2-worked-example/P2-Worked-Example-Technical-Documentation-v1/#human-review-bypass-testing","title":"Human Review Bypass Testing","text":"<p>Verify that the system architecture does not permit output to reach a client without passing through the lawyer review interface. This is a hard requirement \u2014 any pathway that bypasses mandatory review is a critical defect.</p>"},{"location":"phase-2-worked-example/P2-Worked-Example-Technical-Documentation-v1/#42-ongoing-quality-monitoring","title":"4.2 Ongoing Quality Monitoring","text":"<p>See <code>P2-Worked-Example-Monitoring-Entry-v1.md</code> for the live monitoring framework. Testing and monitoring should be treated as connected \u2014 monitoring data from production use should feed back into test case development.</p>"},{"location":"phase-2-worked-example/P2-Worked-Example-Technical-Documentation-v1/#43-model-change-retesting-requirements","title":"4.3 Model Change Retesting Requirements","text":"<p>When the underlying model version changes (e.g. Anthropic releases a new Claude version), the following minimum retesting is required before deployment:</p> <ul> <li>Full functional accuracy test suite</li> <li>Citation accuracy test</li> <li>Output format validation</li> <li>Sample comparison between old and new model output on the same test contracts</li> </ul>"},{"location":"phase-2-worked-example/P2-Worked-Example-Technical-Documentation-v1/#section-5-known-limitations-and-risk-controls","title":"Section 5 \u2014 Known Limitations and Risk Controls","text":""},{"location":"phase-2-worked-example/P2-Worked-Example-Technical-Documentation-v1/#51-known-limitations","title":"5.1 Known Limitations","text":"<p>The following limitations are inherent to the system design and must be disclosed to users as part of onboarding and within the product interface.</p> Limitation Description Mitigation Not legal advice System output is analytical assistance, not legal advice Mandatory disclosure in UI and terms of service Knowledge base currency RAG corpus reflects point-in-time legal landscape Knowledge base update cadence and version disclosure Hallucination risk LLM may generate plausible but incorrect legal references Mandatory lawyer review; citation spot-check functionality Coverage gaps Some specialist contract types underserved Scope disclosure in product documentation Language limitations German-primary; English and other languages less accurate Language scope disclosure No autonomous action System cannot execute, sign, or submit any document Architectural control \u2014 output is DOCX only"},{"location":"phase-2-worked-example/P2-Worked-Example-Technical-Documentation-v1/#52-hallucination-risk-specific-controls","title":"5.2 Hallucination Risk \u2014 Specific Controls","text":"<p>Hallucination (generation of false but plausible legal references) is the highest-consequence output risk for Vertrag.AI. The following controls apply:</p> <ul> <li>Mandatory lawyer review: Every output requires a qualified lawyer to review before any use. This is the primary control and must never be removed or made optional.</li> <li>Citation flagging: Where the system cites a specific BGB article, AGB standard, or other provision, the UI should provide a mechanism to verify the citation. Implementation of this feature is a compliance priority (Compliance Gap 5 from EU AI Act Mapping).</li> <li>Confidence indicators: Where the system has lower retrieval confidence, this should be surfaced to the reviewing lawyer. Implementation status: to be confirmed.</li> <li>User training: All firm users must complete onboarding covering hallucination risk and how to spot unreliable outputs.</li> </ul>"},{"location":"phase-2-worked-example/P2-Worked-Example-Technical-Documentation-v1/#53-professional-liability-boundary","title":"5.3 Professional Liability Boundary","text":"<p>Vertrag.AI operates in an environment where the reviewing lawyer retains full professional responsibility under BRAK rules and German professional liability law. The system does not assume, transfer, or share professional responsibility.</p> <p>This boundary must be maintained clearly in: - Terms of service with law firm clients - User interface disclosures - Training materials - Any client-facing documentation about the system</p>"},{"location":"phase-2-worked-example/P2-Worked-Example-Technical-Documentation-v1/#section-6-human-oversight-design","title":"Section 6 \u2014 Human Oversight Design","text":""},{"location":"phase-2-worked-example/P2-Worked-Example-Technical-Documentation-v1/#61-oversight-architecture","title":"6.1 Oversight Architecture","text":"<p>Human oversight is structural, not procedural \u2014 it is built into the system architecture so that lawyer review cannot be bypassed.</p> <pre><code>AI output \u2192 Staging layer (not client-deliverable)\n                    |\n                    v\n         Lawyer review interface\n         [Accept / Reject / Modify each suggestion]\n                    |\n                    v\n         Accepted output only \u2192 DOCX export\n                    |\n                    v\n         Lawyer applies professional judgment\n         before any client use\n</code></pre> <p>There is no pathway from AI output to client-deliverable document that does not pass through the lawyer review step.</p>"},{"location":"phase-2-worked-example/P2-Worked-Example-Technical-Documentation-v1/#62-mandatory-review-requirements","title":"6.2 Mandatory Review Requirements","text":"Requirement Implementation All suggestions must be individually reviewed Review interface requires explicit accept/reject/modify for each flagged clause Bulk acceptance without review is not permitted [To be confirmed \u2014 UI design requirement] Export requires review completion [To be confirmed \u2014 system gate before DOCX export] Reviewer identity is logged Audit log records which user reviewed and when <p>Assumption: UI design requirements listed here are intended design specifications. Confirmation of implementation required from engineering team.</p>"},{"location":"phase-2-worked-example/P2-Worked-Example-Technical-Documentation-v1/#63-user-qualification-requirements","title":"6.3 User Qualification Requirements","text":"<p>The system is restricted to qualified lawyers (Rechtsanw\u00e4lte). Access controls should enforce this:</p> <ul> <li>Firm-level onboarding confirms all users are qualified lawyers or supervised trainees with lawyer oversight</li> <li>User terms require disclosure if access is shared with unqualified personnel</li> <li>Account provisioning is via firm administrators, not individual sign-up</li> </ul> <p>Assumption: Access control model is assumed. Implementation details to be confirmed.</p>"},{"location":"phase-2-worked-example/P2-Worked-Example-Technical-Documentation-v1/#section-7-logging-and-traceability","title":"Section 7 \u2014 Logging and Traceability","text":""},{"location":"phase-2-worked-example/P2-Worked-Example-Technical-Documentation-v1/#71-audit-log-requirements","title":"7.1 Audit Log Requirements","text":"<p>The following events must be logged to support incident investigation, quality monitoring, and regulatory enquiry response.</p> Event Log content Retention Contract upload Session ID, user ID, firm ID, file hash (not file content), timestamp 24 months System query Session ID, timestamp, model version, RAG retrieval summary (not full prompt) 24 months Review action Session ID, user ID, each accept/reject/modify action, timestamp 24 months Export Session ID, user ID, timestamp, output file hash 24 months Error or exception Session ID, error type, timestamp 24 months Model version change Old version, new version, deployment timestamp, authorising user Indefinite <p>Assumption: Retention period of 24 months assumed as proportionate. GDPR Article 5(1)(e) storage limitation principle applies \u2014 retention must be justified by legitimate purpose. Legal review of retention periods recommended.</p>"},{"location":"phase-2-worked-example/P2-Worked-Example-Technical-Documentation-v1/#72-what-is-not-logged","title":"7.2 What Is Not Logged","text":"<p>The following must not be captured in system logs to comply with GDPR and confidentiality obligations:</p> <ul> <li>Full contract text uploaded by users</li> <li>Full system prompt content passed to the model</li> <li>Client names or matter details</li> <li>Any personal data beyond user ID and firm ID</li> <li>Legally privileged communications</li> </ul> <p>Note: This creates a tension with incident investigation capability. If a quality incident occurs, the absence of full prompt/contract logs limits root cause analysis. This tension is inherent to the GDPR/confidentiality constraints of the legal market and must be acknowledged in the incident response playbook.</p>"},{"location":"phase-2-worked-example/P2-Worked-Example-Technical-Documentation-v1/#73-traceability-for-output-review","title":"7.3 Traceability for Output Review","text":"<p>Each redline suggestion in the lawyer review interface should carry: - Reference to the retrieved RAG source(s) that informed the suggestion (at minimum: knowledge base category and retrieval score) - The specific contract clause to which the suggestion applies - The model version that generated the suggestion</p> <p>This supports lawyer review quality and provides traceability if a suggestion is later challenged.</p>"},{"location":"phase-2-worked-example/P2-Worked-Example-Technical-Documentation-v1/#section-8-gdpr-and-data-handling","title":"Section 8 \u2014 GDPR and Data Handling","text":""},{"location":"phase-2-worked-example/P2-Worked-Example-Technical-Documentation-v1/#81-personal-data-processing","title":"8.1 Personal Data Processing","text":"<p>Vertrag.AI processes the following categories of data:</p> Data category Nature Legal basis User account data Name, email, firm affiliation Contract (Article 6(1)(b) GDPR) Usage metadata Session logs, review actions Legitimate interests (Article 6(1)(f) GDPR) \u2014 subject to balancing test Uploaded contract content Potentially contains personal data about third parties Processor role \u2014 law firm is controller AI-generated output Redline suggestions \u2014 no personal data N/A <p>Assumption: Legal basis analysis is indicative. GDPR data protection impact assessment (DPIA) required given processing of potentially sensitive legal documents. Flagged as Compliance Gap 3 in EU AI Act Mapping.</p>"},{"location":"phase-2-worked-example/P2-Worked-Example-Technical-Documentation-v1/#82-sub-processor-anthropic","title":"8.2 Sub-Processor: Anthropic","text":"<p>All prompts sent to the Claude API are processed by Anthropic as a sub-processor. This has significant implications:</p> <ul> <li>Data Processing Agreement with Anthropic is required under GDPR Article 28</li> <li>Data transfer mechanisms for any processing outside the EU must be confirmed</li> <li>Anthropic's data retention and training data policies must be reviewed and documented</li> <li>Client-facing DPA with law firms must disclose Anthropic as a sub-processor</li> </ul> <p>Assumption: Anthropic sub-processor relationship assumed based on API usage. DPA status unconfirmed. This is Compliance Gap 6 in the EU AI Act Mapping \u2014 high priority.</p>"},{"location":"phase-2-worked-example/P2-Worked-Example-Technical-Documentation-v1/#83-law-firm-as-data-controller","title":"8.3 Law Firm as Data Controller","text":"<p>When a law firm uses Vertrag.AI to review contracts on behalf of its clients, the law firm is the data controller for any personal data within those contracts. Pickles GmbH acts as data processor.</p> <p>Implications: - Client contract (DPA) must be in place before any law firm can upload contracts - Law firms must have obtained appropriate authority from their clients to process contract data in a cloud AI system - Confidentiality obligations under BRAK rules apply to the law firm \u2014 Pickles GmbH's infrastructure must support confidentiality compliance</p>"},{"location":"phase-2-worked-example/P2-Worked-Example-Technical-Documentation-v1/#section-9-assumptions-register-this-document","title":"Section 9 \u2014 Assumptions Register (This Document)","text":"<p>The following assumptions are embedded in this document and require validation before this documentation is used operationally.</p> ID Assumption Section Priority TD-A-01 Anthropic Claude is the model provider 2.2 High TD-A-02 RAG architecture as described 2.1 High TD-A-03 EU-based hosting 2.4 High TD-A-04 No fine-tuning applied to base model 2.2 Medium TD-A-05 Knowledge base composition as described 3.2 High TD-A-06 Quarterly knowledge base update cadence 3.2 Low TD-A-07 Functional accuracy testing not yet conducted 4.1 High TD-A-08 Lawyer review UI prevents bulk acceptance 6.2 High TD-A-09 GDPR retention periods as specified 7.1 Medium TD-A-10 No DPA with Anthropic currently in place 8.2 High"},{"location":"phase-2-worked-example/P2-Worked-Example-Technical-Documentation-v1/#section-10-document-control-and-review-schedule","title":"Section 10 \u2014 Document Control and Review Schedule","text":"Field Value Document owner Compliance function Technical reviewer Head of Engineering Legal reviewer General Counsel / external German legal counsel Review trigger events Model version change; material architecture change; new use case; annual scheduled review Annual review date [Set on first deployment] Version history v1 \u2014 initial draft (2026-02-28) <p>Note: This document requires review by a qualified German lawyer and a data protection specialist before it is used as a compliance artefact. The current draft is a governance framework demonstration and contains assumptions throughout.</p> <p>End of P2-Worked-Example-Technical-Documentation-v1.md</p>"},{"location":"stage-1-regulatory-orientation/STAGE1-Regulatory-Orientation-Note-v1/","title":"Regulatory Orientation Note \u2014 Stage 1","text":"<p>Project: Pickles GmbH \u2014 AI Governance Framework Stage: Stage 1 \u2014 Regulatory Orientation Status: Draft Version: v1 Date: 2026-02-22 Assumptions: Built on outline assumptions \u2014 not verified against real Pickles GmbH data</p>"},{"location":"stage-1-regulatory-orientation/STAGE1-Regulatory-Orientation-Note-v1/#purpose-of-this-document","title":"Purpose of This Document","text":"<p>This note establishes the regulatory landscape applicable to Pickles GmbH [ASSUMPTION \u2014 A-003] as a provider of legal AI tools to German legal professionals. It extracts the obligations that the AI Governance &amp; Operational Architecture Framework must address, drawn directly from the source documents in <code>_input/</code>. It does not interpret or supplement those documents beyond what is stated in them.</p> <p>All provisions cited are traceable to source documents in <code>_input/</code>. Where a provision cannot be confirmed in source documents, it is flagged as [UNVERIFIED].</p>"},{"location":"stage-1-regulatory-orientation/STAGE1-Regulatory-Orientation-Note-v1/#1-eu-ai-act-classification-of-legal-ai-systems","title":"1. EU AI Act: Classification of Legal AI Systems","text":"<p>Source: Regulation (EU) 2024/1689 of 13 June 2024 (EU AI Act), as read from <code>_input/EU-AI-Act-full-text.pdf</code></p>"},{"location":"stage-1-regulatory-orientation/STAGE1-Regulatory-Orientation-Note-v1/#11-risk-classification-framework","title":"1.1 Risk Classification Framework","text":"<p>The EU AI Act establishes a risk-based hierarchy with four tiers:</p> Tier Status Consequence Prohibited AI Article 5 Cannot be placed on market. Examples: real-time biometric identification for law enforcement in public spaces; social scoring; manipulation techniques. High-Risk AI Articles 6 + Annex III Mandatory pre-market requirements: documentation, conformity assessment, human oversight, logging. Limited-Risk AI Article 50 Transparency obligations only \u2014 disclosure when interacting with natural persons. Minimal Risk General Voluntary self-regulation only."},{"location":"stage-1-regulatory-orientation/STAGE1-Regulatory-Orientation-Note-v1/#12-classification-of-legal-ai-systems","title":"1.2 Classification of Legal AI Systems","text":"<p>The EU AI Act explicitly addresses AI in legal and judicial contexts.</p> <p>Recital 61 identifies AI systems intended for use by judicial authorities (or on their behalf) for: - Assisting with fact-finding - Legal research - Prediction of legal outcomes applied to a concrete set of facts</p> <p>...as high-risk when their outputs are used in the administration of law.</p> <p>Exception: Systems performing ancillary administrative functions (pseudonymisation, document management) are not classified as high-risk under Recital 61.</p> <p>Application to Pickles GmbH [ASSUMPTION \u2014 A-001]:</p> Use Case Likely Classification Rationale Legal drafting assistance Unclear Ancillary if tool only suggests; potentially high-risk if applied to specific facts to produce binding drafts Legal research assistance Likely ancillary / lower risk Research support without autonomous conclusions Summarisation Likely ancillary / lower risk Unless summaries applied to specific facts in decision-making Legal analysis applied to specific client facts Likely high-risk AI analysis applied to specific facts \u2014 Recital 61 <p>[LEGAL REVIEW REQUIRED] The boundary between ancillary and high-risk for legal AI tools depends on actual deployment context. A qualified lawyer must review the application of Recital 61 and Annex III to Pickles GmbH's specific product capabilities before the risk classification is finalised.</p> <p>Key classification principle (Recital 53): An AI system \"does not necessarily influence the outcome of decision-making should be understood to be an AI system that does not have an impact on the substance, and therefore the outcome, of decision-making.\"</p>"},{"location":"stage-1-regulatory-orientation/STAGE1-Regulatory-Orientation-Note-v1/#13-key-obligations-for-high-risk-ai-system-providers","title":"1.3 Key Obligations for High-Risk AI System Providers","text":"<p>Where Pickles GmbH's systems are classified as high-risk, the following obligations apply:</p> <p>Technical Documentation (Article 11): - System description and intended purpose - Data and development methodology - Training, validation, and testing methodology - Performance assessment and known limitations - Human oversight design - Logging and automatic recording capabilities</p> <p>Risk Management (Article 9): - Continuous, iterative risk management process across the full system lifecycle - Identify and document foreseeable misuse scenarios - Identify risks of errors, bias, and discrimination - Implement and document risk mitigation measures - Review and update regularly</p> <p>Data Quality and Governance (Article 10): - Training, validation, and test data must be relevant, representative, free of errors, and complete - Statistical properties must be appropriate for the system's intended use - Data must be assessed for bias and potential for discriminatory outcomes - Data minimisation required</p> <p>Human Oversight (Article 14): - High-risk systems must be designed to allow human override at all times - Human reviewers must have the competence, training, and authority to intervene - Fully automated legal decisions without human review are incompatible with high-risk classification requirements - Recital 91: Deployers must ensure humans overseeing high-risk systems are competent to do so</p> <p>Transparency and Information (Article 13): - Instructions for use must be clear, comprehensive, and accessible - Characteristics, capabilities, and limitations must be documented for deployers</p> <p>Logging and Traceability (Article 12): - High-risk systems must automatically record events throughout their operational lifetime</p> <p>Quality Management and Post-Market Monitoring (Articles 17 and 72): - Providers must maintain a sound quality management system - Post-market monitoring must track system performance throughout its lifecycle and report serious incidents to market surveillance authorities</p>"},{"location":"stage-1-regulatory-orientation/STAGE1-Regulatory-Orientation-Note-v1/#14-transparency-obligations-ai-systems-interacting-with-humans-article-50","title":"1.4 Transparency Obligations \u2014 AI Systems Interacting with Humans (Article 50)","text":"<p>Even where an AI system is not classified as high-risk, Article 50 requires: - Users must be informed they are interacting with an AI system - Clear disclosure of circumstances and context of use - Where AI generates synthetic text, users must be clearly informed the content is AI-generated (exceptions: satirical, artistic, or analogous work with appropriate safeguards; and where content has been subject to human review and editorial responsibility \u2014 Recital 132-133)</p> <p>[ASSUMPTION \u2014 A-006] It is assumed that Pickles GmbH's products include interfaces through which legal professionals interact directly with the AI system. This assumption must be verified before Article 50 obligations are mapped to specific product features.</p> <p>EU AI Act Article 50 (effective 2 August 2026): Providers of AI systems interacting with natural persons (e.g., legal chatbots) must: - Inform users they are interacting with AI (Article 50(1)) - Label AI-generated content as AI-generated (Article 50(2), (5))</p>"},{"location":"stage-1-regulatory-orientation/STAGE1-Regulatory-Orientation-Note-v1/#15-conformity-assessment-requirements-articles-16-23","title":"1.5 Conformity Assessment Requirements (Articles 16-23)","text":"<p>For high-risk AI systems, providers must: - Perform conformity assessment before market placement - Maintain all required documentation - Draw up a Declaration of Conformity - Affix CE marking - Establish and maintain a quality management system</p> <p>Conformity assessment procedures (Articles 43(1) and 43(2)): For high-risk AI systems listed in Annex III point 1, or where applicable harmonised standards are absent, conformity assessment requires involvement of a notified body (Article 43(1)). For high-risk AI systems listed in Annex III points 2\u20138, the conformity assessment procedure is based on internal control, which does not require the involvement of a notified body (Article 43(2)). [LEGAL REVIEW REQUIRED \u2014 the applicable procedure depends on the specific Annex III classification of each system]</p> <p>Substantial modification (Article 3): Changes that affect compliance with high-risk requirements require a new conformity assessment. Providers must track all changes that could constitute a substantial modification.</p>"},{"location":"stage-1-regulatory-orientation/STAGE1-Regulatory-Orientation-Note-v1/#16-ai-competence-obligation-article-4-effective-2-february-2025","title":"1.6 AI Competence Obligation (Article 4 \u2014 Effective 2 February 2025)","text":"<p>Providers and operators must take measures to ensure staff involved in the operation and use of AI systems have sufficient AI competence, taking into account technical knowledge, experience, education, and training in context. This obligation has been in force since 2 February 2025.</p>"},{"location":"stage-1-regulatory-orientation/STAGE1-Regulatory-Orientation-Note-v1/#2-gdpr-key-obligations-for-a-legal-ai-provider","title":"2. GDPR: Key Obligations for a Legal AI Provider","text":"<p>Source: Regulation (EU) 2016/679 (GDPR), as read from <code>_input/GDPR-full-text.pdf</code></p>"},{"location":"stage-1-regulatory-orientation/STAGE1-Regulatory-Orientation-Note-v1/#21-processing-principles-article-5","title":"2.1 Processing Principles (Article 5)","text":"<p>All personal data processing by Pickles GmbH must comply with Article 5:</p> Principle Requirement Lawfulness, fairness, transparency Processing must have a valid legal basis (Article 6); data subjects must be informed Purpose limitation Data collected for specified, explicit, legitimate purposes; not further processed incompatibly Data minimisation Only data adequate, relevant, and limited to what is necessary Accuracy Data must be accurate; inaccurate data erased or rectified without delay Storage limitation Kept no longer than necessary for the purpose Integrity and confidentiality Appropriate security against unauthorised access, loss, destruction, or damage Accountability Controller must be able to demonstrate compliance with all of the above <p>Lawful bases for processing (Article 6): One of the following must apply: (a) consent; (b) contract; (c) legal obligation; (d) vital interests; (e) public task; (f) legitimate interests.</p>"},{"location":"stage-1-regulatory-orientation/STAGE1-Regulatory-Orientation-Note-v1/#22-article-28-processor-obligations","title":"2.2 Article 28 \u2014 Processor Obligations","text":"<p>[ASSUMPTION \u2014 A-007] It is assumed that Pickles GmbH will act as a data processor on behalf of its lawyer clients (the data controllers) when processing personal data contained in legal documents. This structural assumption is fundamental to the governance framework and must be verified.</p> <p>[LEGAL REVIEW REQUIRED] Whether Pickles GmbH acts as a processor, joint controller, or independent controller for specific processing activities must be assessed by a qualified lawyer. This determines the structure of all client contracts and the legal basis for processing.</p> <p>If Pickles GmbH is a processor, Article 28 requires:</p> <p>Controller selection duty (Article 28(1)): Controllers may only use processors that provide sufficient guarantees to implement appropriate technical and organisational measures ensuring GDPR compliance.</p> <p>Processor obligations (Article 28(3)): Processing must be governed by a written contract (the Data Processing Agreement \u2014 DPA) stipulating that Pickles GmbH as processor shall:</p> <ul> <li>(a) Process personal data only on documented instructions from the controller, including with regard to international transfers</li> <li>(b) Ensure persons authorised to process personal data are bound by confidentiality</li> <li>(c) Take all security measures required by Article 32</li> <li>(d) Respect conditions for engaging sub-processors (Article 28(2) \u2014 prior specific or general written authorisation from the controller; sub-processors subject to same obligations by contract)</li> <li>(e) Assist the controller in responding to data subject rights requests (Articles 15-22)</li> <li>(f) Assist the controller in obligations under Articles 32-36 (security, breach notification, DPIA, prior consultation)</li> <li>(g) Delete or return all personal data at the end of services; delete existing copies unless Union or Member State law requires otherwise</li> <li>(h) Make available all information necessary to demonstrate compliance; allow for and contribute to audits, including inspections, conducted by the controller or auditor mandated by the controller</li> <li>Notify the controller immediately if any instruction infringes GDPR (Article 28(3), final paragraph)</li> </ul> <p>DPA form (Article 28(9)): The contract must be in writing, including in electronic form.</p> <p>Sub-processor liability (Article 28(4)): Where Pickles GmbH engages a sub-processor (e.g., a third-party AI model provider), the same data protection obligations must be imposed by contract. Pickles GmbH remains fully liable to the controller for the sub-processor's performance.</p> <p>Standard Contractual Clauses (Article 28(6)-(8)): DPAs may be based on Commission or supervisory authority-approved SCCs.</p>"},{"location":"stage-1-regulatory-orientation/STAGE1-Regulatory-Orientation-Note-v1/#23-chapter-iii-rights-of-data-subjects-articles-12-23","title":"2.3 Chapter III \u2014 Rights of Data Subjects (Articles 12-23)","text":"<p>Where Pickles GmbH processes personal data of individuals named in legal documents, the following rights must be supported:</p> Article Right Key Content Art. 12 Modalities Respond concisely, transparently, intelligibly; free of charge; within 1 month (extendable by 2 months for complexity) Art. 13 Information (data from subject) At point of collection: controller identity, DPO contact, purposes, legal basis, recipients, retention, rights, and existence of automated decision-making (Art. 13(2)(f)) Art. 14 Information (data not from subject) Within 1 month: same information plus source of data. Exception: Art. 14(5)(d) \u2014 does not apply where professional secrecy obligation applies under Union or Member State law Art. 15 Access Right to confirmation of processing and copy of personal data Art. 16 Rectification Right to correction of inaccurate data without undue delay Art. 17 Erasure Right to deletion where: no longer necessary; consent withdrawn; objection upheld; unlawful processing; legal obligation to erase. Exceptions: freedom of expression; legal obligation; legal claims (Art. 17(3)) Art. 18 Restriction Right to restrict processing where accuracy contested; processing unlawful and data subject opposes erasure; data needed for legal claims; objection pending Art. 19 Notification Controller must notify each recipient of rectification, erasure, or restriction; inform data subject of recipients on request Art. 20 Portability Right to receive data in structured, machine-readable format where basis is consent or contract and processing is automated Art. 21 Right to object Right to object to processing based on legitimate interests (Art. 6(1)(f)); absolute right to object to direct marketing including profiling Art. 22 Automated decision-making See Section 2.4 below Art. 23 Restrictions Member States may restrict these rights by law for specified purposes (national security, defence, criminal proceedings, etc.) <p>Professional secrecy note: Article 14(5)(d) provides that the obligation to provide information under Article 14 does not apply where personal data must remain confidential subject to an obligation of professional secrecy regulated by Union or Member State law. This is directly relevant in the legal context, where lawyer-client confidentiality may restrict transparency obligations.</p>"},{"location":"stage-1-regulatory-orientation/STAGE1-Regulatory-Orientation-Note-v1/#24-article-22-automated-individual-decision-making-including-profiling","title":"2.4 Article 22 \u2014 Automated Individual Decision-Making, Including Profiling","text":"<p>Core right (Article 22(1)): Data subjects have the right not to be subject to a decision based solely on automated processing \u2014 including profiling \u2014 which produces legal effects concerning them or similarly significantly affects them.</p> <p>Exceptions (Article 22(2)): The right does not apply where the decision: - (a) Is necessary for entering into or performance of a contract - (b) Is authorised by Union or Member State law with appropriate safeguards - (c) Is based on the data subject's explicit consent</p> <p>Safeguards mandatory in exceptions (a) and (c) (Article 22(3)): - Right to obtain human intervention on the part of the controller - Right to express the data subject's point of view - Right to contest the decision</p> <p>Special categories prohibition (Article 22(4)): Automated decisions must not be based on special categories of data (Article 9(1)) unless Article 9(2)(a) or (g) applies and suitable safeguards are in place.</p> <p>Application to legal AI [ASSUMPTION \u2014 A-001, A-007]: If Pickles GmbH's systems generate analysis or recommendations that are adopted without human review to produce decisions with legal effects on individuals, Article 22 is triggered. This reinforces the human oversight obligation under EU AI Act Article 14 and BRAK professional conduct rules.</p>"},{"location":"stage-1-regulatory-orientation/STAGE1-Regulatory-Orientation-Note-v1/#25-article-25-data-protection-by-design-and-by-default","title":"2.5 Article 25 \u2014 Data Protection by Design and by Default","text":"<p>By design (Article 25(1)): At the time of determining the means of processing and at the time of processing itself, controllers must implement appropriate technical and organisational measures \u2014 such as pseudonymisation \u2014 to implement data protection principles effectively and integrate necessary safeguards.</p> <p>By default (Article 25(2)): By default, only personal data necessary for each specific purpose must be processed. This obligation applies to amount of data collected, extent of processing, storage period, and accessibility.</p>"},{"location":"stage-1-regulatory-orientation/STAGE1-Regulatory-Orientation-Note-v1/#26-article-32-security-of-processing","title":"2.6 Article 32 \u2014 Security of Processing","text":"<p>Controllers and processors must implement appropriate technical and organisational measures ensuring security appropriate to the risk, including as appropriate:</p> <ul> <li>(a) Pseudonymisation and encryption of personal data</li> <li>(b) Ability to ensure ongoing confidentiality, integrity, availability, and resilience of processing systems and services</li> <li>(c) Ability to restore availability and access to personal data in a timely manner in the event of a physical or technical incident</li> <li>(d) A process for regularly testing, assessing, and evaluating the effectiveness of technical and organisational security measures</li> </ul> <p>Risk assessment basis (Article 32(2)): Security risk includes accidental or unlawful destruction, loss, alteration, unauthorised disclosure of, or access to personal data transmitted, stored, or otherwise processed.</p> <p>Staff access controls (Article 32(4)): Any person acting under the authority of the controller or processor with access to personal data must not process them except on instructions from the controller.</p>"},{"location":"stage-1-regulatory-orientation/STAGE1-Regulatory-Orientation-Note-v1/#27-article-35-data-protection-impact-assessment","title":"2.7 Article 35 \u2014 Data Protection Impact Assessment","text":"<p>Trigger (Article 35(1)): Where a type of processing \u2014 particularly using new technologies \u2014 is likely to result in a high risk to the rights and freedoms of natural persons, a DPIA must be carried out prior to processing. A single assessment may address a set of similar processing operations presenting similar high risks.</p> <p>Mandatory DPIA triggers (Article 35(3)): - (a) Systematic and extensive evaluation of personal aspects based on automated processing, including profiling, on which decisions producing legal effects or similarly significantly affecting persons are made - (b) Processing on a large scale of special categories of data (Article 9(1)) or personal data relating to criminal convictions (Article 10) - (c) Systematic monitoring of a publicly accessible area on a large scale</p> <p>[ASSUMPTION \u2014 A-001, A-007] Pickles GmbH's systems likely trigger Article 35(3)(a) if they perform automated analysis of personal data to produce legal analysis or recommendations, and Article 35(3)(b) if they process special categories of data within legal documents. A DPIA is therefore likely mandatory before deployment of any legal AI system that processes personal data.</p> <p>DPIA must contain at minimum (Article 35(7)): - (a) Systematic description of envisaged processing operations and purposes, including the legitimate interest pursued by the controller where applicable - (b) Assessment of the necessity and proportionality of the processing operations in relation to the purposes - (c) Assessment of the risks to the rights and freedoms of data subjects - (d) Measures envisaged to address the risks, including safeguards, security measures, and mechanisms to ensure protection of personal data and demonstrate compliance</p> <p>DPO involvement (Article 35(2)): The controller must seek the advice of the DPO when carrying out a DPIA.</p> <p>Review requirement (Article 35(11)): Controller must carry out a review at least when there is a change in the risk represented by processing operations.</p> <p>Prior consultation (Article 36): Where a DPIA indicates that processing would result in high risk in the absence of mitigation measures, the controller must consult the supervisory authority prior to processing. The supervisory authority has up to eight weeks (extendable by six weeks for complex cases) to provide written advice. Consultation is required with the following information: responsibilities of all parties; purposes and means of intended processing; measures and safeguards to protect data subjects; DPO contact details; and the DPIA itself.</p>"},{"location":"stage-1-regulatory-orientation/STAGE1-Regulatory-Orientation-Note-v1/#28-international-data-transfers-articles-44-49","title":"2.8 International Data Transfers (Articles 44-49)","text":"<p>General principle (Article 44): All transfers of personal data to third countries or international organisations may take place only if Chapter V conditions are complied with \u2014 including onward transfers.</p> <p>[ASSUMPTION \u2014 A-004, A-005] If Pickles GmbH uses third-party AI model providers based outside the EU/EEA, or if data is processed on servers outside the EU/EEA, these transfer provisions apply.</p> <p>Transfer mechanisms in order of preference:</p> Mechanism Article Notes Adequacy decision Art. 45 Commission decision that third country ensures adequate protection \u2014 no further authorisation required Standard Contractual Clauses (SCCs) Art. 46(2)(c)-(d) Commission or supervisory authority-approved SCCs \u2014 no further authorisation required Binding Corporate Rules (BCRs) Art. 47 For intra-group transfers within a corporate group Approved code of conduct + binding commitments Art. 46(2)(e) Approved certification mechanism + binding commitments Art. 46(2)(f) Derogations Art. 49 Exceptions only: consent, contract performance, important public interest, legal claims, vital interests <p>Key risk for US-based AI providers: The EU-US Data Privacy Framework provides a current adequacy mechanism for certified US organisations. Providers not certified under this framework require SCCs.</p>"},{"location":"stage-1-regulatory-orientation/STAGE1-Regulatory-Orientation-Note-v1/#3-bdsg-german-law-overlay-on-gdpr","title":"3. BDSG: German Law Overlay on GDPR","text":"<p>Source: BDSG (German Federal Data Protection Act), as read from <code>_input/BDSG-German-Federal-Data-Protection-Act-EN.pdf</code></p>"},{"location":"stage-1-regulatory-orientation/STAGE1-Regulatory-Orientation-Note-v1/#31-application","title":"3.1 Application","text":"<p>Sections 1(4) and 1(7) BDSG: BDSG applies to controllers and processors processing personal data in Germany or in the context of a German establishment. Where GDPR applies directly, BDSG provisions apply only where GDPR does not conclusively govern the matter. BDSG fills gaps and provides German-specific implementation.</p> <p>Section 2 BDSG: Pickles GmbH as a private legal entity is a \"private body\" for BDSG purposes.</p>"},{"location":"stage-1-regulatory-orientation/STAGE1-Regulatory-Orientation-Note-v1/#32-mandatory-dpo-designation-section-38-bdsg","title":"3.2 Mandatory DPO Designation (Section 38 BDSG)","text":"<p>Section 38(1) BDSG: A DPO must be designated if the controller or processor consistently employs at least 20 persons dealing with automated processing of personal data. This threshold is lower than GDPR Article 37, which focuses on large-scale or systematic monitoring.</p> <p>Additionally, Section 38(1) BDSG requires a DPO where the controller undertakes processing subject to DPIA under GDPR Article 35, regardless of staff count.</p> <p>[ASSUMPTION \u2014 A-008] Whether Pickles GmbH meets the 20-person threshold is unverified. If it does, DPO designation is mandatory under BDSG Section 38.</p> <p>DPO tasks (Section 7 BDSG): In addition to GDPR tasks, the DPO must monitor compliance with both GDPR and BDSG provisions and advise on DPIAs under Section 67 BDSG.</p>"},{"location":"stage-1-regulatory-orientation/STAGE1-Regulatory-Orientation-Note-v1/#33-automated-decision-making-bdsg-overlay","title":"3.3 Automated Decision-Making \u2014 BDSG Overlay","text":"<p>Section 37 BDSG: The GDPR Article 22(1) right not to be subject to automated decisions does not apply in the context of certain insurance contract services.</p> <p>Section 54 BDSG (law enforcement context): Decisions based solely on automated processing producing adverse legal effects shall be permitted only if authorised by law. Profiling resulting in discrimination against natural persons is prohibited.</p>"},{"location":"stage-1-regulatory-orientation/STAGE1-Regulatory-Orientation-Note-v1/#34-data-subject-rights-professional-confidentiality-modifications","title":"3.4 Data Subject Rights \u2014 Professional Confidentiality Modifications","text":"<p>Section 29 BDSG: The right of access (GDPR Article 15) and transparency obligations (GDPR Article 14) do not apply where disclosure would breach the legitimate interests of a third party, including professional confidentiality obligations. This directly reinforces the Anwaltgeheimnis (attorney-client privilege) requirements described in Section 5 below.</p>"},{"location":"stage-1-regulatory-orientation/STAGE1-Regulatory-Orientation-Note-v1/#35-dpia-and-prior-consultation-with-bfdi","title":"3.5 DPIA and Prior Consultation with BfDI","text":"<p>Section 67 BDSG: Where processing using new technologies is likely to result in a substantial risk to the legally protected interests of data subjects, a DPIA is mandatory prior to processing. This applies independently of the GDPR Article 35 trigger.</p> <p>Section 69 BDSG: Prior consultation with the BfDI (Federal Commissioner for Data Protection and Freedom of Information) is required before processing commences if: - DPIA indicates substantial risk that the controller cannot sufficiently mitigate; or - Processing using new technologies or mechanisms involves substantial risk to legally protected interests</p> <p>BfDI response time (Section 69(3) BDSG): The BfDI has up to six weeks to provide written advice (extendable by one month for especially complex processing). If processing is especially urgent, it may commence after consultation begins but before the period expires \u2014 BfDI recommendations must then be applied retroactively (Section 69(4)).</p> <p>[LEGAL REVIEW REQUIRED] This prior consultation obligation applies to all new legal AI systems deployed by Pickles GmbH that involve substantial risk. The BfDI consultation process should be initiated at the design stage, not after deployment.</p>"},{"location":"stage-1-regulatory-orientation/STAGE1-Regulatory-Orientation-Note-v1/#36-technical-and-organisational-security-controls-section-64-bdsg","title":"3.6 Technical and Organisational Security Controls (Section 64 BDSG)","text":"<p>Section 64 BDSG requires the following specific controls for automated processing systems:</p> Control Type Requirement Equipment access control Deny unauthorised persons access to processing equipment Data media control Prevent unauthorised reading, copying, modification, or erasure of data media Storage control Prevent unauthorised input, inspection, modification, or deletion of stored personal data User control Prevent use of automated processing systems by unauthorised persons Data access control Ensure authorised users access only personal data covered by their authorisation Input control Verify and establish who input personal data, and when Transport control Ensure confidentiality and integrity during transfer of personal data Recovery Ensure installed systems can be restored in case of interruption Reliability Ensure all system functions perform and faults are reported Integrity Ensure stored personal data cannot be corrupted by system malfunction Processing control Ensure personal data processed on behalf of controller is processed only per controller instructions Availability control Ensure personal data is protected against loss and destruction Separability Ensure personal data collected for different purposes can be processed separately"},{"location":"stage-1-regulatory-orientation/STAGE1-Regulatory-Orientation-Note-v1/#37-mandatory-audit-logging-section-76-bdsg","title":"3.7 Mandatory Audit Logging (Section 76 BDSG)","text":"<p>Controllers and processors must provide logs for at minimum the following operations in automated processing systems: 1. Collection 2. Alteration 3. Consultation 4. Disclosure (including transfers) 5. Combination 6. Erasure</p> <p>Logs of consultation and disclosure must record: justification; date and time; and, as far as possible, the identity of the person consulting or disclosing data and the identity of recipients.</p> <p>Permitted uses (Section 76 BDSG): Logs may only be used by the DPO, BfDI, or data subject to verify lawfulness of processing.</p> <p>Retention: Log data must be erased at the end of the year following the year in which they were generated.</p>"},{"location":"stage-1-regulatory-orientation/STAGE1-Regulatory-Orientation-Note-v1/#38-enforcement-and-penalties","title":"3.8 Enforcement and Penalties","text":"<p>Section 42 BDSG: Deliberate, unauthorised transfer of personal data of large numbers of people for commercial purposes \u2014 up to three years' imprisonment or a fine.</p> <p>Section 43 BDSG: Administrative fines of up to \u20ac50,000 for specific BDSG violations. These are in addition to GDPR Article 83 fines (up to \u20ac20 million or 4% of global annual turnover for GDPR violations).</p> <p>Section 83 BDSG: Compensation liability for data subjects where personal data is processed in violation of BDSG or applicable law.</p> <p>Supervisory authority (Sections 8-9, 40 BDSG): BfDI supervises federal public bodies and certain private bodies. The Landesbeh\u00f6rden (state data protection authorities) supervise private bodies. If Pickles GmbH is headquartered in Germany, the competent Landesbeh\u00f6rde is the primary supervisory authority for GDPR purposes (one-stop-shop mechanism).</p>"},{"location":"stage-1-regulatory-orientation/STAGE1-Regulatory-Orientation-Note-v1/#4-edpb-guidelines-052020-consent-under-gdpr","title":"4. EDPB Guidelines 05/2020 \u2014 Consent Under GDPR","text":"<p>Source: EDPB Guidelines 05/2020 on Consent under Regulation 2016/679 (v1.1, adopted 4 May 2020), as read from <code>_input/EDPB-Guidelines-05-2020-consent.pdf</code></p> <p>Scope clarification: These Guidelines address consent as a lawful basis for data processing under GDPR Article 4(11) and Article 7. They are not guidance on automated decision-making. The project specification references \"EDPB Guidelines 05/2020 implications for automated decision-making in legal context\" \u2014 however, the document in <code>_input/</code> is exclusively about consent. The dedicated guidelines on automated decision-making are WP29 Guidelines on Automated Decision-Making and Profiling (WP251 rev.01, October 2017), which are referenced within Guidelines 05/2020 (Paragraph 92) but were not included in <code>_input/</code>. [UNVERIFIED \u2014 WP251 provisions not confirmed from source documents.]</p> <p>The following consent provisions are relevant to Pickles GmbH.</p>"},{"location":"stage-1-regulatory-orientation/STAGE1-Regulatory-Orientation-Note-v1/#41-requirements-for-valid-consent","title":"4.1 Requirements for Valid Consent","text":"<p>Where Pickles GmbH or its lawyer clients rely on consent as a lawful basis for any processing, consent must meet all four requirements:</p> <p>Freely given (Paragraphs 13-24): - Real choice and control for the data subject - Power imbalances create a presumption that consent is not freely given (Para. 16) - Consent bundled with service terms is presumptively invalid unless separate consent is also offered (Para. 26-31)</p> <p>Specific (Paragraphs 55-61): - Must relate to one or more specific, identified purposes - Separate consent required for each distinct purpose; granularity is required (Para. 42-45) - Purpose must be described in clear, plain language \u2014 not technical jargon (Para. 56)</p> <p>Informed (Paragraphs 62-74): Minimum information required at the point of consent (Paragraph 64): - (i) Identity of the controller - (ii) Purpose of each processing operation - (iii) Types of data collected and used - (iv) Right to withdraw consent - (v) Information about the use of data for automated decision-making, including profiling, in accordance with Article 22(2)(c) \u2014 where relevant - (vi) Risks of data transfers to third countries due to absence of adequacy decision or safeguards</p> <p>Unambiguous (Paragraphs 75-90): - Must be by a statement or clear affirmative action (Para. 76) - Pre-ticked opt-in boxes = not valid consent (Para. 81) - Silence, inactivity, scrolling, or swiping = not valid consent (Para. 86) - Consent must be given before processing begins (Para. 90)</p>"},{"location":"stage-1-regulatory-orientation/STAGE1-Regulatory-Orientation-Note-v1/#42-demonstrating-and-managing-consent","title":"4.2 Demonstrating and Managing Consent","text":"<p>Demonstrability (Article 7(1); Paragraphs 104-111): Controllers must prove that valid consent was obtained. Documentary records of consent statements and the consent workflow must be maintained. Records must be linked to the specific processing activity.</p> <p>Withdrawal (Article 7(3); Paragraphs 112-120): Consent must be withdrawable as easily as it was given. Withdrawal does not affect the lawfulness of prior processing. If processing is to continue after withdrawal, another lawful basis must be identified in advance.</p> <p>Lawful basis switching (Paragraphs 121-123): Controllers cannot switch from consent to another lawful basis after consent is withdrawn.</p>"},{"location":"stage-1-regulatory-orientation/STAGE1-Regulatory-Orientation-Note-v1/#43-implications-for-legal-ai","title":"4.3 Implications for Legal AI","text":"<ul> <li>If consent is used as the lawful basis for any AI processing, all of the above standards must be met</li> <li>Disclosure of automated decision-making (Para. 64(v)) is mandatory in consent notices where processing involves Article 22 profiling or automated decisions</li> <li>GDPR Article 5 data protection principles apply even where consent is validly obtained</li> </ul>"},{"location":"stage-1-regulatory-orientation/STAGE1-Regulatory-Orientation-Note-v1/#5-brak-position-paper-ai-in-legal-practice","title":"5. BRAK Position Paper \u2014 AI in Legal Practice","text":"<p>Source: BRAK, \"Notes on the Use of Artificial Intelligence in Legal Practice\" (December 2024), as read from <code>_input/BRAK-AI-position-paper en-GB.pdf</code></p>"},{"location":"stage-1-regulatory-orientation/STAGE1-Regulatory-Orientation-Note-v1/#51-braks-overall-position","title":"5.1 BRAK's Overall Position","text":"<p>BRAK acknowledges efficiency gains from legal AI tools but establishes that \"the use of AI does not release lawyers from their duty to provide legal advice to clients and represent their interests independently and on their own responsibility.\"</p> <p>Core principle: \"AI systems should only be used to support a solicitor's work and must not replace it.\" (BRAK Position Paper, Section 2.1)</p> <p>These obligations bind lawyers using Pickles GmbH's tools. As the tool provider, Pickles GmbH must design its systems to support \u2014 not undermine \u2014 compliance with these obligations.</p>"},{"location":"stage-1-regulatory-orientation/STAGE1-Regulatory-Orientation-Note-v1/#52-professional-duty-obligations","title":"5.2 Professional Duty Obligations","text":"<p>Mandatory independent review (Section 2.1; Section 43(1) BRAO): \"In any case, independent review and final inspection of AI results by the solicitor is required.\" This applies to all AI outputs: drafting, research, analysis, and summarisation. [ASSUMPTION \u2014 A-001]</p> <p>No replacement of lawyer judgment (Section 2.1): AI systems must support the lawyer's professional judgment. Systems that imply legal review is unnecessary are non-compliant with professional conduct rules.</p> <p>Heightened duty of care for client-facing use (Section 2.2): Where AI is used in client-facing interactions \u2014 chatbots, auto-responders, client intake automation \u2014 \"a higher standard of due diligence applies.\" It \"must not be implied that legal review and advice are not necessary in individual cases.\"</p> <p>No mandatory obligation to use AI (Section 2.3): BRAO and BORA do not currently require lawyers to use AI tools, though the law firm obligation under Section 5 BORA (maintaining necessary organisational resources) may require AI use for mass proceedings.</p>"},{"location":"stage-1-regulatory-orientation/STAGE1-Regulatory-Orientation-Note-v1/#53-attorney-client-privilege-anwaltgeheimnis","title":"5.3 Attorney-Client Privilege \u2014 Anwaltgeheimnis","text":"<p>Legal basis (Section 43a(2) BRAO): Attorney-client privilege covers all information obtained in the course of a mandate, including client identity and the fact that a mandate has been granted. Post-mandate obligations continue under Section 2(1) BORA. Unauthorised disclosure is a criminal offence under Section 203(1)(3) StGB.</p> <p>Scope: \"Since, in principle, 'everything' from a mandate is covered, the names of clients and the fact that a mandate has been granted at all are also covered by the duty of confidentiality.\" (Section 3, BRAK Position Paper)</p> <p>Practical obligations for legal AI use (Sections 3.1-3.2): - Only abstract prompts that do not allow identification of a specific mandate should be used where possible - Documents uploaded must be fully anonymised before upload where possible - Removing names and addresses alone is insufficient if client identity can be inferred from context</p> <p>Criminal liability threshold (Section 3.2): \"For the offence of accessing client secrets, it is irrelevant whether the AI providers actually take note of the information. It is sufficient that they have the opportunity to do so.\"</p> <p>[LEGAL REVIEW REQUIRED] This threshold creates significant risk for any legal AI product that receives unredacted client data, even if that data is not stored or accessed by the provider. Legal advice is required on the design of data handling and anonymisation workflows.</p>"},{"location":"stage-1-regulatory-orientation/STAGE1-Regulatory-Orientation-Note-v1/#54-it-outsourcing-requirements-section-43e-brao","title":"5.4 IT Outsourcing Requirements \u2014 Section 43e BRAO","text":"<p>Need-to-know principle: Lawyers may only grant AI providers access to confidential information where strictly necessary for the service. Unnecessary access violates Section 43e BRAO.</p> <p>Written service agreements (Sections 43e(2) and (3) BRAO \u2014 mandatory minimum content): - Obligation to maintain confidentiality, with explicit warning of criminal consequences for breach - Obligation to adhere to the purpose limitation principle</p> <p>Termination obligation: If these standards are not (or no longer) guaranteed, the cooperation must be terminated immediately (Section 43e(2)).</p> <p>Foreign providers (Section 43e(4) BRAO): Where AI providers are established outside Germany, confidentiality protection must be comparable to German standards. US-based providers require specific assessment against current adequacy frameworks. Providers in countries without equivalent data protection standards (cited examples: China, India) require Standard Contractual Clauses or equivalent protective measures.</p> <p>[ASSUMPTION \u2014 A-004] This provision is directly relevant if Pickles GmbH uses third-party foundation model providers. Pickles GmbH's ability to offer legally compliant service agreements to lawyer clients depends on the provenance and contractual arrangements of any underlying AI models in use.</p>"},{"location":"stage-1-regulatory-orientation/STAGE1-Regulatory-Orientation-Note-v1/#55-transparency-and-ai-output-labelling","title":"5.5 Transparency and AI Output Labelling","text":"<p>Current position (December 2024): No mandatory professional obligation under BRAO or BORA to inform clients about AI use. However, transparency obligations may arise from contract law or the Unfair Competition Act (UWG).</p> <p>Best practice recommendation (Section 4): \"It is advisable to use AI tools transparently and, in case of doubt, to include a contractual provision with clients.\"</p> <p>EU AI Act transparency obligations for operators (Article 50 \u2014 effective 2 August 2026): - Lawyers as operators must disclose where AI-generated text is published to inform the public about matters of public interest - Safe harbour: No disclosure obligation \"if the content generated by AI has been subject to human review or editorial control and if a natural or legal person is editorially responsible for the publication\"</p> <p>Pickles GmbH as provider (Article 50(1), (2), (5)): - Must inform users that they are interacting with AI (applicable to legal chatbots) - Must label AI-generated content so users know it is machine-generated</p>"},{"location":"stage-1-regulatory-orientation/STAGE1-Regulatory-Orientation-Note-v1/#56-liability-framework","title":"5.6 Liability Framework","text":"<p>Lawyers retain full professional liability for all AI-generated outputs they rely on. They cannot delegate responsibility to Pickles GmbH or to any underlying AI model provider.</p> <p>Additional risk areas for lawyers using AI (Section 6): - Tax law: Above a certain degree of automation, legal activity may be reclassified as commercial activity, affecting tax status - Insurance: Professional liability insurance may refuse coverage if AI use falls outside scope of \"legal activity\" - Copyright: AI-generated text is not protected by copyright but may infringe third-party copyrights \u2014 the lawyer using the tool bears this liability</p>"},{"location":"stage-1-regulatory-orientation/STAGE1-Regulatory-Orientation-Note-v1/#57-regulatory-coexistence","title":"5.7 Regulatory Coexistence","text":"<p>\"The use of an AI system that complies with the AI Regulation may nevertheless violate professional regulations. Conversely, a violation of certain provisions of the AI Regulation, such as Art. 4 (AI competence) or Art. 50 (transparency), may also be relevant under professional law.\" (Section 5.4, BRAK Position Paper)</p> <p>Compliance with the EU AI Act does not ensure BRAK compliance. The governance framework must address both independently.</p>"},{"location":"stage-1-regulatory-orientation/STAGE1-Regulatory-Orientation-Note-v1/#58-ongoing-monitoring","title":"5.8 Ongoing Monitoring","text":"<p>\"As the professional law discussion on the use of AI tools is highly dynamic, these notes are only a snapshot.\" (Section 8, BRAK Position Paper)</p> <p>The governance framework must include a mechanism for monitoring BRAK guidance updates, as further notes from BRAK are expected.</p>"},{"location":"stage-1-regulatory-orientation/STAGE1-Regulatory-Orientation-Note-v1/#6-isoiec-42001-ai-management-system-standard","title":"6. ISO/IEC 42001 \u2014 AI Management System Standard","text":"<p>Source: ISO/IEC 42001 Overview Summary, as read from <code>_input/ISO-42001-overview-summary.pdf</code></p>"},{"location":"stage-1-regulatory-orientation/STAGE1-Regulatory-Orientation-Note-v1/#61-scope","title":"6.1 Scope","text":"<p>ISO/IEC 42001 is a sector-specific AI management system standard specifying requirements for organisations providing or using AI systems to establish, implement, maintain, and continually improve an AI Management System (AIMS) for responsible AI. It follows the ISO High-Level Structure (HLS) common to ISO 9001, ISO 27001, and ISO 22000.</p>"},{"location":"stage-1-regulatory-orientation/STAGE1-Regulatory-Orientation-Note-v1/#62-key-clauses","title":"6.2 Key Clauses","text":"Clause Focus Clause 4 Context: organisational context, interested parties, AIMS scope Clause 5 Leadership: AI policy, roles, responsibilities, authority Clause 6 Planning: risk and opportunity identification, AI objectives Clause 7 Support: resources, competence, awareness, communication, documented information Clause 8.2 AI Risk Assessment \u2014 mandatory for all AI systems Clause 8.3 AI Risk Treatment \u2014 define and implement controls Clause 8.4 AI System Impact Assessment \u2014 impact on individuals and society Clause 9 Performance evaluation: monitoring, measurement, internal audit, management review Clause 10 Continual improvement: nonconformity, corrective action <p>Annex A Controls (10 categories):</p> Control Focus A.2 AI policies \u2014 organisational AI policy alignment and review A.3 Internal organisation \u2014 AI roles, responsibilities, reporting A.4 Resources for AI systems \u2014 documentation, data, tooling, human resources A.5 Assessing impacts \u2014 impact assessment process, societal impact A.6 AI system lifecycle \u2014 development objectives, design, requirements, documentation, verification, validation, deployment, operation, monitoring, technical documentation, event logging A.7 Data for AI systems \u2014 acquisition, quality, provenance, preparation A.8 Information for interested parties \u2014 system documentation, external reporting, incident communication A.9 Responsible use of AI systems \u2014 intended use, objectives, responsible use processes A.10 Third-party and customer relationships \u2014 responsibility allocation, supplier management"},{"location":"stage-1-regulatory-orientation/STAGE1-Regulatory-Orientation-Note-v1/#63-risk-management-integration","title":"6.3 Risk Management Integration","text":"<p>Clause 8.2 (AI Risk Assessment): Risk assessments must address impact to: the organisation; individuals (e.g., lawyers and their clients); and society. Integrates with ISO/IEC 23894:2023 (AI Risk Management).</p> <p>Clause 8.4 (AI System Impact Assessment): Formal assessment of potential impacts on individuals and society. Results shared with organisational leadership.</p>"},{"location":"stage-1-regulatory-orientation/STAGE1-Regulatory-Orientation-Note-v1/#64-relevance-to-pickles-gmbh","title":"6.4 Relevance to Pickles GmbH","text":"<p>ISO/IEC 42001 is directly applicable to Pickles GmbH as an AI system provider. Key areas of relevance:</p> <ul> <li>Clause A.6: Full lifecycle documentation \u2014 design, development, deployment, monitoring \u2014 aligns with EU AI Act Article 11 technical documentation requirements</li> <li>Clause A.7: Data governance for AI training and validation data \u2014 aligns with EU AI Act Article 10</li> <li>Clause A.9: Responsible use documentation \u2014 aligns with BRAK human oversight requirements</li> <li>Clause A.10: Third-party model provider management \u2014 aligns with GDPR Article 28 sub-processor obligations and BRAK Section 43e BRAO requirements</li> <li>Clauses 9-10: Post-deployment monitoring and continual improvement \u2014 aligns with EU AI Act Article 72 post-market monitoring</li> </ul>"},{"location":"stage-1-regulatory-orientation/STAGE1-Regulatory-Orientation-Note-v1/#65-certification-pathway","title":"6.5 Certification Pathway","text":"Pathway Standard Scope Management system certification ISO/IEC 17021 Clauses 4-10 \u2014 organisational AIMS Product/service certification ISO/IEC 17065 Annex A controls \u2014 AI system-level conformance <p>ISO/IEC 42001 certification may be used as evidence of governance maturity for enterprise legal clients and may support demonstration of EU AI Act quality management system requirements.</p>"},{"location":"stage-1-regulatory-orientation/STAGE1-Regulatory-Orientation-Note-v1/#7-enisa-ai-cybersecurity-guidelines","title":"7. ENISA AI Cybersecurity Guidelines","text":"<p>Source: ENISA, \"Threat Landscape for Artificial Intelligence\" (December 2020), as read from <code>_input/ENISA-AI-cybersecurity-guidelines.pdf</code></p>"},{"location":"stage-1-regulatory-orientation/STAGE1-Regulatory-Orientation-Note-v1/#71-scope","title":"7.1 Scope","text":"<p>This document maps cybersecurity threats to AI systems across the AI lifecycle. Its primary relevance to this framework is as a threat intelligence source to inform security controls under GDPR Article 32 and EU AI Act Article 9 (risk management).</p> <p>Three dimensions of AI cybersecurity: 1. Cybersecurity for AI: Protecting AI systems against attack 2. AI to support cybersecurity: Using AI as a defensive tool 3. Malicious use of AI: AI-powered attacks (deepfakes, social engineering, AI-powered malware)</p>"},{"location":"stage-1-regulatory-orientation/STAGE1-Regulatory-Orientation-Note-v1/#72-ai-lifecycle-phases-threat-surface","title":"7.2 AI Lifecycle Phases \u2014 Threat Surface","text":"<p>ENISA identifies 12 lifecycle phases across three groups:</p> Group Phases Design and development Business goal definition, data ingestion, data exploration, data pre-processing, feature selection, model selection/building Training and tuning Model training, model tuning Deployment and operations Transfer learning, model deployment, model maintenance, business understanding"},{"location":"stage-1-regulatory-orientation/STAGE1-Regulatory-Orientation-Note-v1/#73-key-ai-threat-categories","title":"7.3 Key AI Threat Categories","text":"Category Examples Data threats Data poisoning during ingestion; data quality failures; privacy violations during collection; data injection attacks Model threats Adversarial inference (input perturbations); model manipulation/evasion; model extraction; model inversion; backdoor and trojan attacks; membership inference Infrastructure and supply chain threats Compromised dependencies/libraries; third-party provider security failures; software supply chain integrity issues; hardware vulnerabilities Operational threats Insufficient logging and monitoring; lack of audit trails; model drift during deployment; retraining vulnerabilities; insufficient incident response"},{"location":"stage-1-regulatory-orientation/STAGE1-Regulatory-Orientation-Note-v1/#74-supply-chain-and-third-party-ai-provider-risks","title":"7.4 Supply Chain and Third-Party AI Provider Risks","text":"<p>[ASSUMPTION \u2014 A-004] If Pickles GmbH uses third-party foundation model providers, the following risks apply:</p> <p>Data providers: May collect data without user awareness; responsibility and liability for data mishandling must be allocated by contract; GDPR Article 28 DPA compliance must be verified.</p> <p>Model providers: Responsibility for certification and operational monitoring must be documented; logging obligations must be assigned to a specific party in the supply chain; pre-trained model security must be assessed before integration.</p> <p>Cloud providers: Data residency and transfer risk; multi-tenancy isolation; hardware vulnerabilities must be assessed.</p>"},{"location":"stage-1-regulatory-orientation/STAGE1-Regulatory-Orientation-Note-v1/#75-implied-controls-for-legal-ai","title":"7.5 Implied Controls for Legal AI","text":"Risk Area Required Control Training data integrity Validation of training, validation, and test data; data provenance tracking Model robustness Adversarial robustness testing; anomaly detection on outputs Post-deployment monitoring Event logging and audit trails; model drift detection; incident response protocols Supply chain security Vendor/provider security assessments; software dependency scanning; DPA and contractual coverage"},{"location":"stage-1-regulatory-orientation/STAGE1-Regulatory-Orientation-Note-v1/#76-alignment-with-gdpr","title":"7.6 Alignment with GDPR","text":"<p>ENISA explicitly notes that AI security obligations align with GDPR Article 32 security requirements and that appropriate security measures \"should be introduced at the design phase of new applications\" in line with GDPR Article 25 (data protection by design). This confirms that security and data protection design must be concurrent, not sequential.</p>"},{"location":"stage-1-regulatory-orientation/STAGE1-Regulatory-Orientation-Note-v1/#8-concluding-regulatory-obligations-checklist","title":"8. Concluding Regulatory Obligations Checklist","text":"<p>Based on the source documents above, the governance framework for Pickles GmbH must address the following regulatory obligations. This checklist structures the work for Stages 2-5.</p>"},{"location":"stage-1-regulatory-orientation/STAGE1-Regulatory-Orientation-Note-v1/#81-eu-ai-act","title":"8.1 EU AI Act","text":"Ref Obligation Regulatory Basis Target Stage EU-1 Determine risk classification (high-risk / limited-risk / minimal) for each AI system Art. 6, Annex III, Recitals 53 and 61 Stage 2 EU-2 Produce technical documentation for all high-risk systems Art. 11 Stage 3 EU-3 Implement continuous AI risk management system across full lifecycle Art. 9 Stage 2/3 EU-4 Implement data quality and governance controls for training, validation, and test datasets Art. 10 Stage 3 EU-5 Design and operationalise human oversight for all high-risk systems; prohibit fully automated legal decisions Art. 14 Stage 2 EU-6 Implement automatic event logging for all high-risk systems Art. 12 Stage 3/4 EU-7 Produce clear instructions for use covering characteristics, capabilities, and limitations Art. 13 Stage 3 EU-8 Implement AI-human interaction disclosure (users informed they are interacting with AI) Art. 50 Stage 3 EU-9 Implement AI-generated content labelling obligations (from 2 August 2026) Art. 50 Stage 3/5 EU-10 Perform conformity assessment and draw up Declaration of Conformity for high-risk systems Arts. 16-23 Stage 3 EU-11 Establish post-market monitoring system; report serious incidents Art. 72 Stage 4 EU-12 Establish substantial modification tracking and re-assessment process Art. 3 Stage 4 EU-13 Implement AI competence measures for all staff involved in AI system operation Art. 4 (in force from 2 Feb 2025) Stage 2"},{"location":"stage-1-regulatory-orientation/STAGE1-Regulatory-Orientation-Note-v1/#82-gdpr","title":"8.2 GDPR","text":"Ref Obligation Regulatory Basis Target Stage GDPR-1 Execute GDPR-compliant Data Processing Agreements (DPAs) with all lawyer clients Art. 28 Stage 3/5 GDPR-2 Conduct DPIA for all systems processing personal data at high risk Art. 35 Stage 3 GDPR-3 Implement prior consultation with supervisory authority where DPIA shows high residual risk Art. 36 Stage 3 GDPR-4 Implement data subject rights handling procedures (access, erasure, portability, etc.) Arts. 12-22 Stage 2/3 GDPR-5 Prohibit fully automated decisions with legal effects without appropriate human intervention safeguards Art. 22 Stage 2 GDPR-6 Implement data protection by design and by default across all product development Art. 25 Stage 2/3 GDPR-7 Implement appropriate security measures including encryption, resilience, and regular testing Art. 32 Stage 3/4 GDPR-8 Establish data breach detection, notification procedures (72-hour rule), and documentation Art. 33 Stage 4 GDPR-9 Identify and implement appropriate mechanism for all international data transfers Arts. 44-49 Stage 3 GDPR-10 Disclose existence of automated decision-making in transparency notices Arts. 13(2)(f), 14(2)(g) Stage 3 GDPR-11 Implement consent management system if consent is used as legal basis for any processing Arts. 7, 17; EDPB Guidelines 05/2020 Stage 3"},{"location":"stage-1-regulatory-orientation/STAGE1-Regulatory-Orientation-Note-v1/#83-bdsg-german-law","title":"8.3 BDSG (German Law)","text":"Ref Obligation Regulatory Basis Target Stage BDSG-1 Designate DPO if 20+ staff perform automated personal data processing (or if DPIA is undertaken) BDSG Section 38 Stage 2 BDSG-2 Conduct BDSG DPIA for all new AI systems processing personal data with substantial risk BDSG Section 67 Stage 3 BDSG-3 Prior consultation with BfDI where BDSG DPIA indicates substantial residual risk BDSG Section 69 Stage 3 BDSG-4 Implement Section 64 BDSG technical controls for all automated processing systems BDSG Section 64 Stage 3/4 BDSG-5 Implement mandatory audit logging of all CRUD operations in automated systems; 1-year retention BDSG Section 76 Stage 3/4 BDSG-6 Apply Section 29 BDSG professional confidentiality restrictions on data subject rights responses BDSG Section 29 Stage 3"},{"location":"stage-1-regulatory-orientation/STAGE1-Regulatory-Orientation-Note-v1/#84-brak-professional-conduct","title":"8.4 BRAK / Professional Conduct","text":"Ref Obligation Regulatory Basis Target Stage BRAK-1 Design all AI systems to require human review \u2014 never to replace lawyer judgment BRAK Position Paper, Section 2.1; Section 43(1) BRAO Stage 2 BRAK-2 Ensure AI systems never imply legal review by the lawyer is unnecessary BRAK Position Paper, Section 2.2 Stage 3 BRAK-3 Design and document data handling workflows supporting client document anonymisation before upload BRAK Position Paper, Section 3.1; Section 43a(2) BRAO Stage 3 BRAK-4 Provide Section 43e BRAO-compliant service agreements covering confidentiality obligations and purpose limitation Section 43e(2), (3) BRAO Stage 3/5 BRAK-5 Assess and document confidentiality-equivalent protection for all third-country AI model providers Section 43e(4) BRAO Stage 3 BRAK-6 Implement AI output labelling requirements (EU AI Act Article 50 \u2014 from 2 August 2026) Art. 50 EU AI Act; BRAK Position Paper, Section 5.2 Stage 3/5 BRAK-7 Provide client training and documentation materials supporting lawyer AI competence obligations Art. 4 EU AI Act; BRAK Position Paper, Section 5.1 Stage 5 BRAK-8 Establish monitoring process for BRAK guidance updates (guidance is explicitly flagged as a \"snapshot\") BRAK Position Paper, Section 8 Stage 4"},{"location":"stage-1-regulatory-orientation/STAGE1-Regulatory-Orientation-Note-v1/#85-isoiec-42001-and-enisa","title":"8.5 ISO/IEC 42001 and ENISA","text":"Ref Obligation Regulatory Basis Target Stage ISO-1 Establish AI Management System aligned with ISO/IEC 42001 Clauses 4-10 ISO/IEC 42001 Stage 2 ISO-2 Conduct formal AI system impact assessments per Clause 8.4 ISO/IEC 42001, Clause 8.4 Stage 3 ISO-3 Implement AI lifecycle documentation and controls per Annex A Clause A.6 ISO/IEC 42001, Annex A Stage 2/3 ISO-4 Manage third-party AI model provider relationships per Clause A.10 ISO/IEC 42001, Annex A Stage 3 ENISA-1 Conduct supply chain security assessment for all AI model providers and cloud infrastructure ENISA Threat Landscape, Section 2.2 (AI Lifecycle Actors) Stage 3 ENISA-2 Implement adversarial robustness testing as part of model validation ENISA Threat Landscape, threat taxonomy Stage 3/4 ENISA-3 Implement comprehensive event logging and audit trails across full AI lifecycle ENISA Threat Landscape, threat taxonomy (Annex B, Operational threats) Stage 3/4 ENISA-4 Implement model drift monitoring and post-deployment performance review ENISA Threat Landscape, Section 2.3, Phase 11 (Model Maintenance) Stage 4"},{"location":"stage-1-regulatory-orientation/STAGE1-Regulatory-Orientation-Note-v1/#appendix-regulatory-assumptions-flagged-in-this-document","title":"Appendix: Regulatory Assumptions Flagged in This Document","text":"<p>The following assumptions are flagged for verification. All are marked [ASSUMPTION] in the document body. The governance framework is built on these until they are confirmed against real Pickles GmbH data.</p> Code Assumption Status Key Sections A-001 Pickles GmbH provides legal AI covering drafting, research, summarisation, analysis \ud83d\udd34 Unverified 1.2, 2.4, 5.2 A-002 Clients are German legal professionals or in-house legal departments \ud83d\udd34 Unverified 5 (BRAK) throughout A-003 Pickles GmbH operates under EU AI Act, GDPR, BDSG, and BRAK standards \ud83d\udd34 Unverified Opening A-004 Third-party AI model providers may be in use \ud83d\udd34 Unverified 2.8, 5.4, 7.4 A-005 Hosting is EU-based \ud83d\udd34 Unverified 2.8 A-006 Pickles GmbH's products include client-facing AI interaction interfaces \ud83d\udd34 Unverified 1.4 A-007 Pickles GmbH acts as data processor for lawyer clients (not joint controller or independent controller) \ud83d\udd34 Unverified 2.2, 2.4 A-008 Pickles GmbH employs 20+ staff with automated data processing roles \ud83d\udd34 Unverified 3.2 <p>This document is a proposal. It is not a legal compliance certification. All regulatory conclusions are drawn from source documents in <code>_input/</code> as of 2026-02-22. Before any part of this document is used as the basis for operational decisions, it must be reviewed by a qualified German lawyer with expertise in data protection law, AI regulation, and professional conduct regulation.</p> <p>[LEGAL REVIEW REQUIRED] \u2014 This document as a whole requires professional legal review before operational use.</p>"},{"location":"stage-2-governance-foundation/L1-3.1-AI-System-Inventory-v1/","title":"AI System Inventory","text":"<p>Project: Pickles GmbH \u2014 AI Governance Framework Stage: Stage 2 \u2014 Governance Foundation Status: Draft Version: v1 Date: 2026-02-22 Assumptions: Built on outline assumptions \u2014 not verified against real Pickles GmbH data</p>"},{"location":"stage-2-governance-foundation/L1-3.1-AI-System-Inventory-v1/#purpose","title":"Purpose","text":"<p>This document is the master register of all AI systems operated or deployed by Pickles GmbH [ASSUMPTION \u2014 A-001, A-003]. It is the primary reference for risk governance, compliance obligations, and operational oversight across all AI systems.</p> <p>This register must be maintained as a living document. Every AI system used in production \u2014 whether internally developed, procured from a third party, or based on a third-party foundation model \u2014 must be registered here before deployment. Unregistered systems must not be deployed.</p> <p>Regulatory basis: - EU AI Act Article 11 \u2014 Technical documentation requirements for high-risk AI systems - EU AI Act Article 12 \u2014 Logging and event recording requirements - EU AI Act Article 13 \u2014 Transparency and instructions for use - EU AI Act Article 72 \u2014 Post-market monitoring - ISO/IEC 42001 Clause A.6 \u2014 AI system lifecycle documentation</p>"},{"location":"stage-2-governance-foundation/L1-3.1-AI-System-Inventory-v1/#how-to-use-this-register","title":"How to Use This Register","text":"Action Instruction New system intake Complete a new row when a system passes Gate 1 of the AI Intake Approval Workflow (L1-3.3). Risk Classification must be assigned at Gate 2. Risk classification Use the Risk Classification Framework (L1-3.2) to assign High / Medium / Low tier. Updates Any change to system name, model type, hosting location, data categories, or deployment status must be reflected within 5 business days. Substantive modifications Modifications that may affect compliance with EU AI Act requirements (Article 3) must trigger re-classification and re-registration. Decommissioning Update Deployment Status to \"Decommissioned\" and record the date. Do not delete rows \u2014 retain for audit."},{"location":"stage-2-governance-foundation/L1-3.1-AI-System-Inventory-v1/#column-definitions","title":"Column Definitions","text":"Column Definition System ID Unique identifier assigned at registration (format: SYS-001, SYS-002, etc.) System Name Commercial or internal name of the AI system Purpose Brief description of the system's function and intended use Internal / Customer-Facing Whether the system is used internally by Pickles GmbH staff, or deployed to / accessible by external clients Model Type Type of underlying AI model (e.g., LLM, RAG, Classification Model, Rule-Based System) Hosting Location Where the system is hosted (e.g., EU cloud provider, German data centre, third-party API, US-based provider) Data Categories Processed Categories of personal data processed (e.g., general personal data, special categories under GDPR Article 9, criminal convictions under Article 10, no personal data) Risk Classification High / Medium / Low \u2014 assigned using L1-3.2; EU AI Act tier in parentheses System Owner Named individual responsible for compliance and operational oversight Deployment Status Development / Staging / Production / Suspended / Decommissioned Monitoring Status Active Monitoring / Monitoring Pending / Not Required"},{"location":"stage-2-governance-foundation/L1-3.1-AI-System-Inventory-v1/#system-register","title":"System Register","text":"<p>[ASSUMPTION \u2014 A-001] The entries below are placeholder rows based on assumed Pickles GmbH product capabilities. All rows must be replaced with verified system data before operational use. System owners must be named individuals, not job titles.</p> System ID System Name Purpose Internal / Customer-Facing Model Type Hosting Location Data Categories Processed Risk Classification System Owner Deployment Status Monitoring Status SYS-001 Legal Drafting Assistant AI-assisted generation of legal document drafts (contracts, briefs, correspondence) based on lawyer instructions and templates Customer-Facing [ASSUMPTION \u2014 A-006] Large Language Model (foundation model \u2014 provider unconfirmed [ASSUMPTION \u2014 A-004]) EU-based cloud \u2014 unconfirmed [ASSUMPTION \u2014 A-005] General personal data in documents. May include special categories (GDPR Article 9) or criminal data (Article 10) if legal matter involves health, criminal history, or related content [ASSUMPTION] [ASSUMPTION: Pending \u2014 likely High (EU AI Act: potentially High-Risk per Recital 61) if applied to specific client facts; otherwise Medium] [PLACEHOLDER \u2014 named individual required] Development Monitoring Pending SYS-002 Legal Research Engine AI-powered search and retrieval of case law, legislation, and legal commentary; generates research summaries for lawyer review Customer-Facing [ASSUMPTION \u2014 A-006] Retrieval-Augmented Generation (RAG) with LLM EU-based cloud \u2014 unconfirmed [ASSUMPTION \u2014 A-005] Incidental general personal data in legal texts. No direct processing of client personal data anticipated [ASSUMPTION] [ASSUMPTION: Pending \u2014 likely Low/Medium (EU AI Act: Minimal-Risk) \u2014 ancillary research support] [PLACEHOLDER \u2014 named individual required] Development Monitoring Pending SYS-003 Document Summarisation Tool Automated summarisation of legal documents (contracts, judgments, regulatory texts) for lawyer review Customer-Facing [ASSUMPTION \u2014 A-006] Large Language Model (foundation model \u2014 provider unconfirmed [ASSUMPTION \u2014 A-004]) EU-based cloud \u2014 unconfirmed [ASSUMPTION \u2014 A-005] General personal data and potentially special categories if document content includes health, criminal, or Article 9/10 data [ASSUMPTION] [ASSUMPTION: Pending \u2014 likely Medium (EU AI Act: Limited-Risk) \u2014 assistive function requiring review] [PLACEHOLDER \u2014 named individual required] Development Monitoring Pending SYS-004 Internal Operations Tool AI-assisted internal tooling for Pickles GmbH staff (internal knowledge base search, administrative automation) Internal To be confirmed at intake [ASSUMPTION] EU-based cloud \u2014 unconfirmed [ASSUMPTION \u2014 A-005] General personal data of Pickles GmbH staff [ASSUMPTION] [ASSUMPTION: Pending \u2014 likely Low (EU AI Act: Minimal-Risk) \u2014 internal administrative use] [PLACEHOLDER \u2014 named individual required] Development Not Required"},{"location":"stage-2-governance-foundation/L1-3.1-AI-System-Inventory-v1/#systems-pending-registration","title":"Systems Pending Registration","text":"<p>Any AI system under evaluation but not yet through Gate 1 of the AI Intake Approval Workflow (L1-3.3) is tracked here. These systems must not be deployed or used with real client data until they complete the full intake process.</p> System Name Current Stage Date Added Responsible Person [PLACEHOLDER] Pre-intake evaluation [Date] [Name]"},{"location":"stage-2-governance-foundation/L1-3.1-AI-System-Inventory-v1/#decommissioned-systems","title":"Decommissioned Systems","text":"<p>Systems removed from production are retained here for audit and regulatory traceability (EU AI Act Article 72; BDSG Section 76). Do not delete rows.</p> System ID System Name Decommissioning Date Reason Responsible Person \u2014 \u2014 \u2014 \u2014 \u2014"},{"location":"stage-2-governance-foundation/L1-3.1-AI-System-Inventory-v1/#register-governance","title":"Register Governance","text":"Item Requirement Review frequency Minimum every six months, or following any system change, incident, or regulatory update Review responsibility System owner for each system; DPO [ASSUMPTION \u2014 A-008] for data category accuracy; Compliance Lead for risk classification New entries Must pass full AI Intake Approval Workflow (L1-3.3) before Deployment Status is changed to Production Audit trail Version history must be maintained. Do not delete historical rows. Substantive modifications Any change that may affect EU AI Act compliance (Article 3) triggers re-classification and, where applicable, new conformity assessment"},{"location":"stage-2-governance-foundation/L1-3.1-AI-System-Inventory-v1/#regulatory-cross-references","title":"Regulatory Cross-References","text":"Obligation Regulatory Basis How This Register Supports Compliance Technical documentation for high-risk systems EU AI Act Article 11 System ID links to technical documentation pack (Stage 3: L2-4.2) Logging and traceability EU AI Act Article 12; BDSG Section 76 System ID used as reference in audit log entries Post-market monitoring EU AI Act Article 72 Monitoring Status field triggers monitoring framework (Stage 4: L3-6.1) DPIA requirement GDPR Article 35; BDSG Section 67 Data Categories Processed field used to assess DPIA trigger AI risk management EU AI Act Article 9; ISO/IEC 42001 Clause 8.2 Risk Classification links to L1-3.2 Transparency obligations EU AI Act Articles 13 and 50 Customer-Facing flag triggers disclosure requirements (Stage 3: L2-4.3) <p>This register is a governance control document. It must be treated as confidential internal documentation and made available to the DPO, Legal, and relevant regulatory authorities on request.</p> <p>[LEGAL REVIEW REQUIRED] Before this register is used operationally, a qualified lawyer must confirm: (i) the correct EU AI Act risk classification for each system; (ii) the data categories processed by each system; and (iii) whether any system triggers a mandatory DPIA under GDPR Article 35 or BDSG Section 67.</p>"},{"location":"stage-2-governance-foundation/L1-3.2-Risk-Classification-Framework-v1/","title":"Risk Classification Framework","text":"<p>Project: Pickles GmbH \u2014 AI Governance Framework Stage: Stage 2 \u2014 Governance Foundation Status: Draft Version: v1 Date: 2026-02-22 Assumptions: Built on outline assumptions \u2014 not verified against real Pickles GmbH data</p>"},{"location":"stage-2-governance-foundation/L1-3.2-Risk-Classification-Framework-v1/#purpose","title":"Purpose","text":"<p>This framework defines the criteria for classifying AI systems operated or deployed by Pickles GmbH [ASSUMPTION \u2014 A-001, A-003] across three internal risk tiers: High, Medium, and Low. It translates the EU AI Act's regulatory risk tiers and GDPR obligations into operational governance requirements tailored to the legal AI context.</p> <p>Every AI system registered in the AI System Inventory (L1-3.1) must be assigned a risk tier using this framework before deployment. Risk classification determines required documentation, review level, monitoring intensity, and escalation pathway.</p> <p>Regulatory basis: - EU AI Act Articles 6, 9, 13, 14 \u2014 Risk-based requirements - EU AI Act Annex III \u2014 High-risk AI system categories - EU AI Act Recitals 53 and 61 \u2014 Classification of legal and judicial AI - GDPR Article 22 \u2014 Right not to be subject to solely automated decisions with legal effects - GDPR Article 35 \u2014 Data Protection Impact Assessment triggers - BDSG Sections 67-69 \u2014 German DPIA and prior consultation requirements - ISO/IEC 42001 Clauses 8.2-8.4 \u2014 AI risk and impact assessment</p>"},{"location":"stage-2-governance-foundation/L1-3.2-Risk-Classification-Framework-v1/#section-1-risk-tier-definitions","title":"Section 1: Risk Tier Definitions","text":""},{"location":"stage-2-governance-foundation/L1-3.2-Risk-Classification-Framework-v1/#tier-1-high-risk","title":"Tier 1 \u2014 High Risk","text":"<p>Definition: A system is classified as High Risk if it meets any one of the following criteria:</p> <ol> <li> <p>EU AI Act high-risk classification: The system falls within EU AI Act Annex III categories, or is used for the administration of justice or legal reasoning applied to specific facts (Recital 61), or meets the criteria of Article 6(2).</p> </li> <li> <p>Legal effects on identifiable individuals: The system's output is used \u2014 directly or indirectly \u2014 to produce decisions with legal effects on individuals, or that similarly significantly affect their rights, interests, or obligations (GDPR Article 22(1)).</p> </li> <li> <p>Large-scale processing of special categories: The system processes special categories of personal data (GDPR Article 9(1)) or criminal convictions data (GDPR Article 10) at scale.</p> </li> <li> <p>High potential for harm: A failure, error, or misuse of the system could result in material harm to a client's legal interests; professional liability for a lawyer relying on the output; regulatory breach by Pickles GmbH; or reputational harm to the legal profession.</p> </li> <li> <p>Third-party foundation model in client-facing deployment without adequate safeguards: The system is deployed to external clients and relies on a third-party AI model provider [ASSUMPTION \u2014 A-004] where that provider cannot demonstrate EU-equivalent data protection and confidentiality standards per Section 43e(4) BRAO.</p> </li> </ol> <p>Likely High Risk examples [ASSUMPTION \u2014 A-001]: - Legal analysis tools that apply AI reasoning to specific client facts to produce conclusions - AI systems used by lawyers in adversarial or court proceedings - Any system where lawyers apply AI outputs directly to specific client matters without interim review</p>"},{"location":"stage-2-governance-foundation/L1-3.2-Risk-Classification-Framework-v1/#tier-2-medium-risk","title":"Tier 2 \u2014 Medium Risk","text":"<p>Definition: A system is classified as Medium Risk if it meets any of the following criteria but does not meet any Tier 1 criterion:</p> <ol> <li> <p>Customer-facing AI interaction without specific-case outputs: The system is deployed to external clients and directly interacts with natural persons (triggering EU AI Act Article 50 obligations), but does not produce outputs applied to specific client facts.</p> </li> <li> <p>Processing of general personal data as a core function: The system processes general personal data (not special categories) in its core operation.</p> </li> <li> <p>Professional reliance risk: The system's output is likely to be relied upon by lawyers in their professional work, creating a risk of harm from errors or hallucinations, but the risk is mitigated by the assistive (not determinative) nature of the output.</p> </li> <li> <p>Third-party model with adequate safeguards: The system uses a third-party AI model provider [ASSUMPTION \u2014 A-004] with demonstrated EU-equivalent data protection standards, but with residual risk from model behaviour or training data.</p> </li> <li> <p>Internal tooling with personal data access: Internal AI systems used by Pickles GmbH staff that access or process personal data of staff or clients.</p> </li> </ol> <p>Likely Medium Risk examples [ASSUMPTION \u2014 A-001]: - Legal drafting assistance where output requires mandatory lawyer review before use - Document summarisation tools processing documents that may contain personal data - Client-facing legal research portals interacting with natural persons</p>"},{"location":"stage-2-governance-foundation/L1-3.2-Risk-Classification-Framework-v1/#tier-3-low-risk","title":"Tier 3 \u2014 Low Risk","text":"<p>Definition: A system is classified as Low Risk only if it meets all of the following criteria:</p> <ol> <li>No personal data processing: The system does not process personal data of identifiable individuals, or processes only fully anonymised data.</li> <li>No client-facing interaction: The system is used entirely internally with no external client interaction.</li> <li>No legal effects: The system's output is not used to inform decisions with legal effects on individuals.</li> <li>Ancillary function: The system performs administrative, productivity, or support functions with no direct impact on legal advice or client outcomes.</li> <li>Minimal harm potential: Errors in the system's output would not cause material harm to clients, lawyers, or Pickles GmbH.</li> </ol> <p>Likely Low Risk examples [ASSUMPTION \u2014 A-001]: - Internal knowledge base search tools operating on non-personal data - Administrative scheduling or document management automation - Internal analytics operating on aggregate, anonymised data only</p>"},{"location":"stage-2-governance-foundation/L1-3.2-Risk-Classification-Framework-v1/#section-2-classification-requirements-by-tier","title":"Section 2: Classification Requirements by Tier","text":"Requirement High Risk (Tier 1) Medium Risk (Tier 2) Low Risk (Tier 3) EU AI Act classification High-Risk (Annex III / Article 6) Limited-Risk (Article 50) or unclassified Minimal-Risk DPIA Mandatory (GDPR Art. 35; BDSG \u00a767) Risk assessment required; DPIA likely if personal data processed Risk assessment required; DPIA unlikely BfDI prior consultation Required if DPIA shows residual high risk (GDPR Art. 36; BDSG \u00a769) Not typically required Not required Technical documentation Full pack required (EU AI Act Art. 11; L2-4.2) Summary documentation required Basic record only Human oversight Mandatory \u2014 no AI outputs used without review (EU AI Act Art. 14; BRAK Position Paper Section 2.1) Required \u2014 all outputs reviewed before use Standard professional judgment Conformity assessment Required before deployment (EU AI Act Arts. 16-23) Not required Not required AI output labelling Mandatory (EU AI Act Art. 50) Mandatory where interacting with natural persons (Art. 50) Not required Event logging Automatic logging mandatory (EU AI Act Art. 12; BDSG \u00a776) Operational logging required Basic system logging Review level Legal + DPO + Engineering + Executive sign-off Compliance Lead + Engineering sign-off Engineering sign-off only Monitoring intensity Continuous active monitoring with defined KPIs Periodic monitoring (minimum quarterly) Annual review Escalation pathway CEO/Board; DPO; regulatory reporting may apply Compliance Lead; DPO informed Engineering Lead Re-classification trigger Any substantive modification (EU AI Act Art. 3); any incident; annual review Any change in deployment scope or data types; annual review Annual review"},{"location":"stage-2-governance-foundation/L1-3.2-Risk-Classification-Framework-v1/#section-3-classification-decision-tree","title":"Section 3: Classification Decision Tree","text":"<p>Apply this decision tree to any new or modified AI system. Work through each question in order and stop at the first YES.</p> <pre><code>START\n  \u2502\n  \u251c\u2500\u25ba Q1. Is the system's intended use PROHIBITED under EU AI Act Article 5?\n  \u2502       (Examples: biometric categorisation for law enforcement in public spaces;\n  \u2502        social scoring; manipulation of vulnerable persons; real-time biometric\n  \u2502        identification in public spaces)\n  \u2502\n  \u2502   YES \u2500\u2500\u25ba PROHIBITED \u2014 Do not deploy. Escalate to Legal immediately.\n  \u2502   NO  \u2500\u2500\u25ba Continue \u25bc\n  \u2502\n  \u251c\u2500\u25ba Q2. Does the system fall within EU AI Act Annex III categories?\n  \u2502       OR is it used to assist judicial/legal authorities with fact-finding,\n  \u2502       legal research, or prediction of legal outcomes applied to specific\n  \u2502       client facts? (EU AI Act Recital 61)\n  \u2502\n  \u2502   YES \u2500\u2500\u25ba TIER 1 \u2014 HIGH RISK\n  \u2502   NO  \u2500\u2500\u25ba Continue \u25bc\n  \u2502\n  \u251c\u2500\u25ba Q3. Could the system's output be used \u2014 directly or indirectly \u2014 to produce\n  \u2502       decisions with legal effects on an identifiable individual, or that\n  \u2502       similarly significantly affect them? (GDPR Article 22(1))\n  \u2502\n  \u2502   YES \u2500\u2500\u25ba TIER 1 \u2014 HIGH RISK\n  \u2502   NO  \u2500\u2500\u25ba Continue \u25bc\n  \u2502\n  \u251c\u2500\u25ba Q4. Does the system process special categories of personal data\n  \u2502       (GDPR Article 9(1)) or criminal convictions data (GDPR Article 10)\n  \u2502       at scale?\n  \u2502\n  \u2502   YES \u2500\u2500\u25ba TIER 1 \u2014 HIGH RISK\n  \u2502   NO  \u2500\u2500\u25ba Continue \u25bc\n  \u2502\n  \u251c\u2500\u25ba Q5. Is the system customer-facing (directly accessible by or interacting\n  \u2502       with external lawyer clients or their end clients)?\n  \u2502\n  \u2502   YES \u2500\u2500\u25ba Continue to Q6\n  \u2502   NO  \u2500\u2500\u25ba Continue to Q7\n  \u2502\n  \u251c\u2500\u25ba Q6. Does the system produce outputs that lawyers are likely to apply to\n  \u2502       specific client matters \u2014 i.e., outputs about specific facts,\n  \u2502       specific clients, or specific legal situations?\n  \u2502\n  \u2502   YES \u2500\u2500\u25ba TIER 1 \u2014 HIGH RISK\n  \u2502          (risk of harm from reliance on specific-case AI outputs)\n  \u2502   NO  \u2500\u2500\u25ba TIER 2 \u2014 MEDIUM RISK\n  \u2502          (customer-facing with transparency obligations; EU AI Act Art. 50)\n  \u2502\n  \u2514\u2500\u25ba Q7. Does the system process personal data of identifiable individuals\n          in its core function?\n\n      YES \u2500\u2500\u25ba TIER 2 \u2014 MEDIUM RISK\n      NO  \u2500\u2500\u25ba TIER 3 \u2014 LOW RISK\n</code></pre> <p>[LEGAL REVIEW REQUIRED] The application of this decision tree to specific Pickles GmbH products requires legal interpretation before any classification is finalised. Q2 (Annex III / Recital 61) and Q6 (specific-case reliance) are particularly sensitive and must be reviewed by a qualified lawyer with EU AI Act expertise.</p>"},{"location":"stage-2-governance-foundation/L1-3.2-Risk-Classification-Framework-v1/#section-4-tier-specific-governance-requirements","title":"Section 4: Tier-Specific Governance Requirements","text":""},{"location":"stage-2-governance-foundation/L1-3.2-Risk-Classification-Framework-v1/#tier-1-high-risk-full-requirements","title":"Tier 1 \u2014 High Risk: Full Requirements","text":"<p>Required documentation: - [ ] Technical Documentation Pack (EU AI Act Article 11) \u2014 template L2-4.2 - [ ] EU AI Act Risk Classification Assessment \u2014 citing specific Annex III categories or Recital 61 basis - [ ] Data Protection Impact Assessment (GDPR Article 35; BDSG Section 67) - [ ] BfDI prior consultation record or documented decision not required (GDPR Article 36; BDSG Section 69) - [ ] Conformity Assessment and Declaration of Conformity (EU AI Act Articles 16-23) - [ ] Data Processing Agreement with all clients (GDPR Article 28) - [ ] Section 43e BRAO-compliant service agreement (for lawyer clients) [ASSUMPTION \u2014 A-002] - [ ] Vendor Risk Assessment for any third-party model providers (L2-5.3)</p> <p>Review level: All four sign-offs mandatory before deployment: 1. Legal and compliance (including DPIA and DPA review) 2. DPO [ASSUMPTION \u2014 A-008] 3. Engineering and security 4. Executive sign-off (CEO or designated C-suite)</p> <p>Monitoring intensity: - Continuous active monitoring via L3-6.1 - Hallucination rate, citation error rate, bias signals, complaint rate tracked as KPIs - Monthly monitoring report to Compliance Lead and DPO - Annual external audit recommended</p> <p>Escalation pathway: 1. Incident or anomaly detected \u2192 Incident Response Playbook (L3-6.2) activated immediately 2. Serious incident (client harm, regulatory breach, data breach) \u2192 CEO/Board within 24 hours; DPO immediately; regulatory reporting assessed 3. EU AI Act serious incident \u2192 Market surveillance authority per Article 73 4. GDPR data breach \u2192 Supervisory authority within 72 hours (Article 33); data subjects if high risk (Article 34)</p>"},{"location":"stage-2-governance-foundation/L1-3.2-Risk-Classification-Framework-v1/#tier-2-medium-risk-full-requirements","title":"Tier 2 \u2014 Medium Risk: Full Requirements","text":"<p>Required documentation: - [ ] System summary documentation (purpose, model type, data categories, intended use) - [ ] Risk assessment documenting why Tier 1 criteria are not met - [ ] DPIA trigger assessment (document conclusion even if DPIA not triggered) - [ ] Data Processing Agreement if personal data is processed (GDPR Article 28) - [ ] AI transparency disclosure for customer-facing systems (EU AI Act Article 50; L2-4.3)</p> <p>Review level: Two sign-offs required before deployment: 1. Compliance Lead review 2. Engineering and security sign-off</p> <p>Monitoring intensity: - Periodic monitoring \u2014 minimum quarterly review - Error rate and complaint tracking - Quarterly report to Compliance Lead</p> <p>Escalation pathway: 1. Incident or anomaly \u2192 Compliance Lead within 48 hours; Incident Response Playbook assessed 2. Personal data breach \u2192 DPO immediately; GDPR Article 33 reporting assessed 3. Pattern of errors or complaints \u2192 Risk re-assessment; consider re-classification to Tier 1</p>"},{"location":"stage-2-governance-foundation/L1-3.2-Risk-Classification-Framework-v1/#tier-3-low-risk-full-requirements","title":"Tier 3 \u2014 Low Risk: Full Requirements","text":"<p>Required documentation: - [ ] Basic system record (system name, purpose, owner, deployment date) - [ ] Documented confirmation that Tier 1 and Tier 2 criteria have been assessed and do not apply</p> <p>Review level: Single sign-off: 1. Engineering sign-off (technical review and basic security check)</p> <p>Monitoring intensity: - Annual review to confirm continued eligibility for Tier 3 - No real-time monitoring required</p> <p>Escalation pathway: 1. Unexpected personal data processing identified \u2192 Re-assess classification immediately; inform DPO 2. Any incident \u2192 Engineering Lead notified; Compliance Lead informed</p>"},{"location":"stage-2-governance-foundation/L1-3.2-Risk-Classification-Framework-v1/#section-5-re-classification-triggers","title":"Section 5: Re-Classification Triggers","text":"<p>A system must be re-classified whenever any of the following occur:</p> Trigger Required Action Substantive modification to model, architecture, or intended use (EU AI Act Article 3) Re-run decision tree; re-classification may require new conformity assessment Change in data categories processed Re-run decision tree; consider DPIA trigger Change from internal to customer-facing deployment Re-run decision tree; likely upgrade to Tier 2 or Tier 1 Change of third-party model provider [ASSUMPTION \u2014 A-004] Re-run Vendor Risk Assessment (L2-5.3); consider classification impact Significant incident or pattern of errors Compliance Lead to review; may require upgrade Annual review Re-confirm classification; update documentation New regulatory guidance (BRAK notes its guidance is a \"snapshot\") Compliance Lead to assess impact on all classified systems"},{"location":"stage-2-governance-foundation/L1-3.2-Risk-Classification-Framework-v1/#section-6-classification-register","title":"Section 6: Classification Register","text":"<p>Risk classifications are recorded in the AI System Inventory (L1-3.1). This framework governs how classifications are assigned and reviewed. L1-3.1 is the authoritative record of each system's current classification.</p> System ID System Name Current Classification Classification Date Next Review SYS-001 Legal Drafting Assistant [ASSUMPTION: Pending \u2014 likely Tier 1 or Tier 2] Pending At deployment SYS-002 Legal Research Engine [ASSUMPTION: Pending \u2014 likely Tier 2 or Tier 3] Pending At deployment SYS-003 Document Summarisation Tool [ASSUMPTION: Pending \u2014 likely Tier 2] Pending At deployment SYS-004 Internal Operations Tool [ASSUMPTION: Pending \u2014 likely Tier 3] Pending At deployment <p>This framework is a governance control document. Classifications assigned under this framework have regulatory significance under the EU AI Act and GDPR.</p> <p>[LEGAL REVIEW REQUIRED] The criteria in this framework, particularly the decision tree at Section 3, require legal interpretation before operational use. The boundary between Tier 1 and Tier 2 for legal AI tools (Q2 and Q6) depends on deployment context and must be assessed per product by a qualified lawyer with EU AI Act expertise.</p>"},{"location":"stage-2-governance-foundation/L1-3.3-AI-Intake-Approval-Workflow-v1/","title":"AI Intake Approval Workflow","text":"<p>Project: Pickles GmbH \u2014 AI Governance Framework Stage: Stage 2 \u2014 Governance Foundation Status: Draft Version: v1 Date: 2026-02-22 Assumptions: Built on outline assumptions \u2014 not verified against real Pickles GmbH data</p>"},{"location":"stage-2-governance-foundation/L1-3.3-AI-Intake-Approval-Workflow-v1/#purpose","title":"Purpose","text":"<p>This workflow defines the mandatory gate process that every AI system must pass before it may be deployed by or on behalf of Pickles GmbH [ASSUMPTION \u2014 A-001, A-003]. No AI system may be used with real client data, integrated into client-facing products, or made accessible to external users until it has completed all gates in this workflow and received final Deployment Approval at Gate 6.</p> <p>The workflow applies to: - New AI systems being evaluated for procurement or development - Existing AI systems undergoing substantive modification (EU AI Act Article 3) - Third-party AI model integrations [ASSUMPTION \u2014 A-004] - Internal AI tools that access or process personal data</p> <p>Regulatory basis: - EU AI Act Articles 3, 9, 11, 13, 14, 16-23 \u2014 Requirements prior to market placement - EU AI Act Article 72 \u2014 Post-market monitoring obligations triggered at deployment - GDPR Article 35 \u2014 Data Protection Impact Assessment prior to processing - GDPR Article 36 \u2014 Prior consultation with BfDI where residual high risk - GDPR Article 28 \u2014 Data Processing Agreement requirement before processing begins - BDSG Section 67 \u2014 German DPIA requirements - BDSG Section 69 \u2014 BfDI prior consultation (must be initiated at design stage, not post-deployment) [LEGAL REVIEW REQUIRED] - BRAK Position Paper Section 2.1 \u2014 Human oversight requirements prior to AI deployment in legal practice - ISO/IEC 42001 Clause 8.2 \u2014 AI risk and impact assessment requirements</p>"},{"location":"stage-2-governance-foundation/L1-3.3-AI-Intake-Approval-Workflow-v1/#workflow-overview","title":"Workflow Overview","text":"<pre><code>INTAKE REQUEST\n     \u2502\n     \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  GATE 1 \u2014 System Description                                    \u2502\n\u2502  Complete system profile. No evaluation work until complete.    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                           \u2502 PASS\n                           \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  GATE 2 \u2014 Risk Classification                                   \u2502\n\u2502  Assign Tier (High / Medium / Low) using L1-3.2 decision tree. \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                           \u2502 PASS\n                           \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  GATE 3a \u2014 Data Review                                          \u2502\n\u2502  Identify all personal data categories. Assess DPIA trigger.   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                           \u2502 PASS\n                           \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  GATE 3b \u2014 Data Review (DPIA / Prior Consultation)              \u2502\n\u2502  Complete DPIA if triggered. Initiate BfDI consultation         \u2502\n\u2502  if residual high risk. Skip if Tier 3 with no personal data.  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                           \u2502 PASS\n                           \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  GATE 4 \u2014 Legal and Regulatory Review                           \u2502\n\u2502  EU AI Act compliance, BRAO/BRAK obligations, DPA review,       \u2502\n\u2502  conformity assessment (Tier 1 only).                           \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                           \u2502 PASS\n                           \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  GATE 5 \u2014 Engineering Sign-Off                                  \u2502\n\u2502  Security review, logging configuration, monitoring setup,      \u2502\n\u2502  technical documentation.                                       \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                           \u2502 PASS\n                           \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  GATE 6 \u2014 Deployment Approval                                   \u2502\n\u2502  Final sign-off. System registered in AI System Inventory       \u2502\n\u2502  (L1-3.1). Deployment Status set to Production.                \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                           \u2502 APPROVED\n                           \u25bc\n                     DEPLOYED TO PRODUCTION\n</code></pre> <p>BLOCKED systems at any gate are returned to the responsible person with a written blocking reason. Work may not proceed to the next gate until the block is resolved and the gate re-passed.</p>"},{"location":"stage-2-governance-foundation/L1-3.3-AI-Intake-Approval-Workflow-v1/#gate-checklists","title":"Gate Checklists","text":""},{"location":"stage-2-governance-foundation/L1-3.3-AI-Intake-Approval-Workflow-v1/#gate-1-system-description","title":"Gate 1 \u2014 System Description","text":"<p>Purpose: Capture a complete system profile before any evaluation or risk assessment begins. A system cannot be registered in L1-3.1 or assessed against L1-3.2 without a complete Gate 1 profile.</p> <p>Responsible: System owner (named individual) [ASSUMPTION \u2014 A-008]</p> <p>Checklist:</p> <ul> <li>[ ] System name \u2014 the commercial or internal name of the system</li> <li>[ ] Purpose and intended use \u2014 what the system does; what problem it solves; who will use it</li> <li>[ ] Deployment scope \u2014 internal only, or customer-facing (triggering EU AI Act Article 50 obligations) [ASSUMPTION \u2014 A-006]</li> <li>[ ] Model type \u2014 e.g., LLM, RAG, classification model, rule-based system</li> <li>[ ] Third-party model provider identified [ASSUMPTION \u2014 A-004] \u2014 named provider or \"to be confirmed at Gate 4\"</li> <li>[ ] Hosting location [ASSUMPTION \u2014 A-005] \u2014 EU-based cloud, German data centre, third-party API, etc.</li> <li>[ ] Data categories \u2014 initial assessment of what personal data (if any) the system will process</li> <li>[ ] Intended users \u2014 Pickles GmbH staff only; lawyer clients; lawyer clients' end clients; all three</li> <li>[ ] System owner named \u2014 a specific named individual, not a job title, who will be responsible for ongoing compliance</li> <li>[ ] Date of intake request recorded</li> </ul> <p>Gate 1 pass criteria: All fields above complete and internally consistent. No blanks permitted.</p> <p>Regulatory basis: EU AI Act Article 11 (technical documentation requirements begin at intake); EU AI Act Article 13 (transparency and instructions for use must be designed from the start).</p>"},{"location":"stage-2-governance-foundation/L1-3.3-AI-Intake-Approval-Workflow-v1/#gate-2-risk-classification","title":"Gate 2 \u2014 Risk Classification","text":"<p>Purpose: Assign a risk tier to the system using the Risk Classification Framework (L1-3.2). The tier determines all subsequent requirements. Risk classification must be confirmed before the system is registered in the AI System Inventory (L1-3.1) as anything other than \"Pre-intake.\"</p> <p>Responsible: Compliance Lead</p> <p>Checklist:</p> <ul> <li>[ ] Decision tree applied \u2014 worked through all questions in L1-3.2 Section 3 in sequence</li> <li>[ ] Prohibited use check completed (L1-3.2 Q1) \u2014 confirm system does not fall within EU AI Act Article 5 prohibited practices; if yes, intake terminated and Legal notified</li> <li>[ ] Tier assigned \u2014 High (Tier 1), Medium (Tier 2), or Low (Tier 3)</li> <li>[ ] Classification rationale documented \u2014 specific criteria met or not met for each tier</li> <li>[ ] [LEGAL REVIEW REQUIRED for Tier 1] \u2014 if Tier 1 classification is proposed, a qualified lawyer must review the classification before Gate 2 is passed; in particular Q2 (Annex III / Recital 61) and Q6 (specific-case reliance) require legal interpretation</li> <li>[ ] Risk Classification field in L1-3.1 updated with tier and classification date</li> <li>[ ] Next gate requirements determined based on tier (see Gate 3a below)</li> </ul> <p>Gate 2 pass criteria: Tier assigned, rationale documented, and (for Tier 1) legal review completed. Classification entered in L1-3.1.</p> <p>Regulatory basis: EU AI Act Articles 6, 9 (risk-based requirements apply from design stage); EU AI Act Annex III and Recital 61 (legal AI classification triggers); ISO/IEC 42001 Clause 8.2.</p>"},{"location":"stage-2-governance-foundation/L1-3.3-AI-Intake-Approval-Workflow-v1/#gate-3a-data-review-initial","title":"Gate 3a \u2014 Data Review (Initial)","text":"<p>Purpose: Identify all personal data categories that the system will process and determine whether a DPIA is required before processing begins.</p> <p>Responsible: DPO [ASSUMPTION \u2014 A-008] (with input from system owner and Engineering)</p> <p>Checklist:</p> <ul> <li>[ ] Personal data categories mapped \u2014 list all categories the system will process: general personal data (GDPR Article 4); special categories (GDPR Article 9(1)); criminal convictions (GDPR Article 10); no personal data</li> <li>[ ] Data subjects identified \u2014 whose personal data: lawyer clients; their end clients; Pickles GmbH staff; third parties appearing in legal documents</li> <li>[ ] Data flows documented \u2014 where data enters the system, where it is processed, where it is stored, where it exits [ASSUMPTION \u2014 A-005 on hosting]</li> <li>[ ] Sub-processors identified \u2014 third-party model providers [ASSUMPTION \u2014 A-004] and any cloud infrastructure providers</li> <li>[ ] DPIA trigger assessed against GDPR Article 35 and BDSG Section 67 criteria:</li> <li>[ ] Large-scale processing of special categories (Article 9(1)) or criminal data (Article 10)</li> <li>[ ] Systematic and extensive profiling with legal or significant effects</li> <li>[ ] Systematic monitoring of publicly accessible areas (not applicable to legal AI \u2014 note only)</li> <li>[ ] Other criteria in the BfDI or EDPB lists of processing operations requiring DPIA</li> <li>[ ] DPIA trigger conclusion documented \u2014 DPIA required / not required (with reasoning)</li> </ul> <p>Gate 3a pass criteria: All data categories mapped. DPIA trigger assessment documented with conclusion.</p> <p>Regulatory basis: GDPR Articles 35, 36; GDPR Article 28 (processor obligations triggered when personal data processing confirmed); BDSG Section 67.</p>"},{"location":"stage-2-governance-foundation/L1-3.3-AI-Intake-Approval-Workflow-v1/#gate-3b-data-review-dpia-and-prior-consultation","title":"Gate 3b \u2014 Data Review (DPIA and Prior Consultation)","text":"<p>Purpose: Complete the DPIA where required and initiate BfDI prior consultation if residual risk remains high after mitigations. This gate is mandatory for Tier 1 systems and required for Tier 2 systems where Gate 3a determines a DPIA is triggered. Tier 3 systems with no personal data may proceed directly to Gate 4.</p> <p>Responsible: DPO (with Legal and Engineering input) [ASSUMPTION \u2014 A-008]</p> <p>Checklist:</p> <ul> <li>[ ] DPIA completed (where triggered) per L2-5.2 template \u2014 covering:</li> <li>[ ] Systematic description of processing operations and purposes (GDPR Article 35(7)(a))</li> <li>[ ] Assessment of necessity and proportionality (GDPR Article 35(7)(b))</li> <li>[ ] Assessment of risks to rights and freedoms of data subjects (GDPR Article 35(7)(c))</li> <li>[ ] Measures to address risks and demonstrate GDPR compliance (GDPR Article 35(7)(d))</li> <li>[ ] Data Processing Agreement (DPA) drafted under GDPR Article 28 if Pickles GmbH acts as processor [ASSUMPTION \u2014 A-007] \u2014 template at Stage 3</li> <li>[ ] Vendor DPA assessed for any third-party model provider [ASSUMPTION \u2014 A-004] \u2014 template at L2-5.3</li> <li>[ ] Section 43e BRAO service agreement assessed for lawyer clients [ASSUMPTION \u2014 A-002] [LEGAL REVIEW REQUIRED]</li> <li>[ ] Residual risk assessed \u2014 high, medium, or low after mitigations applied</li> <li>[ ] BfDI prior consultation initiated if residual high risk (GDPR Article 36; BDSG Section 69) [LEGAL REVIEW REQUIRED \u2014 must be initiated at design stage, not post-deployment]</li> <li>[ ] DPO sign-off recorded on DPIA conclusion and residual risk assessment</li> </ul> <p>Gate 3b pass criteria: DPIA complete (where required); DPAs in place or in progress; BfDI consultation initiated where required; DPO sign-off recorded.</p> <p>Regulatory basis: GDPR Articles 28, 35, 36; BDSG Sections 67, 69; BRAO Section 43e [ASSUMPTION \u2014 A-002].</p>"},{"location":"stage-2-governance-foundation/L1-3.3-AI-Intake-Approval-Workflow-v1/#gate-4-legal-and-regulatory-review","title":"Gate 4 \u2014 Legal and Regulatory Review","text":"<p>Purpose: Confirm that the system as designed and documented complies with all applicable regulatory obligations. For Tier 1 systems, this includes the EU AI Act conformity assessment. For all customer-facing systems, this includes BRAK professional obligation review.</p> <p>Responsible: Legal (qualified lawyer with EU AI Act expertise) and Compliance Lead</p> <p>Checklist:</p> <p>For all tiers: - [ ] EU AI Act obligations confirmed for the assigned risk tier \u2014 documentation, transparency, logging, human oversight requirements all planned and feasible - [ ] AI transparency disclosure designed for customer-facing systems (EU AI Act Article 50) [ASSUMPTION \u2014 A-006] - [ ] Human oversight design reviewed against L1-3.4 \u2014 confirm no fully automated legal advice output; mandatory review steps designed in - [ ] Legal review of classification rationale for Tier 1 systems (if not already completed at Gate 2)</p> <p>Tier 1 additional requirements: - [ ] Conformity assessment process initiated (EU AI Act Articles 16-23) \u2014 internal conformity assessment or notified body assessment as applicable - [ ] Technical Documentation Pack initiated (EU AI Act Article 11) \u2014 template L2-4.2 - [ ] EU AI Act Article 13 transparency content drafted \u2014 instructions for use, known limitations, human oversight requirements, intended purpose statement - [ ] Declaration of Conformity pathway confirmed (EU AI Act Article 47)</p> <p>BRAK / professional obligation review (for lawyer-facing systems): - [ ] Anwaltgeheimnis compliance assessed \u2014 professional secrecy obligations satisfied [ASSUMPTION \u2014 A-002] - [ ] Section 43e BRAO IT outsourcing requirements satisfied \u2014 where system relies on a third-party provider [ASSUMPTION \u2014 A-004] [LEGAL REVIEW REQUIRED] - [ ] BRAK professional liability framework reviewed \u2014 responsibility allocation between Pickles GmbH and lawyer client documented</p> <p>Gate 4 pass criteria: Legal sign-off documented. All Tier 1 conformity assessment steps initiated. Customer-facing transparency content drafted. No unresolved legal blockers.</p> <p>Regulatory basis: EU AI Act Articles 6, 9, 11, 13, 16-23, 47, 50; BRAO Section 43e; BRAK Position Paper December 2024 Section 2.1.</p>"},{"location":"stage-2-governance-foundation/L1-3.3-AI-Intake-Approval-Workflow-v1/#gate-5-engineering-sign-off","title":"Gate 5 \u2014 Engineering Sign-Off","text":"<p>Purpose: Confirm that the technical implementation satisfies all security, logging, monitoring, and documentation requirements for the assigned risk tier before deployment proceeds.</p> <p>Responsible: Engineering Lead (with Security review where applicable)</p> <p>Checklist:</p> <p>For all tiers: - [ ] Security review completed \u2014 at minimum: access controls, authentication, data in transit (encryption), data at rest (encryption), input validation, output sanitisation - [ ] Logging configured as required for tier:   - Tier 1: Automatic logging mandatory (EU AI Act Article 12; BDSG Section 76) \u2014 logging of inputs, outputs, oversight decisions, anomalies   - Tier 2: Operational logging of interactions and errors   - Tier 3: Basic system logging - [ ] Hosting location confirmed as EU-based [ASSUMPTION \u2014 A-005]; if not EU-based, flag immediately to Legal and DPO for Article 44-49 GDPR transfer assessment - [ ] Monitoring configured per L3-6.1 requirements for tier:   - Tier 1: Continuous active monitoring with KPIs defined   - Tier 2: Periodic monitoring (minimum quarterly)   - Tier 3: Annual review schedule set</p> <p>Tier 1 additional requirements: - [ ] Technical Documentation Pack (L2-4.2) complete \u2014 all required sections populated - [ ] Human oversight mechanisms tested \u2014 system cannot produce outputs that bypass mandatory review step - [ ] Audit trail tested \u2014 logging captures events required under EU AI Act Article 12 - [ ] Incident response integration tested \u2014 system feeds into L3-6.2 Incident Response Playbook</p> <p>Tier 2 additional requirements: - [ ] AI interaction transparency implemented \u2014 EU AI Act Article 50 disclosure active for any system that interacts with natural persons</p> <p>Gate 5 pass criteria: Engineering sign-off recorded. All tier-specific logging and monitoring configured and tested. No unresolved security issues.</p> <p>Regulatory basis: EU AI Act Articles 9, 11, 12, 14; GDPR Article 32; BDSG Section 64 (technical controls); BDSG Section 76 (audit logging).</p>"},{"location":"stage-2-governance-foundation/L1-3.3-AI-Intake-Approval-Workflow-v1/#gate-6-deployment-approval","title":"Gate 6 \u2014 Deployment Approval","text":"<p>Purpose: Final cross-functional sign-off confirming all gates have been passed, all documentation is complete, and the system is authorised to proceed to Production status.</p> <p>Responsible: See sign-off authority table below.</p> <p>Checklist:</p> <ul> <li>[ ] All previous gates confirmed passed \u2014 written records of Gate 1-5 completions on file</li> <li>[ ] AI System Inventory (L1-3.1) entry complete and accurate \u2014 all fields populated with verified information; no placeholders</li> <li>[ ] Deployment Status set to \"Staging\" before any production traffic; Production only after this gate is passed</li> <li>[ ] Monitoring Status set to \"Active Monitoring\" (Tier 1/2) or \"Not Required\" (Tier 3) in L1-3.1</li> <li>[ ] System owner confirmed \u2014 named individual (not job title) recorded in L1-3.1</li> <li>[ ] Incident response pathway confirmed \u2014 system owner and Engineering Lead know the escalation pathway per L3-6.2</li> <li>[ ] Post-market monitoring plan active (EU AI Act Article 72 for Tier 1) \u2014 KPIs defined, monitoring schedule set</li> <li>[ ] First review date scheduled in L1-3.1</li> </ul> <p>Sign-off authority by tier:</p> Tier Required Sign-Offs Tier 1 \u2014 High Risk (1) Legal and Compliance Lead; (2) DPO [ASSUMPTION \u2014 A-008]; (3) Engineering Lead; (4) CEO or designated C-suite executive Tier 2 \u2014 Medium Risk (1) Compliance Lead; (2) Engineering Lead Tier 3 \u2014 Low Risk (1) Engineering Lead <p>Gate 6 pass criteria: All required sign-offs obtained and documented. L1-3.1 entry complete. Deployment Status set to Production.</p> <p>Regulatory basis: EU AI Act Articles 16-23 (obligations of providers before market placement); EU AI Act Article 72 (post-market monitoring obligation begins at deployment); ISO/IEC 42001 Clause 8.4 (deployment requirements).</p>"},{"location":"stage-2-governance-foundation/L1-3.3-AI-Intake-Approval-Workflow-v1/#substantive-modification-process","title":"Substantive Modification Process","text":"<p>A deployed system that undergoes substantive modification must re-enter this workflow at the appropriate gate. A modification is substantive under EU AI Act Article 3(23) if it affects the intended purpose, the AI model or its performance, or the risk level of the system.</p> Modification Type Re-entry Point Notes Change to AI model architecture or provider Gate 2 Re-run full risk classification; may require new conformity assessment Change in intended purpose or deployment scope Gate 2 Scope change may change risk tier Change in data categories processed Gate 3a Re-assess DPIA trigger Change from internal to customer-facing Gate 2 Likely triggers transparency obligations and tier upgrade Change of third-party model provider [ASSUMPTION \u2014 A-004] Gate 3b New vendor DPA required; re-run L2-5.3 Security or infrastructure change affecting logging Gate 5 Engineering re-sign-off required Minor bug fix or performance change without scope change No re-entry Document in change log; confirm not substantive per Article 3(23) <p>[LEGAL REVIEW REQUIRED] The definition of \"substantive modification\" under EU AI Act Article 3(23) requires legal interpretation in each specific case. When in doubt, treat a modification as substantive and re-enter the workflow.</p>"},{"location":"stage-2-governance-foundation/L1-3.3-AI-Intake-Approval-Workflow-v1/#roles-and-responsibilities","title":"Roles and Responsibilities","text":"Role Responsibility in This Workflow System Owner (named individual) Initiates intake; completes Gate 1; responsible for ongoing compliance post-deployment Compliance Lead Leads Gate 2 (risk classification) and Gate 4 (legal/regulatory review); final compliance sign-off for Tier 2 DPO [ASSUMPTION \u2014 A-008] Leads Gate 3a and Gate 3b (data review and DPIA); DPO sign-off for Tier 1 and any system triggering DPIA Legal Gate 4 legal review; Tier 1 classification review; BRAO/BRAK compliance confirmation Engineering Lead Gate 5 technical review; Engineering sign-off; post-deployment monitoring configuration CEO / C-suite Gate 6 final sign-off for Tier 1 systems only"},{"location":"stage-2-governance-foundation/L1-3.3-AI-Intake-Approval-Workflow-v1/#blocked-system-protocol","title":"Blocked System Protocol","text":"<p>If a system is blocked at any gate:</p> <ol> <li>Written blocking reason produced by the gate reviewer within 2 business days of assessment</li> <li>Blocking reason communicated to the system owner and recorded against the system in L1-3.1</li> <li>System status remains \"Development\" or \"Staging\" \u2014 may not advance to Production</li> <li>Resolution pathway agreed \u2014 system owner and gate reviewer agree remediation steps</li> <li>Re-assessment \u2014 system re-presents at the blocked gate; previous gate completions remain valid unless the modification affects them</li> </ol> <p>A system that is blocked and subsequently abandoned must have its L1-3.1 entry updated to \"Suspended\" or \"Decommissioned\" with a reason noted.</p> <p>This workflow is a governance control document. Completion of all gates is a prerequisite for deployment. No exceptions.</p> <p>[LEGAL REVIEW REQUIRED] The application of this workflow to specific Pickles GmbH systems requires legal review before operational use. In particular: Gate 2 risk classification for legal AI tools; Gate 3b BDSG Section 69 prior consultation timing; and Gate 4 Section 43e BRAO compliance for any system relying on a third-party AI model provider.</p>"},{"location":"stage-2-governance-foundation/L1-3.4-Human-Oversight-Policy-v1/","title":"Human Oversight Policy","text":"<p>Project: Pickles GmbH \u2014 AI Governance Framework Stage: Stage 2 \u2014 Governance Foundation Status: Draft Version: v1 Date: 2026-02-22 Assumptions: Built on outline assumptions \u2014 not verified against real Pickles GmbH data</p>"},{"location":"stage-2-governance-foundation/L1-3.4-Human-Oversight-Policy-v1/#purpose","title":"Purpose","text":"<p>This policy defines the minimum human oversight requirements for all AI systems operated or deployed by Pickles GmbH [ASSUMPTION \u2014 A-001, A-003]. It establishes that no AI output produced by any Pickles GmbH system may constitute final legal advice delivered to a client without review and authorisation by a qualified human lawyer.</p> <p>The policy exists because:</p> <ol> <li>The EU AI Act (Article 14) requires that high-risk AI systems be designed and operated to allow effective human oversight throughout their lifecycle.</li> <li>BRAK professional standards (Position Paper, December 2024) require that AI outputs in legal practice be subject to human review and that responsibility for legal advice cannot be delegated to an AI system.</li> <li>GDPR Article 22 prohibits decisions based solely on automated processing that produce legal or similarly significant effects on individuals, without appropriate safeguards.</li> <li>Professional liability under German law rests with the qualified lawyer (Rechtsanwalt), not with the AI system or its provider.</li> </ol> <p>Regulatory basis: - EU AI Act Article 14 \u2014 Human oversight obligations for high-risk AI systems - EU AI Act Article 13 \u2014 Transparency obligations including instructions for human oversight - EU AI Act Article 50 \u2014 Disclosure when interacting with natural persons via AI; AI-generated content labelling obligations - GDPR Article 22 \u2014 Right not to be subject to solely automated decisions with legal or significant effects - BRAK Position Paper (December 2024) Section 2.1 \u2014 Lawyer responsibility; human review requirements - BRAO Section 43a(1) \u2014 Lawyer's duty of professional independence - BRAO Section 43e \u2014 IT service obligations for German law practices [ASSUMPTION \u2014 A-002] - ISO/IEC 42001 Clause A.6 \u2014 Human oversight in AI system design</p>"},{"location":"stage-2-governance-foundation/L1-3.4-Human-Oversight-Policy-v1/#section-1-core-principle","title":"Section 1: Core Principle","text":"<p>Pickles GmbH AI systems are tools to support qualified human legal professionals. They do not replace human legal judgement. No AI output from any Pickles GmbH system may be delivered to a client as final legal advice or as the basis for a decision with legal or significant effects on an individual without a competent human lawyer having reviewed, verified, and taken professional responsibility for that output.</p> <p>This principle applies regardless of: - The quality or apparent accuracy of the AI output - The risk tier of the system - Time pressure or operational convenience - Client expectations or requests</p> <p>Regulatory basis summary:</p> Principle Regulatory Basis No solely automated legal advice GDPR Article 22(1); BRAK Position Paper Section 2.1 Lawyer retains professional responsibility BRAO Section 43a(1); BRAK Position Paper Human oversight designed into system EU AI Act Article 14; ISO/IEC 42001 Clause A.6 Transparency about AI involvement EU AI Act Articles 13, 50; BRAK Position Paper Section 3"},{"location":"stage-2-governance-foundation/L1-3.4-Human-Oversight-Policy-v1/#section-2-prohibited-practices","title":"Section 2: Prohibited Practices","text":"<p>The following practices are prohibited across all Pickles GmbH systems and must be technically and contractually prevented where feasible.</p> Prohibited Practice Basis Delivering AI output directly to a client as legal advice without lawyer review GDPR Article 22(1); BRAK Position Paper Section 2.1; BRAO Section 43a(1) Designing a system workflow that permits AI output to bypass a human review step before client delivery EU AI Act Article 14; BRAK Position Paper Section 2.1 Representing AI output as the independent opinion of a qualified lawyer without disclosure that AI was used in its preparation EU AI Act Article 50; BRAK Position Paper Section 3 Using AI to make decisions on client matters \u2014 including decisions to proceed, settle, or advise \u2014 without lawyer oversight GDPR Article 22(1); BRAO Section 43a(1) Disabling or bypassing AI output labelling or transparency disclosures for customer-facing systems EU AI Act Article 50 [ASSUMPTION \u2014 A-006] Deploying a Tier 1 (High Risk) system without documented human oversight design reviewed by Legal EU AI Act Article 14; L1-3.3 Gate 4 <p>[LEGAL REVIEW REQUIRED] The precise boundaries of GDPR Article 22 in the context of AI-assisted legal work require legal analysis in specific deployment contexts. The obligation not to make decisions based solely on automated processing applies where the decision has legal or similarly significant effects \u2014 the application of this threshold to AI-assisted legal research or drafting outputs must be assessed per use case.</p>"},{"location":"stage-2-governance-foundation/L1-3.4-Human-Oversight-Policy-v1/#section-3-permitted-uses-of-ai-output","title":"Section 3: Permitted Uses of AI Output","text":"<p>The following uses of AI output are permitted, subject to the review requirements in Section 4:</p> Permitted Use Conditions Regulatory Note Legal drafting assistance \u2014 generating draft clauses, letters, or documents Mandatory lawyer review and amendment before use; AI involvement disclosed BRAK Position Paper; EU AI Act Article 14 Legal research \u2014 retrieving case law, legislation, commentary Lawyer verifies all citations before reliance; output not delivered directly to client as research BRAK Position Paper Section 2.2 Document summarisation \u2014 condensing contracts, judgments, or regulatory texts Lawyer reviews summary and confirms accuracy before relying on it EU AI Act Article 14 Internal analysis \u2014 pattern identification, administrative automation Standard professional judgement applies; no client-facing output without review EU AI Act Article 14 Client-facing AI interaction \u2014 chatbots or research portals interacting with natural persons [ASSUMPTION \u2014 A-006] Must comply with EU AI Act Article 50 disclosure; must not produce specific legal advice for specific facts EU AI Act Articles 13, 50"},{"location":"stage-2-governance-foundation/L1-3.4-Human-Oversight-Policy-v1/#section-4-review-requirements-by-risk-tier","title":"Section 4: Review Requirements by Risk Tier","text":""},{"location":"stage-2-governance-foundation/L1-3.4-Human-Oversight-Policy-v1/#tier-1-high-risk-systems","title":"Tier 1 \u2014 High Risk Systems","text":"<p>For every AI output produced by a Tier 1 system that is to be relied upon in a legal matter or delivered to a client:</p> <ol> <li> <p>Mandatory documented review. The reviewing lawyer must record: (a) that they have reviewed the AI output; (b) the date of review; (c) any amendments made; and (d) that they take professional responsibility for the output as reviewed and amended.</p> </li> <li> <p>Competence requirement. The reviewing lawyer must have sufficient competence in the relevant area of law to evaluate the AI output critically. Reliance on AI output in an area where the reviewing lawyer lacks competence does not satisfy this requirement. [LEGAL REVIEW REQUIRED \u2014 professional competence obligations under BRAO; BRAK Position Paper Section 2.3]</p> </li> <li> <p>Override capability. The system must permit the reviewing lawyer to reject, amend, or override any AI output at any stage. No workflow design may prevent override.</p> </li> <li> <p>Hallucination and citation check. For legal research or drafting outputs, the reviewing lawyer must verify all cited cases, statutes, and legal propositions independently before reliance. AI-generated citations must not be assumed accurate.</p> </li> <li> <p>No automated client delivery. Tier 1 system outputs must not be automatically forwarded to clients. A human step must intervene between AI output generation and any client delivery.</p> </li> </ol> <p>Minimum review record format (Tier 1):</p> Field Content System ID e.g., SYS-001 Date of AI output [date] Reviewing lawyer [name] Date of review [date] Amendments made [describe amendments, or \"none \u2014 output used as generated after verification\"] Professional responsibility accepted Yes / No Notes [any concerns flagged for Compliance Lead]"},{"location":"stage-2-governance-foundation/L1-3.4-Human-Oversight-Policy-v1/#tier-2-medium-risk-systems","title":"Tier 2 \u2014 Medium Risk Systems","text":"<p>For Tier 2 systems, human review is required before any output is relied upon, but the documentation requirement is less intensive than Tier 1:</p> <ol> <li>Review before reliance. Outputs must be reviewed by a qualified professional before being relied upon in legal work or delivered to a client.</li> <li>No formal review record required unless the output is used in a Tier 1 context (in which case Tier 1 requirements apply).</li> <li>Error reporting. Any suspected error, hallucination, or unreliable output must be reported to the system owner or Compliance Lead using the incident pathway in L3-6.2.</li> <li>AI involvement disclosed where required under EU AI Act Article 50 (customer-facing systems).</li> </ol>"},{"location":"stage-2-governance-foundation/L1-3.4-Human-Oversight-Policy-v1/#tier-3-low-risk-systems","title":"Tier 3 \u2014 Low Risk Systems","text":"<p>Standard professional judgement applies. No additional review requirements beyond those applicable to any professional tool. Errors should be reported to Engineering Lead.</p>"},{"location":"stage-2-governance-foundation/L1-3.4-Human-Oversight-Policy-v1/#section-5-mandatory-disclaimer-requirements","title":"Section 5: Mandatory Disclaimer Requirements","text":""},{"location":"stage-2-governance-foundation/L1-3.4-Human-Oversight-Policy-v1/#51-output-disclaimers","title":"5.1 Output Disclaimers","text":"<p>All AI outputs produced by Pickles GmbH systems that are made available to lawyer clients or their end clients must carry a disclaimer meeting the following minimum requirements [ASSUMPTION \u2014 A-002]:</p> <p>Minimum required disclaimer content: 1. The output was generated or assisted by an artificial intelligence system 2. The output has not been independently verified by a qualified lawyer unless that has occurred 3. The output does not constitute legal advice 4. The recipient should seek qualified legal advice before relying on the output for any legal matter</p> <p>Suggested standard disclaimer text (to be reviewed by Legal before operational use) [LEGAL REVIEW REQUIRED]:</p> <p>This document was produced with the assistance of an artificial intelligence system operated by Pickles GmbH. It has not been independently verified by a qualified lawyer unless explicitly stated. It does not constitute legal advice and should not be relied upon as such. Recipients should seek advice from a qualified lawyer before acting on any content in this document.</p>"},{"location":"stage-2-governance-foundation/L1-3.4-Human-Oversight-Policy-v1/#52-ai-output-labelling-eu-ai-act","title":"5.2 AI Output Labelling (EU AI Act)","text":"<p>Under EU AI Act Article 50(1), any system that interacts with natural persons must disclose that they are interacting with an AI system, unless this is obvious from the context [ASSUMPTION \u2014 A-006].</p> <p>Under EU AI Act Article 50(2) and (5), AI-generated content must be labelled in a machine-readable format.</p> <p>Required labelling for customer-facing systems:</p> Obligation Trigger Required Action Regulatory Basis Disclosure of AI interaction Any system interacting with natural persons Disclosure at or before first interaction EU AI Act Article 50(1) AI-generated content label Any AI-generated output including text, audio, image Machine-readable label from August 2026 EU AI Act Article 50 Instructions for use High-risk systems User-facing documentation explaining purpose, limitations, and oversight requirements EU AI Act Article 13 Transparency to lawyer clients All customer-facing systems [ASSUMPTION \u2014 A-006] Contractual disclosure in service agreement; BRAK Position Paper alignment BRAK Position Paper Section 3"},{"location":"stage-2-governance-foundation/L1-3.4-Human-Oversight-Policy-v1/#section-6-responsibility-allocation","title":"Section 6: Responsibility Allocation","text":""},{"location":"stage-2-governance-foundation/L1-3.4-Human-Oversight-Policy-v1/#61-summary-table","title":"6.1 Summary Table","text":"Responsibility Pickles GmbH Lawyer Client [ASSUMPTION \u2014 A-002] AI system design and operation \u2713 \u2014 Accuracy of AI model outputs (best efforts) \u2713 \u2014 Disclosure that AI is used in service delivery \u2713 \u2014 Compliance with EU AI Act obligations as provider/deployer \u2713 \u2014 Data processing obligations as processor [ASSUMPTION \u2014 A-007] \u2713 \u2014 Review and verification of AI output before reliance \u2014 \u2713 Professional responsibility for legal advice given to clients \u2014 \u2713 Compliance with BRAO/BRAK professional obligations \u2014 \u2713 Decision to use AI output in a specific client matter \u2014 \u2713 Disclosure to end clients that AI was used Provides disclosure tools and templates \u2713 (final responsibility)"},{"location":"stage-2-governance-foundation/L1-3.4-Human-Oversight-Policy-v1/#62-pickles-gmbh-obligations","title":"6.2 Pickles GmbH Obligations","text":"<p>Pickles GmbH, as the operator of AI systems used by German legal professionals, accepts the following responsibilities:</p> <ol> <li>System design: Design AI systems with mandatory human oversight steps that cannot be bypassed</li> <li>Transparency: Disclose clearly in service agreements and product interfaces that AI systems are used and their limitations</li> <li>Documentation: Maintain technical documentation, risk assessments, and monitoring records as required under EU AI Act and GDPR</li> <li>Incident response: Maintain and activate an Incident Response Playbook (L3-6.2) for AI system failures, errors, and data breaches</li> <li>Limitation disclosure: Proactively communicate known model limitations, hallucination risks, and known error types to lawyer clients</li> </ol>"},{"location":"stage-2-governance-foundation/L1-3.4-Human-Oversight-Policy-v1/#63-lawyer-client-obligations-assumption-a-002","title":"6.3 Lawyer Client Obligations [ASSUMPTION \u2014 A-002]","text":"<p>Pickles GmbH's service agreements must require that lawyer clients using Pickles GmbH AI systems accept the following obligations [ASSUMPTION \u2014 A-007] [LEGAL REVIEW REQUIRED]:</p> <ol> <li>Mandatory review: All AI outputs used in legal matters are reviewed by a competent qualified lawyer before reliance</li> <li>Professional responsibility: The lawyer accepts professional responsibility for any output they rely upon or deliver to their client</li> <li>Disclosure: The lawyer discloses to their end clients that AI was used in the preparation of any advice or document, where required by BRAK guidelines or professional rules</li> <li>Training: Lawyers using Pickles GmbH systems have sufficient competence to evaluate AI outputs critically in the relevant area of law</li> <li>Anwaltgeheimnis compliance: Lawyers comply with their professional secrecy obligations when inputting client data into Pickles GmbH systems</li> </ol>"},{"location":"stage-2-governance-foundation/L1-3.4-Human-Oversight-Policy-v1/#section-7-special-considerations","title":"Section 7: Special Considerations","text":""},{"location":"stage-2-governance-foundation/L1-3.4-Human-Oversight-Policy-v1/#71-client-facing-ai-interaction-assumption-a-006","title":"7.1 Client-Facing AI Interaction [ASSUMPTION \u2014 A-006]","text":"<p>Where a Pickles GmbH system allows direct AI-to-human interaction with lawyer clients or their end clients (e.g., a legal research portal or chatbot interface):</p> <ul> <li>The system must disclose at the start of every interaction that the user is communicating with an AI (EU AI Act Article 50(1))</li> <li>The system must be designed to refuse to answer questions that require specific legal advice for specific facts unless a qualified human lawyer is in the loop</li> <li>Client-facing systems must be classified as Tier 2 or Tier 1 (not Tier 3) and must comply with all relevant transparency requirements</li> </ul>"},{"location":"stage-2-governance-foundation/L1-3.4-Human-Oversight-Policy-v1/#72-ai-in-criminal-proceedings-legal-review-required","title":"7.2 AI in Criminal Proceedings [LEGAL REVIEW REQUIRED]","text":"<p>The use of AI in criminal proceedings warrants heightened caution. BRAK notes that the stakes in criminal matters (personal liberty) are particularly high. Any Pickles GmbH system used in criminal proceedings must be classified as Tier 1 (High Risk) regardless of other criteria, and the human oversight requirements in Section 4 (Tier 1) must be applied with particular rigour.</p>"},{"location":"stage-2-governance-foundation/L1-3.4-Human-Oversight-Policy-v1/#73-third-party-model-limitations-assumption-a-004","title":"7.3 Third-Party Model Limitations [ASSUMPTION \u2014 A-004]","text":"<p>Where Pickles GmbH uses a third-party AI model provider, Pickles GmbH cannot fully control model behaviour, training data, or model updates. Lawyer clients must be informed that:</p> <ul> <li>The underlying model may change over time</li> <li>Pickles GmbH monitors for performance degradation per L3-6.1 but cannot guarantee consistent output quality across all model versions</li> <li>Human oversight is the primary safeguard against model error or degradation</li> </ul>"},{"location":"stage-2-governance-foundation/L1-3.4-Human-Oversight-Policy-v1/#74-override-and-refusal","title":"7.4 Override and Refusal","text":"<p>No system designed or operated by Pickles GmbH may prevent a human reviewer from: - Refusing to use an AI output - Amending an AI output before use - Raising concerns about an AI output through the incident pathway (L3-6.2) - Switching off or suspending their use of the system pending clarification</p>"},{"location":"stage-2-governance-foundation/L1-3.4-Human-Oversight-Policy-v1/#regulatory-basis-appendix","title":"Regulatory Basis Appendix","text":"Policy Section Requirement Regulatory Basis Section 1 (Core Principle) No solely automated legal decisions GDPR Article 22(1) Section 1 (Core Principle) Human oversight designed in EU AI Act Article 14; ISO/IEC 42001 Clause A.6 Section 1 (Core Principle) Lawyer retains professional responsibility BRAO Section 43a(1); BRAK Position Paper Section 2.1 Section 2 (Prohibited Practices) No bypass of review step EU AI Act Article 14 Section 2 (Prohibited Practices) No solely automated decisions with legal effects GDPR Article 22(1) Section 2 (Prohibited Practices) No suppression of AI disclosure EU AI Act Article 50 Section 4 (Tier 1 Review) Documented human oversight EU AI Act Article 14; BRAK Position Paper Section 4 (Tier 1 Review) Override capability EU AI Act Article 14(4) Section 5 (Disclaimers) Disclosure of AI use EU AI Act Article 50; BRAK Position Paper Section 3 Section 5 (Disclaimers) AI-generated content labelling EU AI Act Article 50 (from August 2026) Section 5 (Disclaimers) Instructions for use EU AI Act Article 13 Section 6 (Responsibility) Provider obligations before deployment EU AI Act Articles 16-23 Section 6 (Responsibility) Processor obligations GDPR Article 28 [ASSUMPTION \u2014 A-007] Section 6 (Responsibility) IT service obligations BRAO Section 43e [ASSUMPTION \u2014 A-002] <p>This policy is a governance control document. It is binding on all Pickles GmbH staff and must be incorporated by reference into service agreements with lawyer clients [ASSUMPTION \u2014 A-002].</p> <p>[LEGAL REVIEW REQUIRED] This policy requires review by a qualified German lawyer with expertise in EU AI Act, GDPR, and BRAO/BRAK professional obligations before operational implementation. In particular: the application of GDPR Article 22 to AI-assisted legal tools; the scope of Section 43e BRAO obligations where third-party model providers are used; and the appropriate disclaimer text for client-facing AI outputs.</p>"},{"location":"stage-3-regulatory-alignment/L2-4.1-EU-AI-Act-Risk-Mapping-Matrix-v1/","title":"EU AI Act Risk Mapping Matrix","text":"<p>Project: Pickles GmbH \u2014 AI Governance Framework Stage: Stage 3 \u2014 Regulatory Alignment Status: Draft Version: v1 Date: 2026-02-26 Assumptions: Built on outline assumptions \u2014 not verified against real Pickles GmbH data</p>"},{"location":"stage-3-regulatory-alignment/L2-4.1-EU-AI-Act-Risk-Mapping-Matrix-v1/#purpose","title":"Purpose","text":"<p>This document maps Pickles GmbH's assumed AI systems against the EU AI Act (Regulation (EU) 2024/1689) risk classification framework. For each system, it identifies: the applicable risk tier, relevant articles, documentation requirements, and transparency obligations.</p> <p>Scope of this document: EU AI Act obligations only. GDPR/BDSG data protection obligations are addressed in L2-5.1 through L2-5.3.</p> <p>[ASSUMPTION] This matrix is built entirely on the assumed product line described in CLAUDE.md Section 2 (A-001). The actual Pickles GmbH product portfolio has not been verified. Before this matrix is used operationally, each system must be reviewed against the real product architecture.</p> <p>[LEGAL REVIEW REQUIRED] Risk classification under the EU AI Act is a legal determination. This matrix constitutes a preliminary analytical framework, not a compliance certification. A qualified legal practitioner familiar with EU AI Act implementation must review classifications before reliance.</p>"},{"location":"stage-3-regulatory-alignment/L2-4.1-EU-AI-Act-Risk-Mapping-Matrix-v1/#1-eu-ai-act-risk-tier-framework","title":"1. EU AI Act Risk Tier Framework","text":"<p>The EU AI Act uses a four-tier risk model. The applicable tier determines which obligations apply.</p> Tier Risk Level Primary Trigger Applicable Articles 1 Prohibited Systems posing unacceptable risks to fundamental rights Article 5 2 High-risk Systems listed in Annex III, or safety components under Annex I legislation Articles 8\u201327, 49 3 Limited-risk (transparency obligations) AI systems interacting with humans, generating synthetic content, or processing biometric/emotional data Article 50 4 Minimal-risk All other AI systems Voluntary codes only"},{"location":"stage-3-regulatory-alignment/L2-4.1-EU-AI-Act-Risk-Mapping-Matrix-v1/#2-annex-iii-high-risk-classification-assessment","title":"2. Annex III High-Risk Classification Assessment","text":"<p>Article 6(2) designates systems in Annex III as high-risk. For legal AI providers, the most relevant Annex III entry is:</p> <p>Annex III, Point 8(a): \"AI systems intended to be used by a judicial authority or on their behalf to assist a judicial authority in researching and interpreting facts and the law and in applying the law to a concrete set of facts, or to be used in a similar way in alternative dispute resolution.\"</p> <p>Critical interpretation for Pickles GmbH:</p> <p>The note at Annex III Point 8(a) in the stage-3 regulatory extracts confirms that this classification applies to judicial authorities \u2014 courts, tribunals, arbitrators acting in a judicial capacity. It does not automatically apply to AI systems used by lawyers advising clients, even where those lawyers subsequently appear before judicial authorities.</p> <p>[ASSUMPTION] Pickles GmbH's clients are law firms and in-house legal departments (A-002), not judicial authorities. Subject to verification, Pickles GmbH's systems provisionally do not fall under Annex III Point 8(a).</p> <p>However, the following circumstances could change this assessment: - If Pickles GmbH markets to, or sells to, judicial bodies or court-appointed experts [LEGAL REVIEW REQUIRED] - If output from Pickles GmbH systems is directly integrated into judicial decision workflows without intermediate lawyer review [LEGAL REVIEW REQUIRED]</p> <p>Article 6(3) Derogation Check:</p> <p>Even if a system appeared in Annex III, Article 6(3) provides that it shall not be considered high-risk where it: - Performs a narrow procedural task (Article 6(3)(a)) - Improves the result of a previously completed human activity (Article 6(3)(b)) - Detects patterns without replacing human assessment without proper human review (Article 6(3)(c)) - Performs a preparatory task to an assessment (Article 6(3)(d))</p> <p>Note: Article 6(3) does not apply if the system performs profiling of natural persons (Article 6(3) final subparagraph). Legal research and drafting systems are unlikely to perform profiling, but this must be confirmed per system.</p>"},{"location":"stage-3-regulatory-alignment/L2-4.1-EU-AI-Act-Risk-Mapping-Matrix-v1/#3-ai-system-risk-classification-matrix","title":"3. AI System Risk Classification Matrix","text":""},{"location":"stage-3-regulatory-alignment/L2-4.1-EU-AI-Act-Risk-Mapping-Matrix-v1/#31-assumed-pickles-gmbh-ai-systems","title":"3.1 Assumed Pickles GmbH AI Systems","text":"<p>[ASSUMPTION] The following four AI system categories are assumed to represent the Pickles GmbH product portfolio (A-001). Each must be validated against the actual product architecture.</p> System ID System Name Description Primary Users SYS-01 Legal Research Assistant AI-powered case law, legislation, and commentary search and summarisation Lawyers, paralegals [ASSUMPTION] SYS-02 Document Drafting Tool AI-assisted generation and auto-completion of legal documents, contracts, and briefs Lawyers [ASSUMPTION] SYS-03 Document Summarisation Tool AI summarisation of lengthy legal documents, judgments, and contracts Lawyers, in-house legal [ASSUMPTION] SYS-04 Legal Analysis Tool AI analysis of legal risk, interpretation, and issue identification in documents or fact patterns Lawyers [ASSUMPTION]"},{"location":"stage-3-regulatory-alignment/L2-4.1-EU-AI-Act-Risk-Mapping-Matrix-v1/#32-full-risk-matrix","title":"3.2 Full Risk Matrix","text":""},{"location":"stage-3-regulatory-alignment/L2-4.1-EU-AI-Act-Risk-Mapping-Matrix-v1/#sys-01-legal-research-assistant","title":"SYS-01 \u2014 Legal Research Assistant","text":"Dimension Assessment Regulatory Basis Prohibited (Tier 1)? No \u2014 does not meet any Article 5 prohibition criteria Article 5 High-risk (Tier 2)? Provisionally No \u2014 Annex III Point 8(a) applies to judicial authorities; Pickles GmbH clients are lawyers [ASSUMPTION] Article 6(2), Annex III Point 8(a) Article 6(3) derogation applicable? Likely yes \u2014 performs preparatory task (Article 6(3)(d)); improves result of human activity (Article 6(3)(b)) [LEGAL REVIEW REQUIRED] Article 6(3) Profiling of natural persons? Provisionally No \u2014 research tool, not user-profiling [ASSUMPTION \u2014 confirm against real system] Article 6(3) final subparagraph Provisional risk tier Tier 3 \u2014 Limited-risk Article 50 Article 6(4) self-assessment required? Yes \u2014 provider must document non-high-risk assessment before placing on market Article 6(4) Article 50 triggers Article 50(1): if system interacts directly with end users (lawyers querying the system) \u2014 disclosure required that they are interacting with an AI [ASSUMPTION] Article 50(1) Documentation requirements Article 6(4) self-assessment record; Article 50 compliance documentation Articles 6(4), 50 Transparency to users Must inform users they are interacting with AI system unless obvious Article 50(1) AI competence requirement Yes \u2014 Article 4 requires Pickles GmbH to ensure staff and users have sufficient AI competence Article 4"},{"location":"stage-3-regulatory-alignment/L2-4.1-EU-AI-Act-Risk-Mapping-Matrix-v1/#sys-02-document-drafting-tool","title":"SYS-02 \u2014 Document Drafting Tool","text":"Dimension Assessment Regulatory Basis Prohibited (Tier 1)? No Article 5 High-risk (Tier 2)? Provisionally No \u2014 not within Annex III categories for lawyer-facing use [ASSUMPTION] Article 6(2), Annex III Article 6(3) derogation applicable? Likely yes \u2014 assistive function improving result of human activity (Article 6(3)(b)) [LEGAL REVIEW REQUIRED] Article 6(3) Profiling of natural persons? Provisionally No [ASSUMPTION \u2014 confirm against real system] Article 6(3) final subparagraph Provisional risk tier Tier 3 \u2014 Limited-risk Article 50 Article 6(4) self-assessment required? Yes Article 6(4) Article 50 triggers Article 50(1): direct user interaction \u2014 AI disclosure required; Article 50(2): if generating synthetic text content (drafts, clauses) \u2014 machine-readable marking required Articles 50(1), 50(2) Article 50(2) exemption? Possible \u2014 Article 50(2) exempts systems performing \"assistive function for standard editing\" or not \"substantially altering input data\" [LEGAL REVIEW REQUIRED] Article 50(2) Documentation requirements Article 6(4) self-assessment; Article 50(2) technical marking records Articles 6(4), 50 Transparency to users AI interaction disclosure (Article 50(1)); AI-generated content marking unless assistive exemption applies (Article 50(2)) Article 50 AI competence requirement Yes \u2014 Article 4 Article 4"},{"location":"stage-3-regulatory-alignment/L2-4.1-EU-AI-Act-Risk-Mapping-Matrix-v1/#sys-03-document-summarisation-tool","title":"SYS-03 \u2014 Document Summarisation Tool","text":"Dimension Assessment Regulatory Basis Prohibited (Tier 1)? No Article 5 High-risk (Tier 2)? Provisionally No Article 6(2), Annex III Article 6(3) derogation applicable? Strongly likely \u2014 narrow procedural task (Article 6(3)(a)); preparatory task (Article 6(3)(d)) Article 6(3) Profiling of natural persons? Provisionally No [ASSUMPTION] Article 6(3) final subparagraph Provisional risk tier Tier 3 \u2014 Limited-risk (possibly Tier 4 \u2014 Minimal-risk) [LEGAL REVIEW REQUIRED] Article 50 Article 6(4) self-assessment required? Yes Article 6(4) Article 50 triggers Article 50(1): if direct user interaction \u2014 AI disclosure; Article 50(2): if generating synthetic text (summaries) \u2014 marking required unless assistive exemption Articles 50(1), 50(2) Article 50(2) exemption? Summaries may be considered synthetic text generation \u2014 not clearly an \"assistive function for standard editing\" [LEGAL REVIEW REQUIRED] Article 50(2) Documentation requirements Article 6(4) self-assessment; Article 50 compliance records Articles 6(4), 50 Transparency to users AI disclosure at first interaction; summary output marked as AI-generated unless exemption applies Article 50 AI competence requirement Yes \u2014 Article 4 Article 4"},{"location":"stage-3-regulatory-alignment/L2-4.1-EU-AI-Act-Risk-Mapping-Matrix-v1/#sys-04-legal-analysis-tool","title":"SYS-04 \u2014 Legal Analysis Tool","text":"Dimension Assessment Regulatory Basis Prohibited (Tier 1)? No Article 5 High-risk (Tier 2)? Uncertain \u2014 requires formal legal assessment [LEGAL REVIEW REQUIRED] Article 6(2), Annex III Point 8(a) Annex III Point 8(a) risk If outputs are used directly in judicial proceedings or as basis for consequential legal decisions affecting persons, Annex III Point 8(a) may be engaged [ASSUMPTION] Annex III Point 8(a) Article 6(3) derogation applicable? Possible \u2014 if tool performs preparatory task only (Article 6(3)(d)) and human lawyer makes final legal assessment. Does not apply if profiling of natural persons occurs. [LEGAL REVIEW REQUIRED] Article 6(3) Profiling of natural persons? Risk is higher for analysis tools \u2014 must be confirmed against actual system design [ASSUMPTION] Article 6(3) final subparagraph Provisional risk tier Tier 2 (High-risk) or Tier 3 (Limited-risk) \u2014 classification contingent on product architecture and client use patterns [LEGAL REVIEW REQUIRED] Articles 6, 50 If High-risk: applicable obligations Full Chapter III obligations: risk management system (Art. 9), data governance (Art. 10), technical documentation (Art. 11, Annex IV), logging (Art. 12), transparency to deployers (Art. 13), human oversight (Art. 14), accuracy/robustness/cybersecurity (Art. 15), quality management (Art. 17), conformity assessment (Art. 43), EU declaration of conformity (Art. 47), registration (Art. 49) Articles 8\u201327, 43, 47, 49 If Limited-risk: applicable obligations Article 6(4) self-assessment; Article 50 transparency Articles 6(4), 50 Documentation requirements If high-risk: full Annex IV technical documentation; if limited-risk: Article 6(4) assessment + Article 50 records Articles 11, Annex IV, 6(4), 50 AI competence requirement Yes \u2014 Article 4 Article 4"},{"location":"stage-3-regulatory-alignment/L2-4.1-EU-AI-Act-Risk-Mapping-Matrix-v1/#4-article-obligation-matrix-high-risk-systems","title":"4. Article Obligation Matrix \u2014 High-Risk Systems","text":"<p>If SYS-04 is determined to be high-risk [LEGAL REVIEW REQUIRED], the following obligations apply in full. These obligations are also documented here for reference should any other system be reclassified.</p> Article Obligation Owner [ASSUMPTION] Status Article 9 Establish and maintain a documented risk management system throughout system lifecycle Head of Product / AIRO [ASSUMPTION] \u2610 Not yet implemented Article 10 Data governance: training/validation/testing data quality, bias examination Head of Engineering [ASSUMPTION] \u2610 Not yet implemented Article 11 + Annex IV Technical documentation drawn up before market placement and kept up to date Head of Engineering [ASSUMPTION] \u2610 Not yet implemented Article 12 Automatic event logging capabilities; retain logs as specified Head of Engineering [ASSUMPTION] \u2610 Not yet implemented Article 13 Instructions for use: system characteristics, limitations, human oversight design, log interpretation Product / Legal [ASSUMPTION] \u2610 Not yet implemented Article 14 Human oversight mechanisms embedded in system design; users must be able to override, disregard, or halt outputs Head of Product [ASSUMPTION] \u2610 Not yet implemented Article 15 Accuracy, robustness, and cybersecurity performance targets declared; resilience against adversarial inputs Head of Engineering [ASSUMPTION] \u2610 Not yet implemented Article 16(c) Quality management system (Article 17) CEO / AIRO [ASSUMPTION] \u2610 Not yet implemented Article 17 Documented QMS including strategy, testing, data management, risk management, incident reporting CEO / AIRO [ASSUMPTION] \u2610 Not yet implemented Article 25(4) Written agreements with third-party AI model providers specifying information and capabilities required for compliance CEO / Legal [ASSUMPTION] \u2610 Not yet implemented Article 26 Deployer (Pickles GmbH's clients) obligations \u2014 relevant to inform clients of their duties when using high-risk AI Legal / Client Success [ASSUMPTION] \u2610 Not yet implemented Article 43 Conformity assessment before market placement CEO / Legal [ASSUMPTION] \u2610 Not yet implemented Article 47 EU declaration of conformity CEO / Legal [ASSUMPTION] \u2610 Not yet implemented Article 49(1) Registration in EU AI Act database CEO / Legal [ASSUMPTION] \u2610 Not yet implemented"},{"location":"stage-3-regulatory-alignment/L2-4.1-EU-AI-Act-Risk-Mapping-Matrix-v1/#5-article-50-transparency-obligations-all-systems","title":"5. Article 50 Transparency Obligations \u2014 All Systems","text":"<p>Regardless of high-risk classification, Article 50 applies to all Pickles GmbH AI systems in the following circumstances:</p> Obligation Trigger Systems Affected Action Required Article 50(1) \u2014 AI interaction disclosure System \"intended to interact directly with natural persons\" SYS-01, SYS-02, SYS-03, SYS-04 [ASSUMPTION] Inform users at first interaction that they are interacting with an AI system Article 50(1) \u2014 Exemption Disclosure not required if AI nature is \"obvious\" from context to a reasonably well-informed user All systems \u2014 assess per system [LEGAL REVIEW REQUIRED] whether lawyer-facing AI tool interaction is \"obvious\" Article 50(2) \u2014 Synthetic content marking System generates synthetic audio, image, video or text content SYS-02 (drafts), SYS-03 (summaries), SYS-04 (analysis outputs) [ASSUMPTION] Outputs must be marked in machine-readable format as AI-generated Article 50(2) \u2014 Assistive exemption Does not apply where system performs \"assistive function for standard editing\" SYS-02 \u2014 partial exemption possible; SYS-03, SYS-04 \u2014 less clear [LEGAL REVIEW REQUIRED] Legal review required per system Article 50(5) \u2014 Timing Disclosure must be provided \"at the latest at the time of the first interaction or exposure\" All systems Implement at onboarding / first login"},{"location":"stage-3-regulatory-alignment/L2-4.1-EU-AI-Act-Risk-Mapping-Matrix-v1/#6-value-chain-obligations","title":"6. Value Chain Obligations","text":"<p>Article 25 imposes obligations on the AI value chain, relevant where Pickles GmbH uses third-party AI model providers:</p> <p>[ASSUMPTION] Pickles GmbH may use third-party AI model providers (A-004). If so:</p> Obligation Basis Action Required Pickles GmbH must treat itself as a provider under Article 16 if it substantially modifies a third-party AI system or places its brand on it Article 25(1)(a)(b) Confirm modification scope with model providers [ASSUMPTION] Written agreement with third-party providers must specify information, technical access, and capabilities needed for Pickles GmbH to comply with EU AI Act Article 25(4) Include in vendor contracts \u2014 see L2-5.3 If third-party model is a general-purpose AI model (GPAI), additional Chapter V obligations may apply to the GPAI provider Articles 51\u201356 Review model provider's compliance status [ASSUMPTION]"},{"location":"stage-3-regulatory-alignment/L2-4.1-EU-AI-Act-Risk-Mapping-Matrix-v1/#7-article-4-ai-competence-obligation","title":"7. Article 4 \u2014 AI Competence Obligation","text":"<p>Article 4 applies from 2 February 2025 and is not contingent on high-risk classification. It requires that Pickles GmbH:</p> <p>Take measures to ensure, to the best of their ability, that their personnel and other persons involved in the operation and use of AI systems on their behalf have a sufficient level of AI competence.</p> <p>Per the BRAK AI Position Paper (December 2024), AI competence requirements also apply to lawyers as operators of AI systems under Article 3(4) EU AI Act. Pickles GmbH's client-facing materials should therefore support clients' own Article 4 compliance.</p> <p>[ASSUMPTION] Pickles GmbH's internal AI competence training programme has not been verified. See L1-3.1 and L1-3.4 for related governance structures.</p>"},{"location":"stage-3-regulatory-alignment/L2-4.1-EU-AI-Act-Risk-Mapping-Matrix-v1/#8-compliance-readiness-summary","title":"8. Compliance Readiness Summary","text":"System Provisional Tier High-Risk Uncertainty Article 50 Applies Article 6(4) Required AI Competence (Art. 4) SYS-01 Legal Research Assistant Tier 3 \u2014 Limited-risk Low [ASSUMPTION] Yes Yes Yes SYS-02 Document Drafting Tool Tier 3 \u2014 Limited-risk Low [ASSUMPTION] Yes (incl. Art. 50(2)) Yes Yes SYS-03 Document Summarisation Tier 3 or Tier 4 [LEGAL REVIEW REQUIRED] Low [ASSUMPTION] Likely yes Yes Yes SYS-04 Legal Analysis Tool Tier 2 or Tier 3 [LEGAL REVIEW REQUIRED] High Yes Yes Yes <p>Priority action: SYS-04 requires a formal Article 6(4) risk classification assessment by a qualified EU AI Act practitioner before any market placement or operational deployment. [LEGAL REVIEW REQUIRED]</p>"},{"location":"stage-3-regulatory-alignment/L2-4.1-EU-AI-Act-Risk-Mapping-Matrix-v1/#9-key-dates-eu-ai-act-application-timeline","title":"9. Key Dates \u2014 EU AI Act Application Timeline","text":"Date Event Impact on Pickles GmbH 1 August 2024 Regulation entered into force Regulation applies 2 February 2025 Chapters I and II apply (including Article 4 \u2014 AI competence) AI competence obligations now active 2 August 2025 Chapter V (GPAI models) and Chapter III Section 4 (notified bodies) apply Relevant if using GPAI model providers 2 August 2026 Full application including Article 50 (transparency obligations) and Chapter III high-risk obligations Transparency obligations and high-risk obligations fully active 2 August 2027 High-risk AI systems as safety components under existing products (Annex I) \u2014 delayed application Not directly applicable to Pickles GmbH [ASSUMPTION] <p>Note: Article 50 transparency obligations for limited-risk systems apply from 2 August 2026 per Article 113. Article 4 (AI competence) already applies from 2 February 2025.</p>"},{"location":"stage-3-regulatory-alignment/L2-4.1-EU-AI-Act-Risk-Mapping-Matrix-v1/#document-control","title":"Document Control","text":"Field Detail Document ID L2-4.1 Next review After SYS-04 legal classification assessment [LEGAL REVIEW REQUIRED] Cross-references L1-3.1 (AI System Inventory), L1-3.2 (Risk Classification), L2-4.2 (Technical Documentation Template), L2-4.3 (Transparency Framework) Assumptions relied upon A-001, A-002, A-003, A-004, A-005"},{"location":"stage-3-regulatory-alignment/L2-4.2-Technical-Documentation-Pack-Template-v1/","title":"Technical Documentation Pack \u2014 Template","text":"<p>Project: Pickles GmbH \u2014 AI Governance Framework Stage: Stage 3 \u2014 Regulatory Alignment Status: Draft Version: v1 Date: 2026-02-26 Assumptions: Built on outline assumptions \u2014 not verified against real Pickles GmbH data</p>"},{"location":"stage-3-regulatory-alignment/L2-4.2-Technical-Documentation-Pack-Template-v1/#how-to-use-this-template","title":"How to Use This Template","text":"<p>This is a reusable template for producing EU AI Act-compliant technical documentation for each AI system operated by Pickles GmbH. It is structured to satisfy the minimum content requirements of Annex IV of the EU AI Act (Regulation (EU) 2024/1689), as mandated by Article 11.</p> <p>When to complete this template: - Before any new AI system is placed on the market or put into service (Article 11(1)) - Whenever an existing system undergoes a substantial modification that affects its classification or compliance status (Article 6(2)) - During conformity assessment procedures (Article 43) \u2014 if a system is or becomes high-risk</p> <p>How to use it: 1. Complete one copy of this template per AI system 2. Replace all <code>[PLACEHOLDER]</code> fields with real system data 3. Mark any section where data is unavailable with <code>[DATA REQUIRED \u2014 reason]</code> 4. Store the completed document in the Pickles GmbH document management system with version control 5. Update the document whenever a change occurs that affects any of the declared fields</p> <p>Template ID convention: <code>TECH-DOC-[SYSTEM-ID]-v[VERSION]</code> Example: <code>TECH-DOC-SYS-01-v1</code></p> <p>[LEGAL REVIEW REQUIRED] Technical documentation for high-risk systems is a legal compliance requirement under Article 11. Incomplete or inaccurate documentation constitutes non-compliance. A qualified EU AI Act practitioner must review any completed technical documentation before it is relied upon for conformity assessment.</p>"},{"location":"stage-3-regulatory-alignment/L2-4.2-Technical-Documentation-Pack-Template-v1/#section-0-document-header","title":"SECTION 0 \u2014 Document Header","text":"Field Value System Name <code>[PLACEHOLDER \u2014 e.g., Legal Research Assistant]</code> System ID <code>[PLACEHOLDER \u2014 e.g., SYS-01]</code> Document ID <code>[PLACEHOLDER \u2014 e.g., TECH-DOC-SYS-01-v1]</code> Version <code>[PLACEHOLDER \u2014 e.g., v1]</code> Date of Initial Documentation <code>[PLACEHOLDER \u2014 DD-MM-YYYY]</code> Date of Last Update <code>[PLACEHOLDER \u2014 DD-MM-YYYY]</code> Prepared by <code>[PLACEHOLDER \u2014 name and role]</code> Reviewed by <code>[PLACEHOLDER \u2014 name, role, and date]</code> EU AI Act Risk Classification <code>[PLACEHOLDER \u2014 Tier 1 / Tier 2 (High-risk) / Tier 3 (Limited-risk) / Tier 4 (Minimal-risk)]</code> Annex III Category (if high-risk) <code>[PLACEHOLDER \u2014 e.g., Annex III Point 8(a) \u2014 or \"Not applicable\"]</code> Provider Name Pickles GmbH Provider Legal Address <code>[PLACEHOLDER \u2014 registered address]</code> Provider Contact <code>[PLACEHOLDER \u2014 contact email]</code> Authorised Representative (if applicable) <code>[PLACEHOLDER \u2014 or \"Not applicable\"]</code>"},{"location":"stage-3-regulatory-alignment/L2-4.2-Technical-Documentation-Pack-Template-v1/#section-1-general-description-of-the-ai-system","title":"SECTION 1 \u2014 General Description of the AI System","text":"<p>Basis: Annex IV, Point 1</p>"},{"location":"stage-3-regulatory-alignment/L2-4.2-Technical-Documentation-Pack-Template-v1/#11-intended-purpose","title":"1.1 Intended Purpose","text":"<p>Instructions: Describe what the AI system is designed to do, for whom, and in what context. Be specific \u2014 this description defines the legal scope of the system's obligations. Reference Article 13(3)(b)(i).</p> <p><code>[PLACEHOLDER \u2014 Example: \"This system is designed to assist qualified lawyers and paralegals at German law firms and in-house legal departments in searching, retrieving, and summarising publicly available case law, legislative texts, and legal commentary. It is not designed to provide legal advice and is not intended for use as the sole basis for legal decisions.\"]</code></p> <p>Intended users: <code>[PLACEHOLDER \u2014 e.g., qualified lawyers, trainees, paralegals]</code> Intended deployment context: <code>[PLACEHOLDER \u2014 e.g., law firm intranet, SaaS platform, API integration]</code> Use cases explicitly excluded from intended purpose: <code>[PLACEHOLDER \u2014 e.g., judicial decision-making, automated legal advice without lawyer review]</code></p>"},{"location":"stage-3-regulatory-alignment/L2-4.2-Technical-Documentation-Pack-Template-v1/#12-system-identification-and-version","title":"1.2 System Identification and Version","text":"<p>Instructions: Provide sufficient detail for a competent authority to uniquely identify the system and distinguish it from other versions.</p> Field Value System name <code>[PLACEHOLDER]</code> Version number <code>[PLACEHOLDER]</code> Relationship to previous versions <code>[PLACEHOLDER \u2014 e.g., \"First release\" or \"Replaces v1.2 \u2014 changes: updated model weights, new document type support\"]</code> Date of version <code>[PLACEHOLDER]</code>"},{"location":"stage-3-regulatory-alignment/L2-4.2-Technical-Documentation-Pack-Template-v1/#13-software-and-hardware-interfaces","title":"1.3 Software and Hardware Interfaces","text":"<p>Basis: Annex IV, Point 1(b)(c)</p> <p>Software integrations: <code>[PLACEHOLDER \u2014 list other software, APIs, or AI systems this system interacts with, e.g., \"Integrates with client document management system via REST API; uses [third-party model provider] API for language model inference [ASSUMPTION]\"]</code></p> <p>Hardware requirements for deployment: <code>[PLACEHOLDER \u2014 e.g., \"Runs on cloud infrastructure; client requires minimum browser version [X]; no dedicated hardware\"]</code></p> <p>Relevant software version requirements: <code>[PLACEHOLDER]</code></p> <p>Update requirements: <code>[PLACEHOLDER \u2014 e.g., \"System auto-updates; major version changes require client notification under Service Agreement\"]</code></p>"},{"location":"stage-3-regulatory-alignment/L2-4.2-Technical-Documentation-Pack-Template-v1/#14-forms-in-which-the-system-is-placed-on-the-market-or-put-into-service","title":"1.4 Forms in Which the System Is Placed on the Market or Put into Service","text":"<p>Basis: Annex IV, Point 1(d)</p> <p><code>[PLACEHOLDER \u2014 e.g., \"Delivered as SaaS platform via web browser interface and REST API. No embedded hardware component.\"]</code></p>"},{"location":"stage-3-regulatory-alignment/L2-4.2-Technical-Documentation-Pack-Template-v1/#15-user-interface-description","title":"1.5 User Interface Description","text":"<p>Basis: Annex IV, Point 1(g)(h)</p> <p>User interface summary: <code>[PLACEHOLDER \u2014 brief description of the interface provided to users/deployers]</code></p> <p>Instructions for use provided to deployers: <code>[PLACEHOLDER \u2014 confirm format: e.g., \"Digital documentation provided at onboarding; in-application help system; dedicated knowledge base at [URL]\"]</code></p>"},{"location":"stage-3-regulatory-alignment/L2-4.2-Technical-Documentation-Pack-Template-v1/#section-2-development-and-technical-architecture","title":"SECTION 2 \u2014 Development and Technical Architecture","text":"<p>Basis: Annex IV, Point 2</p>"},{"location":"stage-3-regulatory-alignment/L2-4.2-Technical-Documentation-Pack-Template-v1/#21-development-methods-and-steps","title":"2.1 Development Methods and Steps","text":"<p>Instructions: Describe how the AI system was built. If third-party models were used, specify how they were integrated, modified, or fine-tuned. This is particularly important for Pickles GmbH's obligations under Article 25(4) regarding value chain responsibilities.</p> <p><code>[PLACEHOLDER \u2014 Example: \"The system was developed using a combination of [in-house developed components] and a pre-trained large language model provided by [third-party provider, ASSUMPTION]. The third-party model was [fine-tuned / integrated via API without modification / used as a base for retrieval-augmented generation (RAG)]. Development methodology followed [Agile / specified framework]. Testing was conducted in [specify environment].\"]</code></p> <p>Third-party models or tools used:</p> Component Provider Integration Method Modification Made <code>[PLACEHOLDER \u2014 e.g., Language model]</code> <code>[PLACEHOLDER \u2014 e.g., Third-party provider name [ASSUMPTION]]</code> <code>[PLACEHOLDER \u2014 e.g., API, fine-tuning, RAG]</code> <code>[PLACEHOLDER \u2014 e.g., None / prompt engineering / domain fine-tuning]</code> <p>[ASSUMPTION] The use of third-party AI model providers has not been confirmed (A-004). This section must be completed based on actual architecture.</p>"},{"location":"stage-3-regulatory-alignment/L2-4.2-Technical-Documentation-Pack-Template-v1/#22-design-specifications","title":"2.2 Design Specifications","text":"<p>Basis: Annex IV, Point 2(b)</p> <p>General logic of the AI system: <code>[PLACEHOLDER \u2014 e.g., \"The system uses a retrieval-augmented generation (RAG) architecture: user queries are embedded and matched against a legal document index; retrieved documents are passed to an LLM which generates a response grounded in those documents.\"]</code></p> <p>Key design choices and rationale: <code>[PLACEHOLDER \u2014 explain key architecture decisions, e.g., \"RAG architecture was selected to reduce hallucination risk by grounding outputs in verified source documents. This reflects the legal context where citation accuracy is critical.\"]</code></p> <p>Persons/groups the system is intended for: <code>[PLACEHOLDER \u2014 see Section 1.1]</code></p> <p>What the system is designed to optimise for: <code>[PLACEHOLDER \u2014 e.g., \"Accuracy of legal citation, relevance of retrieved documents, coherence of summaries\"]</code></p> <p>Expected output description and quality: <code>[PLACEHOLDER \u2014 e.g., \"Output: natural language summaries with citations to source documents. Quality target: [X]% citation accuracy against source corpus.\"]</code></p> <p>Trade-offs made in design to meet compliance requirements: <code>[PLACEHOLDER \u2014 e.g., \"Output length is constrained to reduce risk of unsupported legal conclusions; system does not generate case outcome predictions.\"]</code></p>"},{"location":"stage-3-regulatory-alignment/L2-4.2-Technical-Documentation-Pack-Template-v1/#23-system-architecture","title":"2.3 System Architecture","text":"<p>Basis: Annex IV, Point 2(c)</p> <p><code>[PLACEHOLDER \u2014 Describe how software components interact. Include a high-level architecture diagram or reference to one. Example: \"User query \u2192 front-end UI \u2192 API gateway \u2192 retrieval engine (semantic search over legal document index) \u2192 LLM inference engine \u2192 response formatter \u2192 user. Components are hosted on [cloud provider, ASSUMPTION A-005].\"]</code></p> <p>Computational resources used for development, training, testing, and validation: <code>[PLACEHOLDER]</code></p>"},{"location":"stage-3-regulatory-alignment/L2-4.2-Technical-Documentation-Pack-Template-v1/#24-training-data-where-applicable","title":"2.4 Training Data (where applicable)","text":"<p>Basis: Annex IV, Point 2(d); Article 10</p> <p>If the system uses a pre-trained third-party model with no further training by Pickles GmbH, indicate this and describe what is known about the third-party model's training data. If Pickles GmbH performs fine-tuning, this section must be completed in full.</p> Element Description Training data sources <code>[PLACEHOLDER \u2014 e.g., \"Base model trained by [third-party provider] on [published training corpus]. Pickles GmbH fine-tuning used [legal document corpus \u2014 ASSUMPTION].\"]</code> Data provenance and collection method <code>[PLACEHOLDER]</code> Data selection and filtering criteria <code>[PLACEHOLDER]</code> Annotation / labelling procedures (if applicable) <code>[PLACEHOLDER]</code> Bias examination performed <code>[PLACEHOLDER \u2014 describe what bias checks were conducted per Article 10(2)(f)]</code> Bias mitigation measures <code>[PLACEHOLDER \u2014 per Article 10(2)(g)]</code> Data gaps identified <code>[PLACEHOLDER \u2014 per Article 10(2)(h)]</code> Special categories of personal data processed in training <code>[PLACEHOLDER \u2014 if applicable, justify under Article 10(5)]</code> Validation and testing data sets <code>[PLACEHOLDER \u2014 describe sets used, distinct from training data]</code>"},{"location":"stage-3-regulatory-alignment/L2-4.2-Technical-Documentation-Pack-Template-v1/#25-human-oversight-assessment","title":"2.5 Human Oversight Assessment","text":"<p>Basis: Annex IV, Point 2(e); Article 14</p> <p><code>[PLACEHOLDER \u2014 Describe the human oversight mechanisms built into the system at design stage. Example: \"The system produces outputs labelled as AI-generated. Users are required to independently verify any legal citations before use in submissions. The system does not support automated submission of outputs to external parties without user confirmation. Override is always possible \u2014 users can ignore, edit, or discard any output.\"]</code></p> <p>Reference: Full human oversight policy is documented in L1-3.4-Human-Oversight-Policy-v1.md.</p>"},{"location":"stage-3-regulatory-alignment/L2-4.2-Technical-Documentation-Pack-Template-v1/#26-pre-determined-changes","title":"2.6 Pre-Determined Changes","text":"<p>Basis: Annex IV, Point 2(f)</p> <p><code>[PLACEHOLDER \u2014 Describe any changes to the system that have been pre-approved as part of the conformity assessment (e.g., model weight updates within defined performance bounds). If none: \"No pre-determined changes have been defined for this version. All updates will be subject to change management procedures under L3-6.3.\"]</code></p>"},{"location":"stage-3-regulatory-alignment/L2-4.2-Technical-Documentation-Pack-Template-v1/#27-validation-and-testing-procedures","title":"2.7 Validation and Testing Procedures","text":"<p>Basis: Annex IV, Point 2(g); Article 9(6)(8)</p> Element Description Validation methodology <code>[PLACEHOLDER \u2014 e.g., \"Internal evaluation against [X] benchmark legal queries; expert review by practising lawyers [ASSUMPTION]\"]</code> Testing data sets used <code>[PLACEHOLDER]</code> Accuracy metrics <code>[PLACEHOLDER \u2014 per Article 15(3) \u2014 declare accuracy metrics, e.g., citation accuracy rate, factual error rate]</code> Robustness testing <code>[PLACEHOLDER \u2014 e.g., adversarial input testing, edge case testing]</code> Testing against prohibited outputs <code>[PLACEHOLDER \u2014 e.g., tested for generation of content violating Article 5 prohibitions]</code> Test logs and reports <code>[PLACEHOLDER \u2014 reference to test logs. Test logs and reports must be dated and signed by responsible person per Annex IV Point 2(g)]</code> Frequency of testing <code>[PLACEHOLDER \u2014 per Article 9(8): \"testing shall be performed at any time throughout the development process, and in any event, prior to market placement\"]</code>"},{"location":"stage-3-regulatory-alignment/L2-4.2-Technical-Documentation-Pack-Template-v1/#28-cybersecurity-measures","title":"2.8 Cybersecurity Measures","text":"<p>Basis: Annex IV, Point 2(h); Article 15</p> <p><code>[PLACEHOLDER \u2014 Describe technical cybersecurity measures implemented. Should cover at minimum: data poisoning prevention (Article 15(5)), adversarial example resistance, model evasion countermeasures, access controls, encryption. Example: \"Input validation and prompt injection defences implemented at API layer. Model inference is isolated from training environment. API access requires authenticated credentials. Data in transit and at rest encrypted using AES-256 / TLS 1.3.\"]</code></p>"},{"location":"stage-3-regulatory-alignment/L2-4.2-Technical-Documentation-Pack-Template-v1/#section-3-monitoring-functioning-and-control","title":"SECTION 3 \u2014 Monitoring, Functioning, and Control","text":"<p>Basis: Annex IV, Point 3; Articles 12, 13, 14, 15</p>"},{"location":"stage-3-regulatory-alignment/L2-4.2-Technical-Documentation-Pack-Template-v1/#31-capabilities-and-limitations","title":"3.1 Capabilities and Limitations","text":"<p><code>[PLACEHOLDER \u2014 Declare the system's known performance capabilities and limitations. Example: \"The system achieves [X]% citation accuracy on [benchmark]. Accuracy decreases for pre-2010 legal sources [ASSUMPTION]. The system does not interpret ambiguous legislative provisions \u2014 it retrieves and presents options. The system cannot predict judicial outcomes and is not designed to do so. Known limitations: hallucination risk on queries outside the training corpus; limited coverage of regional court decisions [ASSUMPTION].\"]</code></p>"},{"location":"stage-3-regulatory-alignment/L2-4.2-Technical-Documentation-Pack-Template-v1/#32-foreseeable-unintended-outcomes-and-risk-sources","title":"3.2 Foreseeable Unintended Outcomes and Risk Sources","text":"<p><code>[PLACEHOLDER \u2014 List foreseeable risks per Article 9(2)(a). Example: \"Foreseeable risks include: (1) citation of outdated law (mitigation: source currency metadata displayed); (2) lawyer over-reliance on AI output without independent verification (mitigation: outputs labelled as AI-generated; independent review required per L1-3.4); (3) inclusion of confidential client data in prompts (mitigation: data handling training; privacy by design architecture).\"]</code></p>"},{"location":"stage-3-regulatory-alignment/L2-4.2-Technical-Documentation-Pack-Template-v1/#33-human-oversight-mechanisms-operational","title":"3.3 Human Oversight Mechanisms (Operational)","text":"<p><code>[PLACEHOLDER \u2014 Describe the human oversight measures that deployers can use in practice, per Article 14(4). Example: \"Users are able to: (a) review all output before use; (b) edit or discard any output; (c) flag outputs as inaccurate via in-product reporting tool; (d) halt any query session at any time. No output is automatically transmitted to third parties.\"]</code></p>"},{"location":"stage-3-regulatory-alignment/L2-4.2-Technical-Documentation-Pack-Template-v1/#34-input-data-specifications","title":"3.4 Input Data Specifications","text":"<p><code>[PLACEHOLDER \u2014 Describe what input data the system accepts and any constraints. Example: \"System accepts natural language text queries in German and English. Document upload accepts PDF and DOCX formats up to [X]MB. System does not accept audio, image, or biometric data.\"]</code></p>"},{"location":"stage-3-regulatory-alignment/L2-4.2-Technical-Documentation-Pack-Template-v1/#section-4-performance-metrics-appropriateness","title":"SECTION 4 \u2014 Performance Metrics Appropriateness","text":"<p>Basis: Annex IV, Point 4; Article 15</p> <p><code>[PLACEHOLDER \u2014 Explain why the chosen accuracy and performance metrics are appropriate for this AI system's intended purpose. Example: \"Citation accuracy rate is the primary metric because the system's intended purpose is to surface legally accurate references. Factual error rate measures hallucination frequency. Both metrics are appropriate because the system is used for legal research where source accuracy is the primary client requirement. Metrics are calculated against a curated benchmark of [X] annotated legal queries reviewed by qualified lawyers [ASSUMPTION].\"]</code></p>"},{"location":"stage-3-regulatory-alignment/L2-4.2-Technical-Documentation-Pack-Template-v1/#section-5-risk-management-system","title":"SECTION 5 \u2014 Risk Management System","text":"<p>Basis: Annex IV, Point 5; Article 9</p> <p><code>[PLACEHOLDER \u2014 Provide a summary reference to the risk management system. For high-risk systems, a full description is required. Example: \"The risk management system for this AI system is documented in [risk management system document]. It follows Article 9 requirements: continuous iterative process; covers identification, estimation, evaluation, and mitigation of known and foreseeable risks throughout the system lifecycle. Risk management measures address risks identified in Section 3.2 above.\"]</code></p> <p>Reference to risk management documentation: <code>[PLACEHOLDER \u2014 document reference]</code></p>"},{"location":"stage-3-regulatory-alignment/L2-4.2-Technical-Documentation-Pack-Template-v1/#section-6-changes-made-through-the-lifecycle","title":"SECTION 6 \u2014 Changes Made Through the Lifecycle","text":"<p>Basis: Annex IV, Point 6; Article 6(2)</p> <p>Instructions: This section is updated throughout the system's operational life. Maintain a log of all substantive changes.</p> Date Change Description Version Substantial Modification? Responsible Person <code>[DD-MM-YYYY]</code> <code>[PLACEHOLDER \u2014 e.g., \"Initial release\"]</code> v1 N/A <code>[PLACEHOLDER]</code> \u2014 \u2014 \u2014 \u2014 \u2014 <p>Note on substantial modifications: A change that affects the system's risk classification (Article 6), its intended purpose, or its performance in ways that would affect Annex IV documentation triggers re-assessment. This is addressed in the Model Change Management Protocol (L3-6.3).</p>"},{"location":"stage-3-regulatory-alignment/L2-4.2-Technical-Documentation-Pack-Template-v1/#section-7-standards-and-technical-specifications","title":"SECTION 7 \u2014 Standards and Technical Specifications","text":"<p>Basis: Annex IV, Point 7</p> Standard / Specification Status Notes ISO/IEC 42001:2023 \u2014 AI Management System <code>[PLACEHOLDER \u2014 Applied / Partially applied / Under assessment]</code> Relevant to AI management system governance [ASSUMPTION] ISO/IEC 27001 \u2014 Information Security Management <code>[PLACEHOLDER]</code> Relevant to Article 15 cybersecurity requirements [ASSUMPTION] ENISA AI Cybersecurity Guidelines <code>[PLACEHOLDER]</code> Non-binding but referenced for Article 15 implementation [ASSUMPTION] Harmonised EU AI Act standards (pending CEN/CENELEC publication) Not yet published as of 2026-02-26 [LEGAL REVIEW REQUIRED] \u2014 monitor for published harmonised standards under Article 40"},{"location":"stage-3-regulatory-alignment/L2-4.2-Technical-Documentation-Pack-Template-v1/#section-8-eu-declaration-of-conformity","title":"SECTION 8 \u2014 EU Declaration of Conformity","text":"<p>Basis: Annex IV, Point 8; Article 47 (high-risk systems only)</p> <p>This section applies only to high-risk AI systems. For limited-risk systems, this section is marked not applicable.</p> <p><code>[PLACEHOLDER \u2014 For high-risk systems: \"A copy of the EU declaration of conformity as required by Article 47 is appended to this document as Annex A.\" For limited-risk systems: \"Not applicable \u2014 system classified as limited-risk.\"]</code></p>"},{"location":"stage-3-regulatory-alignment/L2-4.2-Technical-Documentation-Pack-Template-v1/#section-9-post-market-monitoring-plan","title":"SECTION 9 \u2014 Post-Market Monitoring Plan","text":"<p>Basis: Annex IV, Point 9; Article 72 (high-risk systems only)</p> <p>For high-risk systems, Article 72 requires a post-market monitoring plan. For limited-risk systems, good practice is to maintain operational monitoring \u2014 this is addressed in L3-6.1 (AI Monitoring Framework).</p> <p><code>[PLACEHOLDER \u2014 For high-risk systems: \"Post-market monitoring plan is appended as Annex B. It covers: monitoring metrics (see L3-6.1), reporting frequency, trigger events for remedial action, notification obligations to competent authorities under Article 73, and serious incident reporting under Article 73.\" For limited-risk systems: \"Post-market monitoring follows the operational monitoring framework in L3-6.1. Incident response follows L3-6.2.\"]</code></p>"},{"location":"stage-3-regulatory-alignment/L2-4.2-Technical-Documentation-Pack-Template-v1/#section-10-logging-and-record-keeping","title":"SECTION 10 \u2014 Logging and Record-Keeping","text":"<p>Basis: Article 12; Article 26(6) (deployer obligations)</p> <p><code>[PLACEHOLDER \u2014 Describe logging capabilities. For high-risk systems, Article 12 requires automatic event logging. For all systems, logging supports governance and incident response. Example: \"The system automatically logs: session start and end timestamps; query inputs and system outputs (retained for [X] days [ASSUMPTION]); error events; override/discard events by users. Logs are stored on [EU-based infrastructure, ASSUMPTION A-005]. Log retention period is [X] days, compliant with applicable data protection law [LEGAL REVIEW REQUIRED \u2014 confirm against GDPR Article 5(1)(e) storage limitation].\"]</code></p>"},{"location":"stage-3-regulatory-alignment/L2-4.2-Technical-Documentation-Pack-Template-v1/#appendices-to-complete-when-finalising-this-template","title":"Appendices to Complete When Finalising This Template","text":"Appendix Description Required For Annex A EU Declaration of Conformity High-risk systems only Annex B Post-Market Monitoring Plan High-risk systems only Annex C Test Logs and Signed Test Reports All systems (good practice) Annex D Data Processing Agreement with Third-Party Model Provider Where applicable (A-004) Annex E Bias Assessment Report Where applicable"},{"location":"stage-3-regulatory-alignment/L2-4.2-Technical-Documentation-Pack-Template-v1/#document-control","title":"Document Control","text":"Field Detail Template ID L2-4.2 Template applies to All Pickles GmbH AI systems Cross-references L2-4.1 (Risk Mapping Matrix), L1-3.1 (AI System Inventory), L1-3.4 (Human Oversight Policy), L3-6.1 (Monitoring Framework), L3-6.2 (Incident Response), L3-6.3 (Model Change Management) Regulatory basis EU AI Act Article 11, Annex IV Assumptions relied upon A-001, A-002, A-004, A-005"},{"location":"stage-3-regulatory-alignment/L2-4.3-Transparency-Disclosure-Framework-v1/","title":"Transparency Disclosure Framework","text":"<p>Project: Pickles GmbH \u2014 AI Governance Framework Stage: Stage 3 \u2014 Regulatory Alignment Status: Draft Version: v1 Date: 2026-02-26 Assumptions: Built on outline assumptions \u2014 not verified against real Pickles GmbH data</p>"},{"location":"stage-3-regulatory-alignment/L2-4.3-Transparency-Disclosure-Framework-v1/#purpose","title":"Purpose","text":"<p>This framework defines Pickles GmbH's transparency obligations under the EU AI Act and related regulatory instruments, and sets out how those obligations are operationalised across Pickles GmbH's products, client communications, and website.</p> <p>Transparency in this context operates at three levels: 1. System-level transparency \u2014 what Pickles GmbH must disclose to deployers (its lawyer clients) about how its AI systems work (EU AI Act, Article 13) 2. User-level transparency \u2014 what must be disclosed to persons interacting with AI systems (EU AI Act, Article 50) 3. Professional transparency \u2014 what lawyers using Pickles GmbH tools must disclose to their own clients under BRAK professional rules (BRAK AI Position Paper, Section 4)</p> <p>[ASSUMPTION] This framework is built on the assumed product portfolio (A-001) and assumed client base of legal professionals (A-002). All disclosure obligations must be reviewed against the actual product architecture and actual client contracts.</p> <p>[LEGAL REVIEW REQUIRED] This framework constitutes a planning document, not legal advice. Transparency obligations under the EU AI Act are subject to phased implementation (see Section 2.1). A qualified practitioner must confirm applicability to each Pickles GmbH product before reliance.</p>"},{"location":"stage-3-regulatory-alignment/L2-4.3-Transparency-Disclosure-Framework-v1/#1-regulatory-basis","title":"1. Regulatory Basis","text":"Instrument Relevant Provisions Topic EU AI Act (Regulation (EU) 2024/1689) Article 13 Transparency to deployers of high-risk systems EU AI Act Article 50(1) Disclosure that user is interacting with an AI system EU AI Act Article 50(2) Machine-readable marking of AI-generated synthetic content EU AI Act Article 50(5) Timing of disclosure (first interaction or exposure) EU AI Act Article 4 AI competence \u2014 operators must ensure users have AI literacy EU AI Act Article 6(4) Provider's self-assessment documentation (non-high-risk Annex III systems) GDPR (Regulation (EU) 2016/679) Articles 13, 14 Data subject information at collection GDPR Article 22 Disclosure of automated decision-making (if applicable) BRAK AI Position Paper (December 2024) Section 4 Professional transparency obligations for lawyers using AI BRAK AI Position Paper Section 3 Attorney-client confidentiality \u2014 indirect transparency obligation"},{"location":"stage-3-regulatory-alignment/L2-4.3-Transparency-Disclosure-Framework-v1/#2-application-timeline","title":"2. Application Timeline","text":""},{"location":"stage-3-regulatory-alignment/L2-4.3-Transparency-Disclosure-Framework-v1/#21-eu-ai-act-implementation-dates","title":"2.1 EU AI Act Implementation Dates","text":"<p>Transparency obligations are being phased in. The following dates are relevant to Pickles GmbH's planning:</p> Date Obligation Basis 2 February 2025 (active) Article 4 AI competence obligations apply Article 113(1), Article 4 2 August 2026 Article 50 transparency obligations fully apply (AI interaction disclosure, synthetic content marking) Article 113(6) 2 August 2026 Full Chapter III high-risk obligations apply (incl. Article 13 deployer information) Article 113(6) <p>Practical implication: Pickles GmbH should implement Article 50 disclosures by 2 August 2026 at the latest, and should treat earlier voluntary implementation as best practice demonstrating good governance. Article 4 (AI competence) obligations apply now.</p>"},{"location":"stage-3-regulatory-alignment/L2-4.3-Transparency-Disclosure-Framework-v1/#3-system-level-transparency-instructions-to-deployers-article-13","title":"3. System-Level Transparency \u2014 Instructions to Deployers (Article 13)","text":""},{"location":"stage-3-regulatory-alignment/L2-4.3-Transparency-Disclosure-Framework-v1/#31-when-article-13-applies","title":"3.1 When Article 13 Applies","text":"<p>Article 13 of the EU AI Act applies to high-risk AI systems only. It requires providers to accompany their systems with instructions for use in digital format, containing specific information for deployers.</p> <p>[ASSUMPTION] Based on the provisional risk classification in L2-4.1, SYS-01, SYS-02, and SYS-03 are provisionally classified as limited-risk and are not subject to Article 13 in its full form. SYS-04 (Legal Analysis Tool) carries a classification uncertainty and may be subject to Article 13 if determined high-risk [LEGAL REVIEW REQUIRED].</p> <p>For limited-risk systems, Pickles GmbH should nonetheless provide equivalent information as a matter of good practice and to satisfy client due diligence expectations.</p>"},{"location":"stage-3-regulatory-alignment/L2-4.3-Transparency-Disclosure-Framework-v1/#32-required-content-article-133-information-for-deployers","title":"3.2 Required Content \u2014 Article 13(3) Information for Deployers","text":"<p>The following information must be provided in deployer-facing documentation (user manuals, onboarding materials, technical documentation) for any system classified as high-risk, and is recommended for all systems:</p> Article 13(3) Element Requirement Pickles GmbH Implementation 13(3)(a) \u2014 Provider identity Name, contact details of provider Include in all product documentation and Terms of Service [ASSUMPTION] 13(3)(b)(i) \u2014 Intended purpose Clear description of what the system is for Included in product Terms of Service and Technical Documentation (L2-4.2 Section 1.1) [ASSUMPTION] 13(3)(b)(ii) \u2014 Accuracy metrics Level of accuracy, robustness, cybersecurity declared; known circumstances affecting performance Publish accuracy and limitation disclosures per system \u2014 see Section 5 of this document 13(3)(b)(iii) \u2014 Known risks Known/foreseeable circumstances that may lead to health, safety or fundamental rights risks Include in deployer-facing documentation \u2014 see Section 5 13(3)(b)(iv) \u2014 Explainability Technical capabilities to explain output (if applicable) Describe output interpretation guidance in user documentation [ASSUMPTION] 13(3)(b)(v) \u2014 Performance by group Performance for specific persons/groups (if applicable) Disclose if performance varies by language, jurisdiction, document type [ASSUMPTION] 13(3)(b)(vi) \u2014 Input data specs Training/validation/testing data information Reference Technical Documentation Pack (L2-4.2 Section 2.4) 13(3)(b)(vii) \u2014 Output interpretation Information enabling deployers to interpret outputs appropriately Include in user guides and in-product help [ASSUMPTION] 13(3)(d) \u2014 Human oversight measures Technical measures facilitating output interpretation and human oversight Describe in user documentation; cross-reference L1-3.4 Human Oversight Policy 13(3)(e) \u2014 Computational needs and lifecycle Hardware requirements; expected system lifetime; maintenance schedule Include in technical specifications and Service Level Agreement [ASSUMPTION] 13(3)(f) \u2014 Log collection Description of logging mechanisms for deployers to collect and interpret logs Include in technical documentation and onboarding materials [ASSUMPTION]"},{"location":"stage-3-regulatory-alignment/L2-4.3-Transparency-Disclosure-Framework-v1/#33-format-and-delivery-of-deployer-information","title":"3.3 Format and Delivery of Deployer Information","text":"<p>[ASSUMPTION] Pickles GmbH delivers client-facing documentation via: - Onboarding documentation package (digital format per Article 13(2)) - In-product help centre and knowledge base - Product-specific Terms of Service and Acceptable Use Policy</p> <p>Required minimum format: Article 13(2) requires \"concise, complete, correct and clear information that is relevant, accessible and comprehensible to deployers\" in \"an appropriate digital format or otherwise.\"</p> <p>[LEGAL REVIEW REQUIRED] Accessibility requirements under Directives (EU) 2016/2102 and (EU) 2019/882 apply to information provided to deployers. Confirm documentation meets accessibility standards.</p>"},{"location":"stage-3-regulatory-alignment/L2-4.3-Transparency-Disclosure-Framework-v1/#4-user-level-transparency-article-50-obligations","title":"4. User-Level Transparency \u2014 Article 50 Obligations","text":""},{"location":"stage-3-regulatory-alignment/L2-4.3-Transparency-Disclosure-Framework-v1/#41-article-501-disclosure-that-a-person-is-interacting-with-an-ai-system","title":"4.1 Article 50(1) \u2014 Disclosure That a Person is Interacting with an AI System","text":"<p>Trigger: The system is \"intended to interact directly with natural persons.\"</p> <p>[ASSUMPTION] Pickles GmbH's AI systems interact directly with lawyers and paralegals as users. Article 50(1) applies to all four assumed AI systems.</p> <p>Obligation: Persons must be informed that they are interacting with an AI system, at the latest at the time of the first interaction.</p> <p>Exemption: Disclosure is not required where \"it is obvious from the point of view of a natural person who is reasonably well-informed, observant and circumspect, taking into account the circumstances and the context of use.\"</p> <p>[LEGAL REVIEW REQUIRED] Whether the AI nature of a legal AI tool is \"obvious\" to lawyer users requires legal assessment. Given that (i) lawyers are sophisticated users, (ii) the product is marketed as an AI tool, and (iii) the EU AI Act's \"reasonable person\" test applies, it is possible that the exemption applies. However, Pickles GmbH should implement disclosure regardless as a conservative compliance approach.</p> <p>Implementation Requirements for Article 50(1):</p> Implementation Point Requirement Action First login / onboarding Disclosure must be made at first interaction Display AI disclosure during account setup / first session [ASSUMPTION] Disclosure language Clear, distinguishable, accessible Use plain language \u2014 see Section 4.4 for model wording Accessibility Must conform to accessibility requirements (Article 50(5)) Ensure disclosure is accessible to users with disabilities [ASSUMPTION] Timing At the latest at first interaction Do not delay until after initial engagement with outputs"},{"location":"stage-3-regulatory-alignment/L2-4.3-Transparency-Disclosure-Framework-v1/#42-article-502-marking-of-ai-generated-synthetic-content","title":"4.2 Article 50(2) \u2014 Marking of AI-Generated Synthetic Content","text":"<p>Trigger: The AI system \"generates synthetic audio, image, video or text content.\"</p> <p>[ASSUMPTION] The following Pickles GmbH systems generate synthetic text content: - SYS-02 (Document Drafting Tool) \u2014 generates draft text - SYS-03 (Document Summarisation Tool) \u2014 generates summary text - SYS-04 (Legal Analysis Tool) \u2014 generates analysis text</p> <p>Obligation: Outputs must be \"marked in a machine-readable format and detectable as artificially generated or manipulated.\" Technical solutions must be effective, interoperable, robust, and reliable.</p> <p>Exemption \u2014 Article 50(2) assistive function carve-out: The marking obligation does not apply where the AI system \"performs an assistive function for standard editing or does not substantially alter the input data provided by the deployer or the semantics thereof.\"</p> <p>[LEGAL REVIEW REQUIRED] For SYS-02 (Document Drafting): where the system completes or reformats text provided by the user, this exemption may partially apply. Where the system generates substantively new text, it does not. The boundary must be determined per system and per use case.</p> <p>Implementation Requirements for Article 50(2):</p> Implementation Point Requirement Action Machine-readable marking AI-generated outputs marked in machine-readable format Implement metadata tagging on AI-generated content [ASSUMPTION \u2014 technical architecture review required] User-visible marking Good practice: human-readable indicator alongside machine-readable marking Display \"AI-generated\" label on outputs in UI [ASSUMPTION] Technical standard Must be \"interoperable, robust, and reliable\" Monitor for published EU technical standards and codes of practice (Article 50(7)) Scope Applies per output, not per session Implement marking at output level, not session level"},{"location":"stage-3-regulatory-alignment/L2-4.3-Transparency-Disclosure-Framework-v1/#43-article-503-and-504-other-transparency-obligations","title":"4.3 Article 50(3) and 50(4) \u2014 Other Transparency Obligations","text":"<p>These provisions address emotion recognition systems, biometric categorisation systems, and deep fake generators. [ASSUMPTION] These do not apply to the assumed Pickles GmbH product portfolio. If any system is modified to include these functions, this assessment must be updated.</p>"},{"location":"stage-3-regulatory-alignment/L2-4.3-Transparency-Disclosure-Framework-v1/#44-model-disclosure-wording","title":"4.4 Model Disclosure Wording","text":"<p>The following model wording is suggested for use in Pickles GmbH's user interfaces and documentation. [LEGAL REVIEW REQUIRED] \u2014 wording should be reviewed by a legal practitioner before finalisation.</p> <p>For AI interaction disclosure (Article 50(1)):</p> <p>\"You are interacting with an AI system. The responses you receive are generated by artificial intelligence and may contain errors or inaccuracies. You should always independently verify any legal information before relying on it in professional advice or submissions.\"</p> <p>For AI-generated content label (Article 50(2)):</p> <p>\"AI-generated content. This output was produced by an AI system. Please review carefully before use.\"</p> <p>For account onboarding (combining both):</p> <p>\"Pickles GmbH uses artificial intelligence to provide legal research, drafting, and analysis assistance. All outputs are AI-generated and must be independently reviewed by a qualified lawyer before use in professional advice, submissions, or client-facing materials. By using this service, you confirm that you understand the role of AI in generating outputs and will apply appropriate professional judgement.\"</p>"},{"location":"stage-3-regulatory-alignment/L2-4.3-Transparency-Disclosure-Framework-v1/#5-client-facing-limitation-disclosures","title":"5. Client-Facing Limitation Disclosures","text":""},{"location":"stage-3-regulatory-alignment/L2-4.3-Transparency-Disclosure-Framework-v1/#51-purpose","title":"5.1 Purpose","text":"<p>Beyond the Article 50 trigger-based disclosures, Pickles GmbH should publish structured limitation disclosures for each product. These serve multiple purposes: - Satisfy Article 13(3)(b)(ii) and (iii) requirements for deployer information - Support Pickles GmbH clients' own professional obligations under BRAK Section 2.1 (lawyer duty of independent review) - Manage professional liability expectations - Demonstrate good governance for enterprise procurement</p>"},{"location":"stage-3-regulatory-alignment/L2-4.3-Transparency-Disclosure-Framework-v1/#52-standard-limitation-disclosure-structure","title":"5.2 Standard Limitation Disclosure Structure","text":"<p>Each AI system should have a published limitation disclosure covering:</p> Disclosure Element Description Hallucination risk AI systems can generate plausible but factually incorrect content. Frequency and circumstances to be disclosed per system. Jurisdictional scope Whether the system covers German law only, EU law, or other jurisdictions; and known gaps in coverage [ASSUMPTION] Temporal currency Training data cut-off date; how frequently the system is updated with new case law or legislation [ASSUMPTION] Language limitations Whether the system operates in German, English, or other languages; quality differences by language [ASSUMPTION] Output type limitations What the system does and does not produce; e.g., \"does not provide legal advice; does not predict outcomes\" Human review requirement Explicit statement that outputs require independent lawyer review before use Known failure modes Documented cases where the system performs below expected accuracy (e.g., regional courts, minority languages, specialist practice areas) [ASSUMPTION] <p>[ASSUMPTION] The specific limitation disclosures for each system must be completed based on actual system performance data, which is not available at the time of this document.</p>"},{"location":"stage-3-regulatory-alignment/L2-4.3-Transparency-Disclosure-Framework-v1/#53-brak-transparency-context-for-lawyer-clients","title":"5.3 BRAK Transparency Context for Lawyer Clients","text":"<p>The BRAK AI Position Paper (Section 4) notes that while neither the BRAO nor BORA currently impose a professional obligation on lawyers to inform clients about their use of AI tools, transparency obligations may arise from: - Contract law (duty to inform clients about essential aspects of case handling) - The Unfair Competition Act (UWG) - Best practice and risk management</p> <p>The BRAK paper advises: \"it is advisable to use AI tools transparently and, in case of doubt, to include a contractual provision with clients.\"</p> <p>Implication for Pickles GmbH: Pickles GmbH's client-facing materials should support its lawyer clients in meeting their own evolving transparency obligations. This may include: - Template client disclosure language for law firms using Pickles GmbH tools [ASSUMPTION] - Guidance on how to explain AI-assisted services to clients [ASSUMPTION] - Client-facing summaries suitable for lawyer websites or engagement letters [ASSUMPTION]</p> <p>[ASSUMPTION] This support has not been confirmed as part of the Pickles GmbH product or service offering.</p>"},{"location":"stage-3-regulatory-alignment/L2-4.3-Transparency-Disclosure-Framework-v1/#6-website-and-public-facing-disclosures","title":"6. Website and Public-Facing Disclosures","text":""},{"location":"stage-3-regulatory-alignment/L2-4.3-Transparency-Disclosure-Framework-v1/#61-recommended-website-disclosures","title":"6.1 Recommended Website Disclosures","text":"<p>[ASSUMPTION] Pickles GmbH operates a website visible to prospective and existing clients. The following disclosures are recommended as a matter of good practice and to support client due diligence:</p> Disclosure Location Content AI system description Product pages Description of AI components in each product, intended purpose, and human oversight model Data handling summary Privacy Policy How client and end-user data is processed (feeds into L2-5.1 and L2-5.2) EU AI Act compliance statement Governance / Trust page Statement of Pickles GmbH's approach to EU AI Act compliance Limitation disclosures Product documentation / Help centre Per-system limitation disclosures (Section 5.2) Sub-processor list Privacy Policy List of third-party AI model providers and other sub-processors (GDPR Article 13/14 and Article 28 requirement)"},{"location":"stage-3-regulatory-alignment/L2-4.3-Transparency-Disclosure-Framework-v1/#62-eu-ai-act-compliance-statement-suggested-content","title":"6.2 EU AI Act Compliance Statement \u2014 Suggested Content","text":"<p>[ASSUMPTION] The following suggested content for a public governance or trust page is a starting point only and must be verified against Pickles GmbH's actual compliance posture before publication:</p> <p>\"Pickles GmbH is committed to responsible AI development and compliance with the EU AI Act (Regulation (EU) 2024/1689). Our AI systems have been assessed against the EU AI Act's risk classification framework. We operate transparency practices including [AI disclosure at user interaction / AI-generated content labelling]. Our governance framework includes an AI Risk and Information Officer, human oversight policies, and a risk management process. For further information, please contact [contact details].\"</p> <p>[LEGAL REVIEW REQUIRED] A public compliance statement must be accurate and not misleading. It should only be published after legal review and after verifying that the stated practices are in place.</p>"},{"location":"stage-3-regulatory-alignment/L2-4.3-Transparency-Disclosure-Framework-v1/#7-article-4-ai-competence-obligations-and-transparency","title":"7. Article 4 \u2014 AI Competence Obligations and Transparency","text":"<p>Article 4 requires Pickles GmbH to ensure that its personnel and persons operating AI systems on its behalf have sufficient AI competence. This includes:</p> <p>Internal: Pickles GmbH staff working with AI systems must be trained on AI capabilities, risks, and limitations. See L1-3.4 Human Oversight Policy.</p> <p>External (client-facing): Pickles GmbH has a commercial and governance interest in supporting its lawyer clients' own AI competence. BRAK Section 5.1 describes the Article 4 competence obligation as applying to lawyers as operators. Pickles GmbH's products and documentation should: - Clearly explain what the AI system does and does not do - Highlight the need for qualified review - Not imply a level of accuracy or reliability that the system cannot sustain</p> <p>[ASSUMPTION] Training materials or AI competence resources for clients have not been confirmed as part of the Pickles GmbH product offering.</p>"},{"location":"stage-3-regulatory-alignment/L2-4.3-Transparency-Disclosure-Framework-v1/#8-compliance-checklist-transparency-obligations","title":"8. Compliance Checklist \u2014 Transparency Obligations","text":"Obligation Regulatory Basis Implementation Status Target Date Owner [ASSUMPTION] Ensure Pickles GmbH staff have AI competence EU AI Act Article 4 (active from 2 Feb 2025) \u2610 Not confirmed Immediate CEO / Head of HR [ASSUMPTION] Disclose to users that they are interacting with AI EU AI Act Article 50(1) (applies from 2 Aug 2026) \u2610 Not yet implemented By 2 Aug 2026 Head of Product [ASSUMPTION] Mark AI-generated text outputs in machine-readable format EU AI Act Article 50(2) (applies from 2 Aug 2026) \u2610 Not yet implemented By 2 Aug 2026 Head of Engineering [ASSUMPTION] Assess Article 50(2) assistive exemption per system EU AI Act Article 50(2) \u2610 Not yet assessed Before 2 Aug 2026 Legal / Head of Product [ASSUMPTION] Publish deployer information per Article 13(3) (if high-risk) EU AI Act Article 13 (applies from 2 Aug 2026) \u2610 Pending SYS-04 risk classification After risk classification Legal / Head of Product [ASSUMPTION] Complete Article 6(4) self-assessment documentation per system EU AI Act Article 6(4) \u2610 Not yet completed Before market placement Legal [ASSUMPTION] Publish website AI governance statement Good practice / BRAK \u2610 Not yet published Before next product launch CEO / Marketing [ASSUMPTION] Publish per-system limitation disclosures Good practice / Article 13(3) \u2610 Not yet completed Rolling \u2014 per system Head of Product [ASSUMPTION] Provide lawyer clients with BRAK-aligned AI use guidance Good practice / BRAK Section 4 \u2610 Not yet implemented [PLACEHOLDER] Legal / Client Success [ASSUMPTION] Implement GDPR transparency information (Articles 13/14) GDPR Articles 13, 14 \u2610 See L2-5.2 DPIA Assessment See L2-5.2 DPO [ASSUMPTION]"},{"location":"stage-3-regulatory-alignment/L2-4.3-Transparency-Disclosure-Framework-v1/#9-cross-references","title":"9. Cross-References","text":"Document Relevance L2-4.1-EU-AI-Act-Risk-Mapping-Matrix-v1.md Risk classification that determines Article 13 and Article 50 applicability L2-4.2-Technical-Documentation-Pack-Template-v1.md Contains Article 13(3) disclosure elements (Section 3 above) L2-5.1-Data-Flow-Map-v1.md GDPR data transparency context L2-5.2-DPIA-Assessment-v1.md Article 35 GDPR \u2014 DPIA transparency implications L1-3.4-Human-Oversight-Policy-v1.md Human oversight \u2014 referenced in Article 13(3)(d) disclosures L3-6.2-Incident-Response-Playbook-v1.md Transparency to clients and regulators in incident situations"},{"location":"stage-3-regulatory-alignment/L2-4.3-Transparency-Disclosure-Framework-v1/#document-control","title":"Document Control","text":"Field Detail Document ID L2-4.3 Next review After SYS-04 risk classification; before 2 August 2026 implementation deadline Assumptions relied upon A-001, A-002, A-003"},{"location":"stage-3-regulatory-alignment/L2-5.1-Data-Flow-Map-v1/","title":"Data Flow Map","text":"<p>Project: Pickles GmbH \u2014 AI Governance Framework Stage: Stage 3 \u2014 Regulatory Alignment Status: Draft Version: v1 Date: 2026-02-26 Assumptions: Built on outline assumptions \u2014 not verified against real Pickles GmbH data</p>"},{"location":"stage-3-regulatory-alignment/L2-5.1-Data-Flow-Map-v1/#purpose","title":"Purpose","text":"<p>This document maps the flow of personal data through Pickles GmbH's AI platform, identifies storage locations, retention periods, sub-processors, and encryption measures. It supports:</p> <ul> <li>Compliance with GDPR Article 30 (Records of Processing Activities \u2014 RoPA)</li> <li>The DPIA threshold assessment and DPIA preparation (L2-5.2)</li> <li>Vendor and sub-processor management (L2-5.3)</li> <li>EU AI Act Article 12 (logging and record-keeping for high-risk systems)</li> </ul> <p>[ASSUMPTION] This data flow map is based entirely on assumed system architecture (A-001 through A-005) and has not been validated against Pickles GmbH's actual technical infrastructure. Before this document is used for compliance purposes, the entire flow must be verified against real system documentation, hosting contracts, and model provider agreements.</p> <p>[LEGAL REVIEW REQUIRED] Finalisation of the RoPA, DPIA, and sub-processor list requires legal review. This document is a working framework, not a compliance certification.</p>"},{"location":"stage-3-regulatory-alignment/L2-5.1-Data-Flow-Map-v1/#1-regulatory-basis","title":"1. Regulatory Basis","text":"Instrument Provision Topic GDPR Article 4(7) Controller definition GDPR Article 4(8) Processor definition GDPR Article 28 Processor contract requirements GDPR Article 30 Records of processing activities (RoPA) GDPR Article 32 Security of processing GDPR Articles 44, 46 International data transfers \u2014 general principle and appropriate safeguards BDSG Section 64 Security requirements for automated processing EU AI Act Article 12 Logging for high-risk AI systems (SYS-04) EU AI Act Article 26(6) Deployer log retention (relevant for Pickles GmbH's lawyer clients) BRAK Section 3 (\u00a743e BRAO) Attorney-client confidentiality in IT outsourcing"},{"location":"stage-3-regulatory-alignment/L2-5.1-Data-Flow-Map-v1/#2-data-controller-and-processor-roles","title":"2. Data Controller and Processor Roles","text":""},{"location":"stage-3-regulatory-alignment/L2-5.1-Data-Flow-Map-v1/#21-role-identification","title":"2.1 Role Identification","text":"<p>[ASSUMPTION] The following role allocation is assumed and must be verified against Pickles GmbH's actual service agreements and data processing practices.</p> Party Role Basis Pickles GmbH Data controller \u2014 for personal data of its own employees, registered users, and account holders GDPR Article 4(7) [ASSUMPTION] Pickles GmbH Data processor \u2014 for personal data contained in legal documents, queries, and inputs submitted by lawyer clients who are the data controllers for their clients' data GDPR Article 4(8) [ASSUMPTION] Lawyer clients (law firms, in-house legal depts.) Data controllers \u2014 for personal data of their own clients and counterparties contained in documents they submit to Pickles GmbH GDPR Article 4(7) [ASSUMPTION] Third-party AI model provider Sub-processor \u2014 if lawyer client data is passed to a third-party model API GDPR Article 28(2) [ASSUMPTION A-004] Cloud hosting provider Sub-processor \u2014 for infrastructure hosting GDPR Article 28(2) [ASSUMPTION A-005] <p>[LEGAL REVIEW REQUIRED] The controller/processor boundary is critical. If Pickles GmbH determines its own purposes and means for processing client-submitted data (e.g., for model training or product improvement), it may be a joint controller or an independent controller for that processing. This must be assessed carefully per Article 4(7) and Recital 74 GDPR.</p>"},{"location":"stage-3-regulatory-alignment/L2-5.1-Data-Flow-Map-v1/#3-data-categories-in-scope","title":"3. Data Categories in Scope","text":""},{"location":"stage-3-regulatory-alignment/L2-5.1-Data-Flow-Map-v1/#31-personal-data-categories","title":"3.1 Personal Data Categories","text":"<p>[ASSUMPTION] The following categories of personal data are assumed to flow through Pickles GmbH's systems based on the nature of legal AI tools:</p> Category Source Sensitivity Notes Lawyer/user account data Registration and onboarding Standard personal data Name, email, firm name, role Legal document content User-submitted documents and prompts Potentially sensitive / special categories [ASSUMPTION] May include health data, financial data, family information, criminal records \u2014 depending on practice area Case facts and client details User queries and prompts Potentially sensitive / special categories [ASSUMPTION] May include client names, dispute facts, identifying details Usage logs and session data Automatically generated Standard personal data / technical data Query timestamps, session IDs, system events Payment data Subscription / billing Standard financial personal data [ASSUMPTION \u2014 handled by payment processor sub-processor] <p>Key risk: Legal documents routinely contain special categories of personal data (GDPR Article 9) \u2014 health, financial, criminal. Processing special categories of personal data triggers GDPR Article 9 restrictions, heightened Article 32 security requirements, and may trigger DPIA requirements under Article 35(3)(b). See L2-5.2 for DPIA assessment.</p>"},{"location":"stage-3-regulatory-alignment/L2-5.1-Data-Flow-Map-v1/#4-data-flow-maps","title":"4. Data Flow Maps","text":""},{"location":"stage-3-regulatory-alignment/L2-5.1-Data-Flow-Map-v1/#41-primary-prompt-flow-sys-01-sys-02-sys-03-sys-04","title":"4.1 Primary Prompt Flow (SYS-01, SYS-02, SYS-03, SYS-04)","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                         LAWYER CLIENT                               \u2502\n\u2502   (Data controller for client personal data)                        \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                  \u2502\n                  \u2502 HTTPS (TLS 1.3+) [ASSUMPTION]\n                  \u2502 Query / document input\n                  \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                    PICKLES GMBH PLATFORM                            \u2502\n\u2502   (Data processor for client data; data controller for user data)   \u2502\n\u2502                                                                     \u2502\n\u2502   [1] API Gateway / Authentication layer                            \u2502\n\u2502       - User identity verification                                  \u2502\n\u2502       - Input validation                                            \u2502\n\u2502       - Session logging (start timestamp, session ID)               \u2502\n\u2502                                                                     \u2502\n\u2502   [2] Application Processing Layer                                  \u2502\n\u2502       - Query routing to appropriate AI system                      \u2502\n\u2502       - Input preprocessing / prompt construction                   \u2502\n\u2502       - Retrieval step (SYS-01: legal document index search)        \u2502\n\u2502                                                                     \u2502\n\u2502   [3] AI Inference Layer                                            \u2502\n\u2502       EITHER: In-house model inference [ASSUMPTION]                 \u2502\n\u2502       OR: API call to third-party model provider [ASSUMPTION A-004] \u2502\n\u2502                                                                     \u2502\n\u2502   [4] Output Processing Layer                                       \u2502\n\u2502       - Response formatting                                         \u2502\n\u2502       - AI-generated content marking (Article 50(2))               \u2502\n\u2502       - Output logging (Article 12 \u2014 SYS-04)                       \u2502\n\u2502                                                                     \u2502\n\u2502   [5] Storage                                                       \u2502\n\u2502       - Logs retained per retention policy                          \u2502\n\u2502       - User account data retained per account lifecycle            \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n           \u2502                          \u2502\n           \u2502 Output returned          \u2502 API call [ASSUMPTION A-004]\n           \u2502 via HTTPS                \u2502 HTTPS (TLS)\n           \u2502                          \u25bc\n           \u2502             \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n           \u2502             \u2502  THIRD-PARTY MODEL PROVIDER \u2502\n           \u2502             \u2502  (Sub-processor)            \u2502\n           \u2502             \u2502  [ASSUMPTION A-004]         \u2502\n           \u2502             \u2502                             \u2502\n           \u2502             \u2502  Location: [UNKNOWN \u2014       \u2502\n           \u2502             \u2502  may be non-EU ASSUMPTION]  \u2502\n           \u2502             \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n           \u2502\n           \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                         LAWYER CLIENT                               \u2502\n\u2502   Receives AI output \u2014 applies professional judgment                \u2502\n\u2502   No automatic transmission to third parties [ASSUMPTION]           \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>[ASSUMPTION] The architecture above is entirely assumed. Actual data flows may differ significantly depending on whether Pickles GmbH runs its own models, uses third-party model APIs, or uses a hybrid approach.</p>"},{"location":"stage-3-regulatory-alignment/L2-5.1-Data-Flow-Map-v1/#42-data-flow-at-third-party-model-provider-if-applicable","title":"4.2 Data Flow at Third-Party Model Provider (If Applicable)","text":"<p>[ASSUMPTION A-004] If Pickles GmbH uses a third-party AI model provider:</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502               THIRD-PARTY MODEL PROVIDER                           \u2502\n\u2502                                                                    \u2502\n\u2502   Receives: Constructed prompt (may contain personal data from     \u2502\n\u2502             lawyer client's documents) [ASSUMPTION]                \u2502\n\u2502                                                                    \u2502\n\u2502   Processing: Language model inference only [ASSUMPTION]           \u2502\n\u2502                                                                    \u2502\n\u2502   Returns: Generated text response                                 \u2502\n\u2502                                                                    \u2502\n\u2502   Data retention by provider: [UNKNOWN \u2014 must be contractually     \u2502\n\u2502   restricted per GDPR Article 28(3)(g) and \u00a743e BRAO]             \u2502\n\u2502                                                                    \u2502\n\u2502   Location: [UNKNOWN \u2014 if USA: SCCs required under GDPR Art. 46;  \u2502\n\u2502   \u00a743e(4) BRAO requires comparable confidentiality protection]     \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>[LEGAL REVIEW REQUIRED] Whether personal data from lawyer client documents is actually transmitted to the third-party model provider depends on architecture (e.g., RAG systems may avoid transmitting personal data if retrieval is in-house and only anonymised prompts are sent to the model). This must be confirmed per system.</p>"},{"location":"stage-3-regulatory-alignment/L2-5.1-Data-Flow-Map-v1/#5-storage-locations-and-retention","title":"5. Storage Locations and Retention","text":""},{"location":"stage-3-regulatory-alignment/L2-5.1-Data-Flow-Map-v1/#51-storage-location-map","title":"5.1 Storage Location Map","text":"Data Type Storage Location Jurisdiction Encryption Notes User account data Pickles GmbH cloud infrastructure [ASSUMPTION] EU [ASSUMPTION A-005] At rest: AES-256 [ASSUMPTION]; In transit: TLS [ASSUMPTION] Includes registration, login, firm details Query logs / session logs Pickles GmbH cloud infrastructure [ASSUMPTION] EU [ASSUMPTION A-005] As above [ASSUMPTION] May contain personal data from queries AI output logs (SYS-04 only) Pickles GmbH cloud infrastructure [ASSUMPTION] EU [ASSUMPTION A-005] As above [ASSUMPTION] Mandatory logging per EU AI Act Article 12 Submitted documents (if retained) [UNKNOWN \u2014 must be clarified] [ASSUMPTION] [UNKNOWN] [UNKNOWN] [LEGAL REVIEW REQUIRED] \u2014 Retention of submitted documents creates significant GDPR liability if personal data is involved Training / fine-tuning data [UNKNOWN \u2014 if Pickles GmbH fine-tunes models] [ASSUMPTION] [UNKNOWN] [UNKNOWN] If personal data used for training: Article 6 lawful basis required; Article 9 heightened requirements for special categories Data at third-party model provider [UNKNOWN \u2014 if API used] [ASSUMPTION A-004] [UNKNOWN \u2014 possibly non-EU] [UNKNOWN] SCCs required if non-EU; \u00a743e BRAO contractual controls required <p>[ASSUMPTION A-005] EU-based hosting is assumed but unverified. If any storage location is outside the EEA, GDPR Chapter V (international transfer requirements) applies.</p>"},{"location":"stage-3-regulatory-alignment/L2-5.1-Data-Flow-Map-v1/#52-retention-periods","title":"5.2 Retention Periods","text":"<p>[ASSUMPTION] The following retention periods are proposed as a working framework and must be confirmed against Pickles GmbH's actual business requirements, contractual obligations, and data protection assessment.</p> Data Type Proposed Retention Basis Notes User account data (active accounts) Duration of account relationship + 3 years [ASSUMPTION] Contract performance; legitimate interests (legal claims) [LEGAL REVIEW REQUIRED] User account data (closed accounts) 3 years from account closure [ASSUMPTION] Limitation periods (\u00a7195 BGB \u2014 standard 3-year period) [LEGAL REVIEW REQUIRED] Query and session logs 90 days [ASSUMPTION] Operational monitoring and incident response [LEGAL REVIEW REQUIRED \u2014 balance against Article 5(1)(e) GDPR storage limitation] AI output logs (SYS-04 \u2014 high-risk) 6 months minimum per EU AI Act Article 26(6) EU AI Act Article 26(6) mandatory minimum \"Deployers shall keep logs... for a period of at least six months\" Submitted documents (if retained) [NOT RECOMMENDED \u2014 avoid retention unless operationally essential] [ASSUMPTION] GDPR Article 5(1)(e) storage limitation principle Retention of client legal documents creates maximum GDPR risk and \u00a743a BRAO confidentiality risk Training data Per training dataset lifecycle documentation [ASSUMPTION] As required by EU AI Act Article 10 Anonymised training data should be treated differently from personal data <p>[LEGAL REVIEW REQUIRED] Retention periods must be assessed against GDPR Article 5(1)(e) (storage limitation) and documented in the RoPA. Pickles GmbH must have a specific lawful basis for each processing activity within each retention window.</p>"},{"location":"stage-3-regulatory-alignment/L2-5.1-Data-Flow-Map-v1/#6-sub-processors","title":"6. Sub-Processors","text":""},{"location":"stage-3-regulatory-alignment/L2-5.1-Data-Flow-Map-v1/#61-sub-processor-register-assumed","title":"6.1 Sub-Processor Register (Assumed)","text":"<p>[ASSUMPTION] The following sub-processors are assumed based on the typical architecture of a cloud-based legal AI SaaS platform. This list must be verified and maintained as the definitive sub-processor register under GDPR Article 28(2).</p> Sub-Processor Category Role Data Transferred Location Transfer Mechanism DPA in Place Third-party AI model provider [ASSUMPTION A-004] Processes queries / generates AI outputs May include personal data from prompts [ASSUMPTION] Unknown \u2014 possibly non-EU [ASSUMPTION] SCCs required if non-EU [LEGAL REVIEW REQUIRED] Required \u2014 see L2-5.3 Cloud hosting provider [ASSUMPTION A-005] Infrastructure hosting \u2014 compute, storage, networking All platform data EU assumed [ASSUMPTION] Within EEA \u2014 no Chapter V mechanism required Required Payment processor [ASSUMPTION] Subscription billing Payment data, account holder name/email [UNKNOWN] [UNKNOWN] Required Email / notification provider [ASSUMPTION] Transactional emails (account verification, alerts) Email address, name [UNKNOWN] [UNKNOWN] Required Monitoring / logging provider [ASSUMPTION] Application performance monitoring Technical logs (may include metadata) [UNKNOWN] [UNKNOWN] Required Analytics provider [ASSUMPTION] Product usage analytics Anonymised or pseudonymised usage data [ASSUMPTION] [UNKNOWN] [UNKNOWN] Required if personal data <p>BRAK \u00a743e BRAO obligation: For any sub-processor that handles data that may constitute attorney-client confidential information, Pickles GmbH must ensure a written contract (at minimum in text form per \u00a743e(2) BRAW) containing the minimum content specified in \u00a743e(3) Nos. 1\u20133 BRAO: (1) confidentiality obligation with criminal consequences disclosure; (2) purpose limitation; (3) obligation to terminate if confidentiality can no longer be guaranteed.</p>"},{"location":"stage-3-regulatory-alignment/L2-5.1-Data-Flow-Map-v1/#62-client-notification-of-sub-processors","title":"6.2 Client Notification of Sub-Processors","text":"<p>GDPR Article 28(2) requires that processors obtain prior specific or general written authorisation from the controller before engaging sub-processors. If Pickles GmbH acts as a data processor for its lawyer clients:</p> <ul> <li>Pickles GmbH must notify lawyer clients of all sub-processors handling their data</li> <li>Lawyer clients must have the opportunity to object to sub-processor changes</li> <li>The sub-processor list should be published and maintained as part of Pickles GmbH's Privacy Policy or a dedicated sub-processor list page</li> </ul> <p>[ASSUMPTION] This disclosure has not been confirmed as currently in place.</p>"},{"location":"stage-3-regulatory-alignment/L2-5.1-Data-Flow-Map-v1/#7-international-data-transfers","title":"7. International Data Transfers","text":""},{"location":"stage-3-regulatory-alignment/L2-5.1-Data-Flow-Map-v1/#71-transfer-risk-assessment","title":"7.1 Transfer Risk Assessment","text":"<p>GDPR Article 44 requires that personal data transferred to third countries is subject to appropriate safeguards. This is particularly relevant where Pickles GmbH's third-party model provider is located outside the EEA.</p> <p>[ASSUMPTION A-004] If using a US-based model provider (common for large language models):</p> Transfer Destination Risk Mechanism Required Prompts containing personal data \u2192 third-party model API USA (assumed) [ASSUMPTION] High \u2014 no adequacy decision for USA for all transfers; Data Privacy Framework applies only to certified organisations SCCs (EU Standard Contractual Clauses per Article 46(2)(c) GDPR) and Transfer Impact Assessment (TIA) [LEGAL REVIEW REQUIRED] Prompts \u2192 non-EU, non-adequacy country Other third countries Very high SCCs + TIA, or other Article 46 safeguards; \u00a743e(4) BRAO requires special protective measures"},{"location":"stage-3-regulatory-alignment/L2-5.1-Data-Flow-Map-v1/#72-gdpr-article-46-safeguards-required","title":"7.2 GDPR Article 46 Safeguards Required","text":"<p>Where no adequacy decision exists (GDPR Article 45), transfers may proceed only if appropriate safeguards are in place (Article 46), including: - Standard data protection clauses adopted by the Commission (Article 46(2)(c)) \u2014 EU SCCs (Commission Decision 2021/914) - Transfer Impact Assessment (TIA) \u2014 non-binding but required by EDPB recommendations for SCC transfers to high-risk destinations</p>"},{"location":"stage-3-regulatory-alignment/L2-5.1-Data-Flow-Map-v1/#73-brak-43e4-brao-transfer-obligation","title":"7.3 BRAK \u00a743e(4) BRAO Transfer Obligation","text":"<p>Where client secrets are transferred to providers in non-EU countries, \u00a743e(4) BRAO requires the level of confidentiality protection to be comparable to Germany. For US-based cloud and AI providers, the BRAK position paper notes: \"it is not yet clear whether the level of data protection can be relied upon in this context, so that \u2014 as far as possible \u2014 preference should be given to AI providers with servers located in Germany or Europe.\"</p> <p>[LEGAL REVIEW REQUIRED] If the third-party model provider is US-based, a TIA must be conducted and documented. Contractual data processing agreement terms must meet both GDPR Article 28 and \u00a743e BRAO requirements. See L2-5.3 for vendor risk assessment framework.</p>"},{"location":"stage-3-regulatory-alignment/L2-5.1-Data-Flow-Map-v1/#8-security-measures-overview","title":"8. Security Measures Overview","text":"<p>Detailed security requirements are governed by GDPR Article 32 and BDSG Section 64.</p> Security Control Requirement Basis Status [ASSUMPTION] Encryption in transit (TLS 1.3+) GDPR Article 32(1)(a); BDSG \u00a764(2) [ASSUMPTION \u2014 not verified] Encryption at rest (AES-256 or equivalent) GDPR Article 32(1)(a); BDSG \u00a764(2) [ASSUMPTION \u2014 not verified] Access controls \u2014 user authentication BDSG \u00a764(3) Nos. 4, 5 [ASSUMPTION \u2014 not verified] Access controls \u2014 internal staff (need-to-know) BDSG \u00a764(3) No. 5; BRAK \u00a743e(1) [ASSUMPTION \u2014 not verified] Audit logging \u2014 who accessed what BDSG \u00a764(3) No. 7 (\"input control\") [ASSUMPTION \u2014 not verified] Communication control \u2014 data transmission tracking BDSG \u00a764(3) No. 6 [ASSUMPTION \u2014 not verified] Separation of data by purpose BDSG \u00a764(3) No. 14 (\"separability\") [ASSUMPTION \u2014 not verified] Resilience and recovery GDPR Article 32(1)(b)(c); BDSG \u00a764(2) [ASSUMPTION \u2014 not verified] Regular security testing GDPR Article 32(1)(d); BDSG \u00a764(3) No. 11 [ASSUMPTION \u2014 not verified] Adversarial input defences (SYS-04 high-risk) EU AI Act Article 15(5) [ASSUMPTION \u2014 not verified] Pseudonymisation where feasible GDPR Article 32(1)(a) [ASSUMPTION \u2014 recommended for query logs]"},{"location":"stage-3-regulatory-alignment/L2-5.1-Data-Flow-Map-v1/#9-gdpr-article-30-records-of-processing-activities-summary","title":"9. GDPR Article 30 \u2014 Records of Processing Activities Summary","text":"<p>This section provides the core elements required for Pickles GmbH's RoPA under Article 30. The RoPA must be maintained in writing (including electronic form) and made available to the supervisory authority on request.</p>"},{"location":"stage-3-regulatory-alignment/L2-5.1-Data-Flow-Map-v1/#91-controller-records-pickles-gmbh-as-controller-for-user-account-data","title":"9.1 Controller Records (Pickles GmbH as controller \u2014 for user account data)","text":"RoPA Element Content Controller name and contact Pickles GmbH; [PLACEHOLDER \u2014 address, DPO contact] Purpose of processing Provision of legal AI platform services; account management; billing Categories of data subjects Registered users (lawyers, paralegals, legal professionals) [ASSUMPTION] Categories of personal data Name, email, firm, professional role, billing details, usage logs [ASSUMPTION] Categories of recipients Cloud hosting sub-processor; payment processor; email provider [ASSUMPTION] International transfers [UNKNOWN \u2014 depends on sub-processor locations] Retention periods [See Section 5.2] Security measures [See Section 8]"},{"location":"stage-3-regulatory-alignment/L2-5.1-Data-Flow-Map-v1/#92-processor-records-pickles-gmbh-as-processor-for-lawyer-client-data","title":"9.2 Processor Records (Pickles GmbH as processor \u2014 for lawyer client data)","text":"RoPA Element Content Processor name and contact Pickles GmbH; [PLACEHOLDER \u2014 DPO contact] Controller(s) Lawyer clients (each law firm or in-house legal dept.) Categories of processing AI-assisted legal research, drafting, summarisation, analysis International transfers [UNKNOWN \u2014 depends on third-party model provider location; see Section 7] Security measures [See Section 8] <p>[LEGAL REVIEW REQUIRED] GDPR Article 30(5) provides an exemption for organisations with fewer than 250 employees, but this exemption does not apply where processing is likely to result in a risk to data subjects' rights, is not occasional, or involves special categories of data. Given the almost certain involvement of special categories of personal data in legal documents, the RoPA obligation almost certainly applies to Pickles GmbH regardless of employee count.</p>"},{"location":"stage-3-regulatory-alignment/L2-5.1-Data-Flow-Map-v1/#10-data-flows-requiring-immediate-action","title":"10. Data Flows Requiring Immediate Action","text":"<p>The following gaps require resolution before Pickles GmbH can produce a complete and accurate data flow map:</p> Gap Priority Owner [ASSUMPTION] Confirm whether third-party model provider is used, and if so, which Critical CEO / Head of Engineering [ASSUMPTION] Confirm model provider location \u2014 EEA or non-EEA Critical CEO / Head of Engineering [ASSUMPTION] Confirm whether user queries / documents are retained after session Critical Head of Engineering [ASSUMPTION] Confirm whether personal data from queries is transmitted to model provider Critical Head of Engineering [ASSUMPTION] Confirm cloud hosting provider identity and jurisdiction High Head of Engineering [ASSUMPTION] Review whether any model training uses client-submitted data Critical Head of Engineering / CEO [ASSUMPTION] Audit all sub-processors and confirm DPAs in place High DPO / Legal [ASSUMPTION] Conduct Transfer Impact Assessment if non-EU transfers identified High DPO / Legal [ASSUMPTION]"},{"location":"stage-3-regulatory-alignment/L2-5.1-Data-Flow-Map-v1/#document-control","title":"Document Control","text":"Field Detail Document ID L2-5.1 Next review After architecture confirmation from engineering; before DPIA (L2-5.2) is finalised Cross-references L2-5.2 (DPIA Assessment), L2-5.3 (Vendor Risk Assessment), L1-3.1 (AI System Inventory) Regulatory basis GDPR Articles 28, 30, 32, 44, 46; BDSG \u00a764; EU AI Act Articles 12, 26(6); BRAK \u00a743e BRAO Assumptions relied upon A-001, A-002, A-004, A-005, A-007"},{"location":"stage-3-regulatory-alignment/L2-5.2-DPIA-Assessment-v1/","title":"Data Protection Impact Assessment","text":"<p>Project: Pickles GmbH \u2014 AI Governance Framework Stage: Stage 3 \u2014 Regulatory Alignment Status: Draft Version: v1 Date: 2026-02-26 Assumptions: Built on outline assumptions \u2014 not verified against real Pickles GmbH data</p>"},{"location":"stage-3-regulatory-alignment/L2-5.2-DPIA-Assessment-v1/#purpose","title":"Purpose","text":"<p>This document contains:</p> <ol> <li> <p>Part A \u2014 DPIA Threshold Assessment: An evaluation of all four assumed Pickles GmbH AI systems against the GDPR Article 35 threshold criteria. Determines which systems require a full DPIA.</p> </li> <li> <p>Part B \u2014 Full DPIA for SYS-04 (Legal Analysis Tool): A complete Data Protection Impact Assessment for SYS-04, which is treated as high-risk for the purposes of this framework following the project owner's direction. Covers processing description, necessity and proportionality, risk identification, mitigation controls, and residual risk.</p> </li> </ol> <p>[ASSUMPTION] This DPIA is based entirely on assumed system architecture, assumed data flows (L2-5.1), and assumed processing activities. Before this document has any compliance effect, it must be reviewed and completed using verified data about real Pickles GmbH systems.</p> <p>[LEGAL REVIEW REQUIRED] A DPIA is a legal compliance document. This draft constitutes a working framework. It must be completed and reviewed by a qualified data protection practitioner, and the DPO must be consulted in accordance with GDPR Article 35(2) and BDSG Section 67(3) before the document is finalised.</p>"},{"location":"stage-3-regulatory-alignment/L2-5.2-DPIA-Assessment-v1/#regulatory-basis","title":"Regulatory Basis","text":"Instrument Provision Topic GDPR Article 35 Data Protection Impact Assessment GDPR Article 36 Prior consultation with supervisory authority GDPR Article 9 Special categories of personal data GDPR Article 22 Automated individual decision-making BDSG Section 67 DPIA requirements under German law EDPB WP251 Section VI; Annex 2 DPIA and automated decision-making guidance EU AI Act Article 26(9) High-risk AI systems and GDPR Article 35 linkage"},{"location":"stage-3-regulatory-alignment/L2-5.2-DPIA-Assessment-v1/#part-a-dpia-threshold-assessment","title":"PART A \u2014 DPIA THRESHOLD ASSESSMENT","text":""},{"location":"stage-3-regulatory-alignment/L2-5.2-DPIA-Assessment-v1/#a1-when-is-a-dpia-required","title":"A.1 When Is a DPIA Required?","text":"<p>GDPR Article 35(1) requires a DPIA where processing \"using new technologies, and taking into account the nature, scope, context and purposes of the processing, is likely to result in a high risk to the rights and freedoms of natural persons.\"</p> <p>Article 35(3) specifies three categories that always require a DPIA:</p> Category Description Reference 35(3)(a) Systematic and extensive evaluation of personal aspects based on automated processing (including profiling) producing legal or similarly significant effects Article 35(3)(a) 35(3)(b) Processing on a large scale of special categories of data (Article 9) or criminal conviction data (Article 10) Article 35(3)(b) 35(3)(c) Systematic monitoring of a publicly accessible area on a large scale Article 35(3)(c) <p>EU AI Act Article 26(9) linkage:</p> <p>\"Deployers of high-risk AI systems shall use the information provided under Article 13 of this Regulation to comply with their obligation to carry out a data protection impact assessment under Article 35 of Regulation (EU) 2016/679.\"</p> <p>SYS-04 has been confirmed as a high-risk AI system. This creates a direct obligation to consider a DPIA under GDPR Article 35, informed by the Article 13 technical information about the system.</p> <p>EDPB WP251 note on Article 35(3)(a):</p> <p>The EDPB Guidelines on automated decision-making (WP251) confirm that Article 35(3)(a) applies to evaluations \"based on automated processing\" \u2014 not only \"solely automated\" processing. Where automated processing significantly shapes an output that a human then endorses, this may still trigger DPIA requirements even if final decisions are made by a lawyer.</p>"},{"location":"stage-3-regulatory-alignment/L2-5.2-DPIA-Assessment-v1/#a2-system-by-system-dpia-threshold-assessment","title":"A.2 System-by-System DPIA Threshold Assessment","text":""},{"location":"stage-3-regulatory-alignment/L2-5.2-DPIA-Assessment-v1/#sys-01-legal-research-assistant","title":"SYS-01 \u2014 Legal Research Assistant","text":"Threshold Factor Assessment Notes New technology? Yes \u2014 LLM-based legal research is a new technology Article 35(1) factor Systematic evaluation of personal aspects? Low \u2014 primarily retrieves legal texts; personal data in queries is incidental Article 35(3)(a) Legal or similarly significant effects on data subjects? Low \u2014 outputs are legal research, not decisions about individuals Article 35(3)(a) Large-scale processing of special categories? Possible \u2014 legal documents submitted may contain special category data [ASSUMPTION] Article 35(3)(b) Systematic monitoring? No Article 35(3)(c) DPIA threshold met? Borderline \u2014 depends on volume of queries and whether special category data routinely appears in submitted documents [ASSUMPTION] Recommend conducting lightweight DPIA Immediate action Assess query volume and data categories handled; if special category data processed at scale, full DPIA required [LEGAL REVIEW REQUIRED]"},{"location":"stage-3-regulatory-alignment/L2-5.2-DPIA-Assessment-v1/#sys-02-document-drafting-tool","title":"SYS-02 \u2014 Document Drafting Tool","text":"Threshold Factor Assessment Notes New technology? Yes Article 35(1) factor Systematic evaluation of personal aspects? Low \u2014 generates draft text; does not evaluate individual profiles Article 35(3)(a) Legal or similarly significant effects on data subjects? Moderate \u2014 drafted documents may affect legal rights of parties [ASSUMPTION] Article 35(3)(a) Large-scale processing of special categories? Possible \u2014 contract drafting may involve personal data of natural persons [ASSUMPTION] Article 35(3)(b) Systematic monitoring? No Article 35(3)(c) DPIA threshold met? Borderline to Low \u2014 depends on processing scale and data content [ASSUMPTION] Recommend screening assessment Immediate action Confirm whether special category data routinely appears in drafting tasks; if yes, DPIA required [LEGAL REVIEW REQUIRED]"},{"location":"stage-3-regulatory-alignment/L2-5.2-DPIA-Assessment-v1/#sys-03-document-summarisation-tool","title":"SYS-03 \u2014 Document Summarisation Tool","text":"Threshold Factor Assessment Notes New technology? Yes Article 35(1) factor Systematic evaluation of personal aspects? Low-to-Moderate \u2014 summaries of legal documents; may synthesise personal data from source documents Article 35(3)(a) Legal or similarly significant effects on data subjects? Moderate \u2014 summaries of judgments, contracts, or case files may affect legal positions [ASSUMPTION] Article 35(3)(a) Large-scale processing of special categories? Possible \u2014 same reasoning as SYS-01/02 Article 35(3)(b) Systematic monitoring? No Article 35(3)(c) DPIA threshold met? Borderline Recommend screening assessment Immediate action Same as SYS-01 [LEGAL REVIEW REQUIRED]"},{"location":"stage-3-regulatory-alignment/L2-5.2-DPIA-Assessment-v1/#sys-04-legal-analysis-tool-confirmed-high-risk","title":"SYS-04 \u2014 Legal Analysis Tool (Confirmed High-Risk)","text":"Threshold Factor Assessment Notes New technology? Yes \u2014 LLM-based legal analysis is a new technology Article 35(1) factor Systematic evaluation of personal aspects? Yes \u2014 analyses legal facts about persons; produces risk assessments and legal interpretations affecting individuals [ASSUMPTION] Article 35(3)(a) triggered Legal or similarly significant effects on data subjects? Yes \u2014 legal risk analysis directly informs legal decisions affecting parties' rights [ASSUMPTION]; WP251: effects need not be solely automated Article 35(3)(a) triggered Large-scale processing of special categories? Very likely \u2014 legal analysis routinely involves health, financial, criminal, or other special category data [ASSUMPTION] Article 35(3)(b) triggered Automated decision-making (Article 22)? Possible \u2014 if analysis outputs are routinely followed without meaningful independent review Article 22; WP251 guidance EU AI Act high-risk linkage? Yes \u2014 Article 26(9) directly links high-risk AI status to DPIA obligation EU AI Act Article 26(9) DPIA threshold met? Yes \u2014 full DPIA required Proceed to Part B"},{"location":"stage-3-regulatory-alignment/L2-5.2-DPIA-Assessment-v1/#part-b-full-dpia-sys-04-legal-analysis-tool","title":"PART B \u2014 FULL DPIA: SYS-04 LEGAL ANALYSIS TOOL","text":""},{"location":"stage-3-regulatory-alignment/L2-5.2-DPIA-Assessment-v1/#b1-system-identification","title":"B.1 System Identification","text":"Field Value System name Legal Analysis Tool (SYS-04) Provider Pickles GmbH [ASSUMPTION] Classification High-risk AI system (confirmed by project owner for this framework) DPIA prepared by [PLACEHOLDER \u2014 name and role] DPO consulted [PLACEHOLDER \u2014 name, date \u2014 mandatory per Article 35(2)] Date of DPIA 2026-02-26 (framework draft) Next review date [PLACEHOLDER \u2014 at minimum when processing changes; annually recommended] Supervisory authority consultation required? [See Section B.7]"},{"location":"stage-3-regulatory-alignment/L2-5.2-DPIA-Assessment-v1/#b2-processing-description","title":"B.2 Processing Description","text":""},{"location":"stage-3-regulatory-alignment/L2-5.2-DPIA-Assessment-v1/#b21-purpose-of-processing","title":"B.2.1 Purpose of Processing","text":"<p>[ASSUMPTION] SYS-04 is an AI system used by lawyers to analyse legal risks, interpret legal provisions, and identify legal issues in documents or fact patterns submitted by the user. Outputs are intended to assist (not replace) lawyer professional judgment.</p> <p>Intended purposes of processing personal data: - Analysing factual circumstances in legal matters to identify applicable legal issues [ASSUMPTION] - Interpreting contractual provisions and identifying risks for parties [ASSUMPTION] - Summarising legal risk profiles based on document content [ASSUMPTION] - Supporting lawyers in due diligence, litigation preparation, or advisory work [ASSUMPTION]</p>"},{"location":"stage-3-regulatory-alignment/L2-5.2-DPIA-Assessment-v1/#b22-categories-of-data-subjects","title":"B.2.2 Categories of Data Subjects","text":"<p>[ASSUMPTION] Personal data processed through SYS-04 may relate to:</p> Data Subject Category Examples Notes Clients of lawyer users Natural persons whose legal matters are analysed Primary data subjects \u2014 no direct relationship with Pickles GmbH Counterparties in legal proceedings Opposing parties, witnesses, relevant third parties May have no knowledge of AI processing Employees (in employment law matters) Individuals named in employment disputes May include special category data Patients (in medical or personal injury matters) Health information [ASSUMPTION] Special category data \u2014 Article 9 Individuals in family law matters Family circumstances, financial situations [ASSUMPTION] Potentially highly sensitive"},{"location":"stage-3-regulatory-alignment/L2-5.2-DPIA-Assessment-v1/#b23-categories-of-personal-data","title":"B.2.3 Categories of Personal Data","text":"<p>[ASSUMPTION] SYS-04 may process the following categories of personal data, depending on the legal matter submitted:</p> Category GDPR Classification Sensitivity Names and identifying information Standard personal data Moderate Professional and financial information Standard personal data Moderate-High Health and medical data Special category (Article 9(1)) Very high Data relating to criminal convictions or offences Article 10 data Very high Sexual orientation or gender identity Special category (Article 9(1)) Very high Racial or ethnic origin (in discrimination matters) Special category (Article 9(1)) Very high Trade union membership (in employment matters) Special category (Article 9(1)) Very high Biometric or genetic data (if included in documents) Special category (Article 9(1)) Very high"},{"location":"stage-3-regulatory-alignment/L2-5.2-DPIA-Assessment-v1/#b24-operational-description","title":"B.2.4 Operational Description","text":"<p>[ASSUMPTION]</p> <ol> <li>Input: Lawyer submits document(s) or fact pattern to SYS-04 platform, which may contain personal data about third parties</li> <li>Processing: System analyses input; constructs prompt; sends to AI inference layer (in-house model or third-party model API [ASSUMPTION A-004])</li> <li>Output: System generates legal analysis \u2014 risk assessment, legal issue identification, or interpretation \u2014 returned to lawyer</li> <li>Human action: Lawyer reviews output and applies professional judgment; no automatic submission to third parties [ASSUMPTION]</li> <li>Logging: System logs session data and output per EU AI Act Article 12 [ASSUMPTION]</li> </ol>"},{"location":"stage-3-regulatory-alignment/L2-5.2-DPIA-Assessment-v1/#b25-lawful-basis-for-processing","title":"B.2.5 Lawful Basis for Processing","text":"<p>[ASSUMPTION] Pickles GmbH acts as a data processor for its lawyer clients when processing data contained in submitted documents. Pickles GmbH does not independently determine the purposes or means of processing that data \u2014 the lawyer client (controller) does.</p> <p>[LEGAL REVIEW REQUIRED] However, the following processing activities may involve Pickles GmbH acting as an independent controller: - Logging and retaining query data for operational monitoring - Use of query data for model improvement or fine-tuning [ASSUMPTION \u2014 if this occurs, it requires independent lawful basis and client consent or contractual authorisation]</p> <p>For lawyer clients acting as data controllers, the following lawful bases may apply to their use of SYS-04:</p> Processing Activity Potential Lawful Basis Notes Processing client personal data for legal advice Article 6(1)(b) \u2014 performance of contract (with their client); or Article 6(1)(f) \u2014 legitimate interests Depends on client engagement terms Processing special category data Article 9(2)(f) \u2014 establishment, exercise or defence of legal claims Most appropriate for legal proceedings context Processing criminal conviction data Article 10 \u2014 requires authorisation under Member State law [LEGAL REVIEW REQUIRED \u2014 confirm BDSG basis]"},{"location":"stage-3-regulatory-alignment/L2-5.2-DPIA-Assessment-v1/#b3-assessment-of-necessity-and-proportionality","title":"B.3 Assessment of Necessity and Proportionality","text":""},{"location":"stage-3-regulatory-alignment/L2-5.2-DPIA-Assessment-v1/#b31-necessity","title":"B.3.1 Necessity","text":"Question Assessment Is processing necessary to achieve the stated purpose? Yes \u2014 AI-assisted legal analysis requires processing of the personal data in submitted legal documents to produce relevant outputs [ASSUMPTION] Could the purpose be achieved with less personal data (data minimisation)? Partially \u2014 lawyer users should be trained to submit only essential information; anonymisation/pseudonymisation of documents before submission should be promoted [ASSUMPTION] Is the processing adequate for the purpose? Yes \u2014 the AI system analyses only what is submitted [ASSUMPTION] Is the processing excessive relative to the purpose? Risk: if system retains submitted documents or query logs containing personal data beyond operational necessity, this is likely excessive per Article 5(1)(c) GDPR"},{"location":"stage-3-regulatory-alignment/L2-5.2-DPIA-Assessment-v1/#b32-proportionality","title":"B.3.2 Proportionality","text":"Factor Assessment Do benefits justify the risk? Yes \u2014 AI-assisted legal analysis has legitimate efficiency and accuracy benefits for legal services delivery [ASSUMPTION] Are safeguards proportionate to the risk? Partially \u2014 safeguards must be confirmed and implemented; this DPIA identifies the required safeguards (Section B.5) Are data subjects' interests adequately protected? Risk: data subjects whose personal data is in submitted documents receive no direct notice of AI processing; this is inherent to the processor model but must be addressed in client contracts and DPAs Is the processing transparent? Risk: transparency to data subjects (GDPR Articles 13/14) is the lawyer client's responsibility as controller, but Pickles GmbH should contractually require clients to meet these obligations"},{"location":"stage-3-regulatory-alignment/L2-5.2-DPIA-Assessment-v1/#b4-risk-identification","title":"B.4 Risk Identification","text":""},{"location":"stage-3-regulatory-alignment/L2-5.2-DPIA-Assessment-v1/#b41-risk-register","title":"B.4.1 Risk Register","text":"# Risk Description Likelihood [ASSUMPTION] Severity [ASSUMPTION] Overall Risk R1 AI hallucination / inaccurate legal analysis leading to flawed legal advice and harm to client's legal interests High (inherent in LLM technology) High (legal consequences for data subjects) HIGH R2 Confidential information disclosure \u2014 client data transmitted to third-party model provider without adequate contractual controls Medium (depends on architecture) Very High (professional liability; criminal exposure under \u00a7203 StGB) HIGH R3 International data transfer without adequate safeguards \u2014 personal data transferred to non-EEA model provider Medium (depends on provider) High (GDPR violation; supervisory authority fine) HIGH R4 Special category data processed without Article 9 basis \u2014 health, criminal, or other sensitive data in submitted documents Medium (inherent in legal practice) Very High HIGH R5 Excessive data retention \u2014 query logs or submitted documents retained longer than necessary Medium High HIGH R6 Automation bias \u2014 lawyer over-relies on AI analysis without adequate independent review; errors not caught Medium-High (well-documented risk) High HIGH R7 Unauthorised access to platform \u2014 interception of queries or outputs containing sensitive legal data Low-Medium Very High MEDIUM-HIGH R8 AI system used beyond intended purpose \u2014 lawyer submits data for use cases outside the system's tested and validated scope Medium Medium-High MEDIUM R9 Model training on client data without consent or lawful basis \u2014 if Pickles GmbH uses submitted data to improve its models Low (if policy controls in place) Very High HIGH (if it occurs) R10 Data subject unable to exercise rights \u2014 third-party individuals whose data is in submitted documents have no knowledge of or access to the processing High (structural \u2014 inherent to processor model) Medium MEDIUM-HIGH"},{"location":"stage-3-regulatory-alignment/L2-5.2-DPIA-Assessment-v1/#b42-automated-decision-making-risk-article-22-and-wp251","title":"B.4.2 Automated Decision-Making Risk (Article 22 and WP251)","text":"<p>[ASSUMPTION] SYS-04 produces legal analysis outputs for lawyer review. The key question is whether this constitutes \"automated processing\" under Article 22.</p> <p>Per EDPB WP251 guidance: Article 22 applies where decisions are \"based solely\" on automated processing. However, DPIA obligations under Article 35(3)(a) apply more broadly to evaluations \"based on\" automated processing. The fact that a lawyer reviews the output does not automatically eliminate the DPIA obligation.</p> <p>Article 22 assessment: - If lawyers routinely endorse AI analysis without meaningful independent verification \u2192 may constitute de facto \"solely automated\" processing (WP251 warns against \"fabricating human involvement\") - If lawyers conduct genuine independent review with authority to change the conclusion \u2192 Article 22(1) prohibition does not apply - [LEGAL REVIEW REQUIRED] Pickles GmbH's human oversight policy (L1-3.4) must be designed to ensure genuine, meaningful human oversight rather than token review</p>"},{"location":"stage-3-regulatory-alignment/L2-5.2-DPIA-Assessment-v1/#b5-mitigation-controls","title":"B.5 Mitigation Controls","text":""},{"location":"stage-3-regulatory-alignment/L2-5.2-DPIA-Assessment-v1/#b51-technical-controls","title":"B.5.1 Technical Controls","text":"Control Risk Addressed Implementation [ASSUMPTION] Priority Prompt minimisation / anonymisation guidance R1, R2, R4 Train users to anonymise submitted documents; implement in-UI guidance prompting minimal data submission High No-training guarantee \u2014 contractual prohibition on using submitted data for model training R9 Include in DPA with lawyer clients; include in contract with third-party model provider Critical End-to-end encryption \u2014 data in transit and at rest R2, R7 TLS 1.3+ in transit; AES-256 at rest; implement before market placement High Short log retention \u2014 query logs deleted after minimum operational period R5 Implement automated deletion; default to 90-day retention maximum [ASSUMPTION] High No document retention \u2014 submitted documents not stored beyond session R5 Architecture: process in-memory only; no persistent storage of submitted documents [ASSUMPTION] Critical AI output labelling \u2014 all SYS-04 outputs marked as AI-generated (Article 50(2)) R6 In-product labelling; machine-readable marking High Mandatory review gate \u2014 UI prevents direct use/forwarding of output without user action R6 UX design: require explicit user review confirmation before output can be exported or shared Medium-High Access controls \u2014 role-based access; MFA; principle of least privilege R7 Implement at infrastructure and application layer High Separation of production and training data R9 Architectural separation; DBA/engineer access controls Critical"},{"location":"stage-3-regulatory-alignment/L2-5.2-DPIA-Assessment-v1/#b52-contractual-controls","title":"B.5.2 Contractual Controls","text":"Control Risk Addressed Implementation Data Processing Agreement (DPA) with lawyer clients \u2014 specifying Pickles GmbH's processor obligations, no-training guarantee, sub-processor disclosure R2, R9, R10 Include in standard client contract terms; see L2-5.3 Sub-processor DPA with third-party model provider \u2014 including GDPR Article 28 terms and \u00a743e BRAO minimum content R2, R3 Required before any client data is transmitted to model provider; see L2-5.3 Standard Contractual Clauses (SCCs) \u2014 if model provider is non-EEA R3 Execute EU SCCs per Commission Decision 2021/914; conduct Transfer Impact Assessment Lawyer client obligations \u2014 contract terms requiring lawyer clients to inform their own data subjects about AI processing (GDPR Articles 13/14 obligation) R10 Include in DPA / Terms of Service \u00a743e BRAO-compliant service agreement \u2014 with third-party model provider where attorney-client confidential information may be transmitted R2 Confirm provider will execute \u00a743e-compliant terms"},{"location":"stage-3-regulatory-alignment/L2-5.2-DPIA-Assessment-v1/#b53-organisational-controls","title":"B.5.3 Organisational Controls","text":"Control Risk Addressed Implementation [ASSUMPTION] Human oversight policy (L1-3.4) \u2014 mandatory independent review of SYS-04 outputs before reliance R6 Implemented at governance level; reinforce through client-facing documentation AI competence training \u2014 lawyer users trained on SYS-04 limitations, hallucination risk, and review requirements (EU AI Act Article 4) R1, R6 Include in onboarding and annual training [ASSUMPTION] DPO involvement \u2014 DPO consulted on this DPIA and monitors ongoing compliance R1\u2013R10 Mandatory per Article 35(2) and BDSG \u00a767(3) Periodic DPIA review \u2014 DPIA reviewed annually or when processing changes materially All risks Schedule next review \u2014 [PLACEHOLDER date] Incident response procedure \u2014 procedures for data breach notification if personal data in queries is compromised (L3-6.2) R7 Cross-reference L3-6.2 Incident Response Playbook User guidance \u2014 guidance to lawyer users on not submitting unnecessary personal data, and on when to anonymise before submission R2, R4 Include in onboarding documentation and in-product help"},{"location":"stage-3-regulatory-alignment/L2-5.2-DPIA-Assessment-v1/#b6-residual-risk-assessment","title":"B.6 Residual Risk Assessment","text":"<p>After applying the mitigation controls in Section B.5:</p> # Risk Residual Likelihood Residual Severity Residual Risk Accepted? R1 AI hallucination / inaccurate analysis Medium (LLMs inherently hallucinate) Medium (mitigated by mandatory lawyer review) MEDIUM Acceptable with continued monitoring R2 Confidential data disclosure to third-party provider Low (if DPA and \u00a743e controls implemented) High (liability does not change) MEDIUM Acceptable with robust contractual controls R3 International transfer without adequate safeguards Low (if SCCs and TIA completed) High MEDIUM Acceptable if SCCs executed R4 Special category data without Article 9 basis Low (managed via processor model and client DPA obligations) High MEDIUM Acceptable \u2014 controller (lawyer client) carries primary obligation R5 Excessive data retention Low (if no-document-retention architecture implemented) Medium LOW Acceptable R6 Automation bias Medium (cultural/behavioural risk) Medium (mitigated by oversight requirements) MEDIUM Acceptable with ongoing monitoring and training R7 Unauthorised access Low (if security controls implemented) High MEDIUM Acceptable with penetration testing programme R8 Use outside intended purpose Low-Medium Medium LOW-MEDIUM Acceptable with terms enforcement R9 Model training on client data Very Low (if no-training guarantee implemented) Very High LOW Acceptable if guarantee contractually enforced R10 Data subject unable to exercise rights Medium (structural; inherent to processor model) Medium MEDIUM Acceptable \u2014 contractor (lawyer client) responsible; requires DPA clause <p>Overall residual risk assessment: MEDIUM \u2014 acceptable for deployment subject to implementation of all mitigation controls in Section B.5 and ongoing monitoring. [LEGAL REVIEW REQUIRED]</p>"},{"location":"stage-3-regulatory-alignment/L2-5.2-DPIA-Assessment-v1/#b7-prior-consultation-gdpr-article-36","title":"B.7 Prior Consultation \u2014 GDPR Article 36","text":"<p>GDPR Article 36 requires prior consultation with the supervisory authority (in Germany: the Bundesdatenschutzbeauftragte or relevant Landesbeauftragte) where the DPIA indicates that processing would result in a high residual risk in the absence of controller measures.</p> <p>Assessment: The residual risk for SYS-04 is assessed as MEDIUM after mitigation controls. Prior consultation under Article 36 is therefore not currently indicated, provided the mitigation controls in Section B.5 are implemented before deployment.</p> <p>[LEGAL REVIEW REQUIRED] If any mitigation control in Section B.5 cannot be implemented, or if additional risks are identified during architecture review, the residual risk may be higher and prior consultation may become required. DPO must confirm this assessment.</p> <p>Note: BDSG Section 67(3) requires the Federal Commissioner to be involved in the DPIA process under the BDSG framework. [LEGAL REVIEW REQUIRED] Confirm whether BDSG \u00a767 applies to this processing in addition to GDPR Article 35.</p>"},{"location":"stage-3-regulatory-alignment/L2-5.2-DPIA-Assessment-v1/#b8-dpo-consultation-record","title":"B.8 DPO Consultation Record","text":"Field Value DPO name [PLACEHOLDER \u2014 must be designated per BDSG \u00a738 [ASSUMPTION A-008]] Date of consultation [PLACEHOLDER] DPO opinion [PLACEHOLDER \u2014 record DPO opinion on processing risks and mitigation adequacy] DPO recommendations [PLACEHOLDER] Action taken on recommendations [PLACEHOLDER]"},{"location":"stage-3-regulatory-alignment/L2-5.2-DPIA-Assessment-v1/#b9-dpia-sign-off","title":"B.9 DPIA Sign-Off","text":"Role Name Date Signature DPIA Author [PLACEHOLDER] [PLACEHOLDER] [PLACEHOLDER] DPO [PLACEHOLDER \u2014 mandatory] [PLACEHOLDER] [PLACEHOLDER] AIRO / Head of Product [PLACEHOLDER] [PLACEHOLDER] [PLACEHOLDER] CEO (if prior consultation required) [PLACEHOLDER \u2014 if Article 36 triggered] [PLACEHOLDER] [PLACEHOLDER]"},{"location":"stage-3-regulatory-alignment/L2-5.2-DPIA-Assessment-v1/#document-control","title":"Document Control","text":"Field Detail Document ID L2-5.2 Applies to SYS-04 (full DPIA); SYS-01, SYS-02, SYS-03 (threshold assessment only \u2014 full DPIAs to be conducted per system) Next review Before SYS-04 deployment; annually thereafter; when processing changes materially Cross-references L2-5.1 (Data Flow Map), L2-5.3 (Vendor Risk Assessment), L1-3.4 (Human Oversight Policy), L3-6.2 (Incident Response) Regulatory basis GDPR Articles 35, 36, 9, 22; BDSG \u00a767; EDPB WP251; EU AI Act Article 26(9) Assumptions relied upon A-001, A-002, A-004, A-005, A-007, A-008"},{"location":"stage-3-regulatory-alignment/L2-5.3-Vendor-Model-Risk-Assessment-v1/","title":"Vendor Model Risk Assessment","text":"<p>Project: Pickles GmbH \u2014 AI Governance Framework Stage: Stage 3 \u2014 Regulatory Alignment Status: Draft Version: v1 Date: 2026-02-26 Assumptions: Built on outline assumptions \u2014 not verified against real Pickles GmbH data</p>"},{"location":"stage-3-regulatory-alignment/L2-5.3-Vendor-Model-Risk-Assessment-v1/#purpose","title":"Purpose","text":"<p>This document provides a framework for assessing and managing the risks associated with third-party AI model providers used by Pickles GmbH. It covers:</p> <ol> <li>Data processing agreement (DPA) requirements under GDPR Article 28</li> <li>Attorney-client confidentiality requirements under \u00a743e BRAO (as mediated through Pickles GmbH's service to lawyer clients)</li> <li>Sub-processor selection criteria and due diligence checklist</li> <li>International data transfer risk and Standard Contractual Clauses (SCCs)</li> <li>Security review checklist</li> <li>Model update monitoring requirements</li> </ol> <p>[ASSUMPTION A-004] This document is premised on the assumption that Pickles GmbH uses at least one third-party AI model provider whose API receives data that may include personal data from lawyer client queries. If Pickles GmbH runs all AI inference in-house with no external model API calls, sections relating to third-party providers are not applicable \u2014 but the document should be updated to confirm this.</p> <p>[LEGAL REVIEW REQUIRED] The contractual and regulatory obligations described in this document require legal review before implementation. DPAs and SCCs are legal instruments \u2014 their execution must be overseen by a qualified legal practitioner.</p>"},{"location":"stage-3-regulatory-alignment/L2-5.3-Vendor-Model-Risk-Assessment-v1/#1-regulatory-basis","title":"1. Regulatory Basis","text":"Instrument Provision Topic GDPR Article 28 Processor / sub-processor obligations GDPR Articles 44, 46 International data transfers and appropriate safeguards GDPR Article 32 Security of processing BDSG Section 64 Security requirements \u2014 automated processing BRAW \u00a743e IT outsourcing and attorney-client confidentiality EU AI Act Article 25(4) Written agreements along the AI value chain EU AI Act Article 15 Accuracy, robustness, and cybersecurity of high-risk AI BRAK AI Position Paper Section 3.2 \u00a743e BRAO obligations for AI providers"},{"location":"stage-3-regulatory-alignment/L2-5.3-Vendor-Model-Risk-Assessment-v1/#2-third-party-model-provider-risk-profile","title":"2. Third-Party Model Provider Risk Profile","text":""},{"location":"stage-3-regulatory-alignment/L2-5.3-Vendor-Model-Risk-Assessment-v1/#21-risk-context","title":"2.1 Risk Context","text":"<p>Third-party AI model providers occupy a uniquely sensitive position in the Pickles GmbH data flow for two independent reasons:</p> <p>Reason 1 \u2014 GDPR sub-processor risk: Queries submitted to a model API may contain personal data of the lawyer client's own clients (natural persons whose legal matters are being analysed). These data subjects have no direct relationship with Pickles GmbH or the model provider. If the model provider retains, logs, or uses this data for training without authorisation, Pickles GmbH and its lawyer clients face GDPR liability.</p> <p>Reason 2 \u2014 \u00a743e BRAO attorney-client confidentiality risk: The BRAK AI Position Paper (Section 3.2) confirms that passing client secrets to a model provider, even if the provider does not actually read the information, constitutes a potential disclosure under \u00a7203(1)(3) StGB (breach of professional secrecy). The mere opportunity for access is sufficient. Pickles GmbH therefore bears a duty to ensure that any model provider receiving data from lawyer queries has contractual confidentiality obligations meeting \u00a743e BRAO standards.</p> <p>Reason 3 \u2014 EU AI Act value chain obligations: EU AI Act Article 25(4) requires that where a third party supplies an AI system, tools, or services integrated into a high-risk AI system, the provider and third party must have a written agreement specifying the information, capabilities, and technical access necessary for the provider to comply with EU AI Act obligations.</p> <p>This obligation applies explicitly to SYS-04 (high-risk) and creates a separate contractual requirement alongside GDPR Article 28 DPA obligations.</p>"},{"location":"stage-3-regulatory-alignment/L2-5.3-Vendor-Model-Risk-Assessment-v1/#3-sub-processor-criteria-and-due-diligence","title":"3. Sub-Processor Criteria and Due Diligence","text":""},{"location":"stage-3-regulatory-alignment/L2-5.3-Vendor-Model-Risk-Assessment-v1/#31-minimum-selection-criteria","title":"3.1 Minimum Selection Criteria","text":"<p>Before any third-party AI model provider is approved for use with Pickles GmbH's platform, the following minimum criteria must be satisfied:</p> # Criterion Basis Status C-01 Provider will execute a GDPR Article 28-compliant Data Processing Agreement GDPR Article 28(1) \u2610 Not confirmed [ASSUMPTION] C-02 Provider's DPA includes a prohibition on using client data for model training or improvement without explicit authorisation GDPR Article 28(3)(a); R9 from L2-5.2 \u2610 Not confirmed [ASSUMPTION] C-03 Provider will execute \u00a743e BRAO-compliant service agreement including: (1) confidentiality obligation with criminal consequences, (2) purpose limitation, (3) termination obligation if confidentiality cannot be guaranteed \u00a743e(2)(3) BRAO \u2610 Not confirmed [ASSUMPTION] C-04 Provider operates data processing infrastructure within the EEA, OR will execute EU Standard Contractual Clauses (SCCs) for non-EEA transfers GDPR Article 46; BRAK \u00a743e(4) BRAO \u2610 Not confirmed [ASSUMPTION] C-05 Provider maintains appropriate technical and organisational security measures (Article 32 compliant) GDPR Article 32; BDSG \u00a764 \u2610 Not confirmed [ASSUMPTION] C-06 Provider will not engage further sub-processors handling Pickles GmbH/client data without Pickles GmbH's prior written authorisation GDPR Article 28(2) \u2610 Not confirmed [ASSUMPTION] C-07 Provider cooperates with audits and inspections by Pickles GmbH or its mandated auditor GDPR Article 28(3)(h) \u2610 Not confirmed [ASSUMPTION] C-08 Provider returns or deletes all client data upon termination of the service relationship GDPR Article 28(3)(g) \u2610 Not confirmed [ASSUMPTION] C-09 Provider notifies Pickles GmbH without undue delay of any personal data breach GDPR Article 33(2); BDSG \u00a765(2) \u2610 Not confirmed [ASSUMPTION] C-10 For high-risk AI model providers: Provider supplies technical information required under EU AI Act Article 25(4) EU AI Act Article 25(4) \u2610 Not confirmed [ASSUMPTION]"},{"location":"stage-3-regulatory-alignment/L2-5.3-Vendor-Model-Risk-Assessment-v1/#32-preferred-provider-characteristics","title":"3.2 Preferred Provider Characteristics","text":"<p>The following are preferred (not minimum) criteria:</p> # Preference Basis P-01 Infrastructure located in Germany or EU \u2014 preferred over non-EU equivalents BRAK \u00a743e(4) BRAO; BRAK AI Position Paper Section 3.2 P-02 ISO/IEC 27001 certified for information security GDPR Article 32; best practice P-03 ISO/IEC 42001 certified or in process EU AI Act Article 15; best practice P-04 EU AI Act compliance commitments \u2014 published or contractually provided EU AI Act Article 25 P-05 Clear, public model card / model documentation available Traceability; EU AI Act Article 25(4) P-06 Promptly communicates model updates, capability changes, and version deprecations L3-6.3 Model Change Management Protocol"},{"location":"stage-3-regulatory-alignment/L2-5.3-Vendor-Model-Risk-Assessment-v1/#4-data-processing-agreement-required-content","title":"4. Data Processing Agreement \u2014 Required Content","text":""},{"location":"stage-3-regulatory-alignment/L2-5.3-Vendor-Model-Risk-Assessment-v1/#41-gdpr-article-283-mandatory-dpa-terms","title":"4.1 GDPR Article 28(3) Mandatory DPA Terms","text":"<p>Every DPA executed with a third-party AI model provider must include the following terms, per GDPR Article 28(3):</p> # Required Term Article 28(3) Paragraph DPA-01 Processor processes personal data only on documented instructions from Pickles GmbH 28(3)(a) DPA-02 Persons authorised to process data have committed to confidentiality 28(3)(b) DPA-03 Processor takes all measures required pursuant to Article 32 (security) 28(3)(c) DPA-04 Processor respects conditions for engaging sub-processors 28(3)(d) DPA-05 Processor assists Pickles GmbH in responding to data subject rights requests 28(3)(e) DPA-06 Processor assists with Articles 32\u201336 obligations (security, breach notification, DPIA) 28(3)(f) DPA-07 At Pickles GmbH's choice: deletes or returns all data after service end; deletes copies 28(3)(g) DPA-08 Processor makes available all information to demonstrate compliance; allows audits 28(3)(h) DPA-09 Processor immediately informs Pickles GmbH if an instruction infringes GDPR 28(3)(h) final subparagraph"},{"location":"stage-3-regulatory-alignment/L2-5.3-Vendor-Model-Risk-Assessment-v1/#42-additional-dpa-terms-legal-ai-context","title":"4.2 Additional DPA Terms \u2014 Legal AI Context","text":"<p>Beyond the GDPR Article 28 minimum, the following additional terms must be included given the legal AI context:</p> # Additional Term Basis ADD-01 No-training guarantee: Explicit prohibition on using any client data, query content, or output data for model training, fine-tuning, improvement, or any secondary purpose beyond service delivery GDPR Article 28(3)(a); L2-5.2 Risk R9 ADD-02 Confidentiality obligation with criminal consequences: Written acknowledgment of confidentiality obligation with explicit reference to criminal liability under \u00a7203(1)(3) StGB \u00a743e(3)(1) BRAO ADD-03 Purpose limitation in knowledge acquisition: Limitation on the scope of access to client information strictly to what is necessary for service delivery (\"need-to-know\" principle) \u00a743e(3)(2) BRAO; BRAK Section 3.2 ADD-04 Termination obligation: Obligation to terminate the relationship immediately if the confidentiality guarantee can no longer be maintained \u00a743e(2) sentence 2 BRAO ADD-05 AI-specific processing controls: No persistent storage of query content beyond what is technically necessary for inference (session-scoped only); specific retention deletion requirements L2-5.2 Controls; GDPR Article 5(1)(e) ADD-06 Model update notification: Provider must notify Pickles GmbH before deploying material model updates affecting output quality, accuracy, or safety behaviour EU AI Act Article 25(4); L3-6.3 ADD-07 Audit and testing access: Pickles GmbH has the right to conduct or commission security assessments GDPR Article 28(3)(h) ADD-08 EU AI Act Article 25(4) information: Provider must supply technical documentation, model performance information, and AI-related information sufficient for Pickles GmbH to comply with EU AI Act obligations for high-risk systems EU AI Act Article 25(4)"},{"location":"stage-3-regulatory-alignment/L2-5.3-Vendor-Model-Risk-Assessment-v1/#43-dpa-execution-requirements","title":"4.3 DPA Execution Requirements","text":"Requirement Basis DPA must be in writing, including electronic form GDPR Article 28(9) \u00a743e BRAO service agreement must be in text form (at minimum) \u00a743e(2) BRAO DPA must be executed before any client data is transmitted to the model provider GDPR Article 28(1) DPA cannot be based on standard terms that conflict with Article 28(3) requirements GDPR Article 28 Commission Standard Contractual Clauses (SCCs) may be used as a basis where applicable GDPR Article 28(6)(7)"},{"location":"stage-3-regulatory-alignment/L2-5.3-Vendor-Model-Risk-Assessment-v1/#5-international-data-transfer-risk-assessment","title":"5. International Data Transfer Risk Assessment","text":""},{"location":"stage-3-regulatory-alignment/L2-5.3-Vendor-Model-Risk-Assessment-v1/#51-transfer-risk-by-provider-location","title":"5.1 Transfer Risk by Provider Location","text":"<p>[ASSUMPTION A-004] The location of Pickles GmbH's third-party model provider is unknown. The following risk assessment applies by provider location:</p> Provider Location GDPR Transfer Mechanism \u00a743e(4) BRAO Assessment Risk Level Germany No cross-border transfer; GDPR applies German confidentiality law fully applicable Lowest \u2014 Preferred per BRAK guidance EU/EEA (non-Germany) No Chapter V mechanism required; GDPR applies Comparable confidentiality protection Low UK Adequacy decision (UK GDPR Adequacy Decision, June 2021) \u2014 review ongoing Adequate confidentiality framework Low-Medium \u2014 monitor adequacy decision status USA (Data Privacy Framework participants) EU-US Data Privacy Framework (adequacy decision July 2023) Comparable protection uncertain for legal confidentiality Medium \u2014 TIA still recommended; \u00a743e(4) assessment required USA (non-DPF) SCCs required (Commission Decision 2021/914) + TIA Comparable protection uncertain High \u2014 TIA + SCCs required; consider alternative providers Other third countries (no adequacy) SCCs + TIA required; possible derogations under Article 49 \u00a743e(4) requires special protective measures Very High \u2014 legal review required before use"},{"location":"stage-3-regulatory-alignment/L2-5.3-Vendor-Model-Risk-Assessment-v1/#52-transfer-impact-assessment-tia-requirement","title":"5.2 Transfer Impact Assessment (TIA) Requirement","text":"<p>Where Pickles GmbH uses a non-EEA model provider, it must conduct a Transfer Impact Assessment per EDPB Recommendations 01/2020. The TIA must:</p> <ol> <li>Assess the legal framework of the destination country \u2014 whether laws permit government access to transferred data in ways incompatible with GDPR</li> <li>Evaluate whether SCCs are effective in the destination country given the legal context</li> <li>Identify whether supplementary measures are needed (technical, contractual, or organisational)</li> <li>Document the assessment and the conclusion</li> </ol> <p>[LEGAL REVIEW REQUIRED] A TIA for major AI model provider jurisdictions (particularly the USA) requires specialist legal input. Pickles GmbH cannot conduct a TIA without a qualified data protection practitioner familiar with international transfer law.</p>"},{"location":"stage-3-regulatory-alignment/L2-5.3-Vendor-Model-Risk-Assessment-v1/#53-scc-module-selection","title":"5.3 SCC Module Selection","text":"<p>If SCCs are required, the correct module from Commission Decision 2021/914 must be selected:</p> Transfer Scenario SCC Module Pickles GmbH (controller) \u2192 model provider (processor) \u2014 for user account data Module 2: Controller to Processor Pickles GmbH (processor for lawyer clients) \u2192 model provider (sub-processor) \u2014 for client query data Module 3: Processor to Processor <p>[LEGAL REVIEW REQUIRED] The correct module depends on the confirmed controller/processor analysis per L2-5.1 Section 2.</p>"},{"location":"stage-3-regulatory-alignment/L2-5.3-Vendor-Model-Risk-Assessment-v1/#6-security-review-checklist","title":"6. Security Review Checklist","text":"<p>This checklist must be completed for each third-party AI model provider before initial approval and reviewed annually (or when the provider reports material security changes).</p>"},{"location":"stage-3-regulatory-alignment/L2-5.3-Vendor-Model-Risk-Assessment-v1/#61-technical-security","title":"6.1 Technical Security","text":"# Control Area Question Status SEC-01 Encryption in transit Does the provider use TLS 1.3+ for all API communications? \u2610 [ASSUMPTION \u2014 to verify] SEC-02 Encryption at rest Does the provider encrypt data at rest using AES-256 or equivalent? \u2610 [ASSUMPTION \u2014 to verify] SEC-03 Data isolation Are Pickles GmbH's queries isolated from other customers' data at inference time? \u2610 [ASSUMPTION \u2014 to verify] SEC-04 No data logging by default Does the provider's API default to no logging of query content? \u2610 Critical [ASSUMPTION \u2014 to verify] SEC-05 Data deletion Can the provider confirm deletion of all session data within a defined short period? \u2610 Critical [ASSUMPTION \u2014 to verify] SEC-06 Access controls Does the provider implement role-based access and audit logging for staff access to system components? \u2610 [ASSUMPTION \u2014 to verify] SEC-07 Adversarial input defences Has the provider published information about defence against prompt injection, data poisoning, and model evasion? \u2610 [ASSUMPTION \u2014 to verify] SEC-08 Penetration testing Does the provider conduct regular third-party penetration testing and make results available? \u2610 [ASSUMPTION \u2014 to verify] SEC-09 Incident response Does the provider have a documented incident response procedure with &lt;72hr notification commitment? \u2610 [ASSUMPTION \u2014 to verify] SEC-10 Data residency Can the provider confirm EU data residency for processing and storage? \u2610 [ASSUMPTION \u2014 to verify]"},{"location":"stage-3-regulatory-alignment/L2-5.3-Vendor-Model-Risk-Assessment-v1/#62-compliance-and-certification","title":"6.2 Compliance and Certification","text":"# Area Question Status COMP-01 ISO/IEC 27001 Is the provider ISO/IEC 27001 certified? Provide certificate. \u2610 [ASSUMPTION \u2014 to verify] COMP-02 ISO/IEC 42001 Has the provider adopted ISO/IEC 42001 or an equivalent AI management framework? \u2610 [ASSUMPTION \u2014 to verify] COMP-03 EU AI Act Has the provider published EU AI Act compliance commitments relevant to their models? \u2610 [ASSUMPTION \u2014 to verify] COMP-04 GDPR DPA Does the provider offer a GDPR-compliant DPA including Article 28(3) terms and no-training guarantee? \u2610 Critical [ASSUMPTION \u2014 to verify] COMP-05 Supervisory authority investigations Is the provider currently under investigation by a data protection supervisory authority? \u2610 [ASSUMPTION \u2014 to verify] COMP-06 Sub-processors Does the provider maintain and publish a current sub-processor list? \u2610 [ASSUMPTION \u2014 to verify]"},{"location":"stage-3-regulatory-alignment/L2-5.3-Vendor-Model-Risk-Assessment-v1/#63-model-transparency","title":"6.3 Model Transparency","text":"# Area Question Status MOD-01 Model card Has the provider published a model card or equivalent documentation for the model used? \u2610 [ASSUMPTION \u2014 to verify] MOD-02 Training data Has the provider disclosed the general nature of training data and data governance practices? \u2610 [ASSUMPTION \u2014 to verify] MOD-03 Performance benchmarks Has the provider published performance benchmarks relevant to legal text tasks? \u2610 [ASSUMPTION \u2014 to verify] MOD-04 Known limitations Has the provider disclosed known limitations and failure modes? \u2610 [ASSUMPTION \u2014 to verify] MOD-05 Hallucination rate Has the provider published hallucination rate data or guidance? \u2610 [ASSUMPTION \u2014 to verify] MOD-06 Bias assessment Has the provider published bias assessment results for the model? \u2610 [ASSUMPTION \u2014 to verify]"},{"location":"stage-3-regulatory-alignment/L2-5.3-Vendor-Model-Risk-Assessment-v1/#7-model-update-monitoring","title":"7. Model Update Monitoring","text":""},{"location":"stage-3-regulatory-alignment/L2-5.3-Vendor-Model-Risk-Assessment-v1/#71-why-model-updates-are-high-risk-for-legal-ai","title":"7.1 Why Model Updates Are High-Risk for Legal AI","text":"<p>Third-party AI model providers regularly update their models. For a legal AI provider like Pickles GmbH, model updates carry particular risks:</p> <ul> <li>Accuracy regression: An updated model may perform worse on legal citation accuracy or legal reasoning tasks</li> <li>Behavioural changes: Output style, length, or safety filtering may change without warning</li> <li>Capability changes: A model update could expand or restrict the model's ability to handle certain legal topics</li> <li>EU AI Act implications: Substantial changes to a third-party model that is integrated into a high-risk system (SYS-04) may require re-assessment under EU AI Act Article 6(2) and Article 17</li> </ul> <p>For a full model update management protocol, see L3-6.3. This section addresses the vendor-specific monitoring obligations.</p>"},{"location":"stage-3-regulatory-alignment/L2-5.3-Vendor-Model-Risk-Assessment-v1/#72-required-contractual-commitments-from-model-providers","title":"7.2 Required Contractual Commitments from Model Providers","text":"# Commitment Basis MU-01 Provider gives advance notice (minimum 30 days [ASSUMPTION]) of material model updates affecting output quality, accuracy, safety, or API behaviour EU AI Act Article 25(4); good practice MU-02 Provider maintains version-locked API access for a defined period (e.g., 6\u201312 months) after a new model version is deployed Good practice; operational continuity MU-03 Provider publishes release notes and changelog for each model update Transparency; EU AI Act Article 25(4) MU-04 Provider cooperates with Pickles GmbH's regression testing on updated models before production deployment Good practice; EU AI Act Article 9(6) MU-05 Provider notifies Pickles GmbH of security vulnerabilities or adversarial risk disclosures affecting the model EU AI Act Article 15(5); GDPR Article 32"},{"location":"stage-3-regulatory-alignment/L2-5.3-Vendor-Model-Risk-Assessment-v1/#73-pickles-gmbhs-internal-model-update-response-process","title":"7.3 Pickles GmbH's Internal Model Update Response Process","text":"<p>When a third-party model provider announces a material update, Pickles GmbH must:</p> Step Action Owner [ASSUMPTION] Timing 1 Receive provider update notification Head of Engineering [ASSUMPTION] Before update deployment 2 Assess whether update constitutes a material change under L3-6.3 criteria Head of Product + Engineering [ASSUMPTION] Within 5 business days of notification 3 Conduct regression testing on benchmark legal query suite Head of Engineering [ASSUMPTION] Before production deployment 4 Assess EU AI Act implications (Article 6(2) substantial modification?) Legal / AIRO [ASSUMPTION] Before production deployment 5 Update Technical Documentation Pack (L2-4.2 Section 6) to record change Head of Engineering [ASSUMPTION] At point of deployment 6 Deploy update in staging environment; validate outputs Head of Engineering [ASSUMPTION] Before production deployment 7 Deploy to production with monitoring Head of Engineering [ASSUMPTION] After validation 8 Notify lawyer clients of material model changes affecting system behaviour [ASSUMPTION] Client Success / Legal [ASSUMPTION] Per client notification obligations in DPA <p>Full change management process is documented in L3-6.3-Model-Change-Management-Protocol-v1.md.</p>"},{"location":"stage-3-regulatory-alignment/L2-5.3-Vendor-Model-Risk-Assessment-v1/#8-ongoing-vendor-management","title":"8. Ongoing Vendor Management","text":""},{"location":"stage-3-regulatory-alignment/L2-5.3-Vendor-Model-Risk-Assessment-v1/#81-review-frequency","title":"8.1 Review Frequency","text":"Review Type Frequency Trigger Security checklist review Annual Annually; or on notification of security incident DPA compliance review Annual Annually; or when provider updates DPA terms SCC/TIA review Biennial or on legal framework change Schrems II-type events; adequacy decision changes Sub-processor list review Quarterly On provider sub-processor change notification Model update assessment Per update On provider model update notification \u00a743e BRAO compliance review Annual Annually; or on legal developments in BRAK guidance"},{"location":"stage-3-regulatory-alignment/L2-5.3-Vendor-Model-Risk-Assessment-v1/#82-vendor-risk-register","title":"8.2 Vendor Risk Register","text":"<p>For each approved third-party model provider, maintain a vendor risk register entry covering:</p> Field Content Provider name [PLACEHOLDER] Model(s) used [PLACEHOLDER] Provider location [PLACEHOLDER] Transfer mechanism [PLACEHOLDER \u2014 EEA / SCC Module 2 / SCC Module 3 / DPF] DPA executed date [PLACEHOLDER] \u00a743e BRAO agreement executed date [PLACEHOLDER] SCCs executed date (if applicable) [PLACEHOLDER] TIA conducted date (if applicable) [PLACEHOLDER] ISO 27001 certificate number [PLACEHOLDER] Last security review date [PLACEHOLDER] Next review due [PLACEHOLDER] Current risk level [PLACEHOLDER \u2014 Low / Medium / High] Open issues [PLACEHOLDER]"},{"location":"stage-3-regulatory-alignment/L2-5.3-Vendor-Model-Risk-Assessment-v1/#9-provider-non-compliance-response","title":"9. Provider Non-Compliance Response","text":"<p>If a third-party model provider fails to meet minimum criteria (Section 3.1), or is found to be in breach of DPA terms:</p> Severity Response Critical breach (e.g., data training without consent; confidentiality breach) Suspend API use immediately; notify lawyer clients per DPA terms; notify DPO; assess GDPR breach notification obligations; consider supervisory authority notification; engage legal counsel Material non-compliance (e.g., failure to delete data; sub-processor not authorised) Issue formal notice to provider; set cure period (maximum 30 days [ASSUMPTION]); escalate to suspension if not cured Procedural non-compliance (e.g., late update notification) Issue formal notice; document; review at next scheduled vendor assessment <p>Per \u00a743e(2) BRAO: if confidentiality cannot be guaranteed, \"cooperation must be terminated immediately.\"</p>"},{"location":"stage-3-regulatory-alignment/L2-5.3-Vendor-Model-Risk-Assessment-v1/#document-control","title":"Document Control","text":"Field Detail Document ID L2-5.3 Applies to All third-party AI model providers used by Pickles GmbH [ASSUMPTION A-004] Next review Before first model provider engagement; annually thereafter Cross-references L2-5.1 (Data Flow Map), L2-5.2 (DPIA Assessment), L3-6.3 (Model Change Management), L1-3.3 (AI Intake Approval Workflow) Regulatory basis GDPR Articles 28, 44, 46, 32; BDSG \u00a764; \u00a743e BRAO; EU AI Act Articles 15, 25(4) Assumptions relied upon A-003, A-004, A-005"},{"location":"stage-4-monitoring-controls/L3-6.1-AI-Monitoring-Framework-v1/","title":"AI Monitoring Framework","text":"<p>Project: Pickles GmbH \u2014 AI Governance Framework Stage: Stage 4 \u2014 Monitoring &amp; Operational Controls Status: Draft Version: v1 Date: 2026-02-26 Assumptions: Built on outline assumptions \u2014 not verified against real Pickles GmbH data</p>"},{"location":"stage-4-monitoring-controls/L3-6.1-AI-Monitoring-Framework-v1/#purpose","title":"Purpose","text":"<p>This document defines Pickles GmbH's operational monitoring framework for all deployed AI systems. It fulfils the post-market monitoring system requirement under EU AI Act Article 72 for SYS-04 (high-risk), and establishes good-practice monitoring for SYS-01 through SYS-03 (limited-risk).</p> <p>Regulatory basis: - EU AI Act Article 72 \u2014 Post-market monitoring system (mandatory for SYS-04) - EU AI Act Article 9(2)(c) \u2014 Risk management system: continuous iterative process including data from post-market monitoring - EU AI Act Article 15 \u2014 Accuracy, robustness, and cybersecurity performance targets - EU AI Act Article 17(1)(h) \u2014 Quality management system must include post-market monitoring - EU AI Act Article 12 \u2014 Logging requirements for high-risk AI systems - ISO/IEC 42001 Clauses 9.1, 9.2, 9.3 \u2014 Performance evaluation</p> <p>[ASSUMPTION] All metrics, thresholds, and measurement methods in this document are proposed based on the assumed product architecture. They must be validated against real system capabilities and real baseline performance data before operational use.</p> <p>[LEGAL REVIEW REQUIRED] Article 72(3) requires the post-market monitoring plan for SYS-04 to form part of the Annex IV technical documentation (L2-4.2 Section 9). The Commission implementing act establishing the template for that plan was due by 2 February 2026 \u2014 check whether it has been published and update accordingly.</p>"},{"location":"stage-4-monitoring-controls/L3-6.1-AI-Monitoring-Framework-v1/#1-scope","title":"1. Scope","text":"System Risk Tier Monitoring Obligation Notes SYS-01 \u2014 Legal Research Assistant Tier 3 Limited-risk Good practice monitoring No Article 72 mandate SYS-02 \u2014 Document Drafting Tool Tier 3 Limited-risk Good practice monitoring No Article 72 mandate SYS-03 \u2014 Document Summarisation Tool Tier 3 Limited-risk Good practice monitoring No Article 72 mandate SYS-04 \u2014 Legal Analysis Tool Tier 2 High-risk Article 72 mandatory post-market monitoring Full monitoring plan required"},{"location":"stage-4-monitoring-controls/L3-6.1-AI-Monitoring-Framework-v1/#2-monitoring-architecture","title":"2. Monitoring Architecture","text":""},{"location":"stage-4-monitoring-controls/L3-6.1-AI-Monitoring-Framework-v1/#21-data-collection-sources","title":"2.1 Data Collection Sources","text":"<p>Per Article 72(2), monitoring data may be provided by deployers or collected from other sources. [ASSUMPTION] Pickles GmbH collects monitoring data from:</p> Source Data Type Collection Method Platform event logs (Article 12) Session events, errors, latency Automated \u2014 system-generated [ASSUMPTION] User feedback mechanism (in-product) User-reported errors, inaccuracies, complaints In-product flag/report button [ASSUMPTION] Lawyer client reports Client-escalated accuracy concerns Structured incident report form [ASSUMPTION] Automated output sampling Periodic automated quality checks Sampling pipeline [ASSUMPTION] Expert review panel Independent legal accuracy assessment Quarterly panel review [ASSUMPTION] Model provider notifications Model version changes, known issues Provider update channel per L2-5.3"},{"location":"stage-4-monitoring-controls/L3-6.1-AI-Monitoring-Framework-v1/#22-monitoring-responsibilities","title":"2.2 Monitoring Responsibilities","text":"<p>[ASSUMPTION]</p> Role Monitoring Responsibility AI Risk and Information Officer (AIRO) Owns monitoring framework; reviews monthly dashboard; escalates to CEO Head of Engineering Operates technical monitoring tooling; reviews daily/weekly technical metrics Head of Product Reviews output quality and user experience metrics; owns expert review panel DPO Reviews data-related metrics; receives breach-relevant flags Client Success Aggregates and categorises client-reported concerns"},{"location":"stage-4-monitoring-controls/L3-6.1-AI-Monitoring-Framework-v1/#3-metrics-framework","title":"3. Metrics Framework","text":""},{"location":"stage-4-monitoring-controls/L3-6.1-AI-Monitoring-Framework-v1/#31-primary-metrics-table","title":"3.1 Primary Metrics Table","text":"# Metric Description System Scope Measurement Method Frequency Alert Threshold [ASSUMPTION] M-01 Hallucination / factual error rate Rate of AI outputs containing demonstrably false or unsupported legal statements SYS-01, SYS-02, SYS-03, SYS-04 Expert review panel sampling (n=50 outputs per system per quarter); user-reported errors normalised to output volume Quarterly (expert); ongoing (user-reported) &gt;2% expert-identified errors per sample triggers review; &gt;5% triggers incident M-02 Citation accuracy rate Rate of legal citations (case references, article numbers, legislation) that are correctly identified and traceable SYS-01, SYS-04 Automated citation verification against legal database [ASSUMPTION]; monthly sample audit Monthly automated; quarterly audit &lt;95% accuracy triggers investigation; &lt;90% triggers incident M-03 User error report rate Volume of user-submitted error/inaccuracy reports per 1,000 outputs All systems In-product reporting tool; normalised to output volume Weekly &gt;5 reports per 1,000 outputs triggers product review M-04 Output override / discard rate Rate at which users actively discard or override AI outputs All systems User action logging (override/discard events) Weekly Significant increase (&gt;20% week-on-week) triggers investigation \u2014 may indicate quality degradation or automation bias reduction M-05 Bias signal monitoring Differential performance across document language (German/English), practice area, or document type SYS-01, SYS-04 Stratified sampling by category; compare error rates across strata Quarterly Statistically significant performance gap between strata triggers bias investigation M-06 System availability / uptime Percentage of time system is available and responsive All systems Infrastructure monitoring Continuous &lt;99.5% monthly uptime triggers engineering review M-07 Latency \u2014 P95 response time 95th percentile response time for standard queries All systems Infrastructure monitoring Continuous &gt;10 seconds P95 triggers engineering review [ASSUMPTION] M-08 Model drift indicator Detected change in output distribution, style, or behaviour without an authorised model update SYS-04 Automated comparison of output embedding distribution against baseline; triggered on model provider update notifications Continuous; reviewed monthly Any statistically significant drift not attributable to an authorised update triggers L3-6.3 change management M-09 Complaint volume and classification Number and category of formal client complaints relating to AI output quality All systems Client complaints log (Client Success); AIRO review Monthly &gt;3 complaints per month in same category triggers root cause analysis M-10 Out-of-scope use detection Queries or use patterns outside the system's intended purpose SYS-04 Log analysis for query patterns outside defined intended purpose categories [ASSUMPTION] Monthly Confirmed out-of-scope use pattern triggers client communication and Terms of Service review"},{"location":"stage-4-monitoring-controls/L3-6.1-AI-Monitoring-Framework-v1/#32-sys-04-high-risk-specific-metrics-article-72-post-market-monitoring","title":"3.2 SYS-04 High-Risk Specific Metrics (Article 72 \u2014 Post-Market Monitoring)","text":"<p>In addition to M-01 through M-10, SYS-04 requires the following Article 72-specific monitoring to evaluate continuous compliance with Chapter III Section 2 requirements:</p> # Metric Chapter III Section 2 Requirement Measurement Method M-11 Risk management system effectiveness Article 9 \u2014 ongoing risk management Annual risk management review; compare identified risks against incident log M-12 Human oversight compliance Article 14 \u2014 users able to override, disregard, halt Quarterly audit of override/discard rate (M-04); user competence assessment [ASSUMPTION] M-13 Logging completeness Article 12 \u2014 automatic event logging Monthly log audit \u2014 confirm all session events are captured; no gaps M-14 Accuracy declaration compliance Article 15(3) \u2014 accuracy metrics declared in instructions for use Quarterly comparison of actual accuracy (M-01, M-02) against declared metrics; flag if actual performance falls below declared level M-15 Cybersecurity posture Article 15(5) \u2014 resilience against adversarial inputs Annual penetration test; quarterly review of prompt injection defence logs [ASSUMPTION]"},{"location":"stage-4-monitoring-controls/L3-6.1-AI-Monitoring-Framework-v1/#4-monitoring-frequency-and-reporting-schedule","title":"4. Monitoring Frequency and Reporting Schedule","text":"Frequency Activities Output Recipient [ASSUMPTION] Continuous Uptime, latency, error alerts (M-06, M-07), drift detection (M-08) Real-time alerts Head of Engineering Weekly User error report rate (M-03), override/discard rate (M-04) Weekly metrics digest Head of Product, Head of Engineering Monthly Citation accuracy (M-02 automated), complaint classification (M-09), out-of-scope use (M-10), logging audit (M-13) Monthly monitoring report AIRO, DPO (data-related metrics) Quarterly Hallucination/error rate (M-01 expert review), bias signals (M-05), human oversight compliance (M-12), accuracy declaration compliance (M-14) Quarterly performance report AIRO, CEO, Head of Product Annual Risk management system effectiveness (M-11), cybersecurity posture (M-15), full post-market monitoring plan review Annual AI system review CEO, AIRO, DPO, Board [ASSUMPTION]"},{"location":"stage-4-monitoring-controls/L3-6.1-AI-Monitoring-Framework-v1/#5-dashboard-design","title":"5. Dashboard Design","text":"<p>[ASSUMPTION] Pickles GmbH's monitoring dashboard aggregates the above metrics into a single view accessible to the AIRO and senior leadership. Recommended dashboard structure:</p>"},{"location":"stage-4-monitoring-controls/L3-6.1-AI-Monitoring-Framework-v1/#51-dashboard-sections","title":"5.1 Dashboard Sections","text":"<p>Section A \u2014 System Health (Real-time) - Uptime status per system (RAG: green/amber/red) - P95 latency per system - Active incident count (links to L3-6.2 incident log)</p> <p>Section B \u2014 Output Quality (Weekly/Monthly) - User error report rate trend (line chart, 13-week rolling) - Override/discard rate trend (line chart, 13-week rolling) - Complaint volume by category (bar chart, monthly) - Citation accuracy rate (SYS-01, SYS-04) \u2014 monthly trend</p> <p>Section C \u2014 High-Risk Compliance (SYS-04) - Last expert review date and result (M-01) - Logging completeness status (M-13) - Drift indicator status (M-08) - Days since last model update and change management status</p> <p>Section D \u2014 Governance - Open action items from previous monitoring reports - Next scheduled expert review date - Assumptions requiring verification (link to ASSUMPTIONS-LOG.md)</p>"},{"location":"stage-4-monitoring-controls/L3-6.1-AI-Monitoring-Framework-v1/#6-escalation-thresholds-and-incident-triggers","title":"6. Escalation Thresholds and Incident Triggers","text":"<p>When a monitoring metric breaches its alert threshold, the following escalation applies:</p> Trigger Immediate Action Escalation Path M-01 &gt;5% error rate in expert sample Pause deployment of affected system pending investigation Head of Engineering \u2192 AIRO \u2192 CEO; activate L3-6.2 M-02 citation accuracy &lt;90% Investigate root cause; suspend marketing claims about accuracy Head of Product \u2192 AIRO M-08 confirmed unauthorised model drift Activate L3-6.3 change management; assess Article 20 / Article 73 obligations Head of Engineering \u2192 AIRO \u2192 Legal Any metric meeting Article 3(49) serious incident definition Activate L3-6.2 Incident Response Playbook immediately AIRO \u2192 CEO \u2192 Legal \u2192 Article 73 reporting GDPR data breach detected Activate L3-6.2 GDPR breach channel; 72-hour GDPR Article 33 clock starts DPO \u2192 CEO \u2192 Legal"},{"location":"stage-4-monitoring-controls/L3-6.1-AI-Monitoring-Framework-v1/#7-post-market-monitoring-plan-sys-04-article-72","title":"7. Post-Market Monitoring Plan \u2014 SYS-04 (Article 72)","text":"<p>This section constitutes the post-market monitoring plan for SYS-04 required by Article 72(3). It must be incorporated into the SYS-04 Technical Documentation Pack (L2-4.2 Section 9).</p> Element Content Monitoring objective Evaluate continuous compliance of SYS-04 with Chapter III Section 2 requirements throughout its operational lifetime Data actively collected Metrics M-01 through M-15 as defined in Section 3; event logs per Article 12 Data from deployers Client-reported errors (M-03, M-09); client-confirmed out-of-scope use reports (M-10) [ASSUMPTION] Review frequency Per Section 4 schedule; annual comprehensive review Compliance evaluation trigger Any metric breach (Section 6) triggers compliance re-evaluation against Chapter III Section 2 Corrective action link Metric breaches trigger L3-6.2 (incident) or L3-6.3 (change management) as appropriate Interaction with other AI systems [ASSUMPTION] SYS-04 does not currently interact with other AI systems \u2014 confirm against real architecture; update if integration occurs Plan update trigger Material change to SYS-04 (L3-6.3); change in regulatory requirements; annual review"},{"location":"stage-4-monitoring-controls/L3-6.1-AI-Monitoring-Framework-v1/#8-cross-references","title":"8. Cross-References","text":"Document Relevance L2-4.1 \u2014 EU AI Act Risk Mapping Matrix Risk classification determining Article 72 scope L2-4.2 \u2014 Technical Documentation Pack Section 9 \u2014 post-market monitoring plan; Section 2.7 \u2014 accuracy metrics declared L3-6.2 \u2014 Incident Response Playbook Activated when monitoring triggers Article 3(49) or GDPR breach L3-6.3 \u2014 Model Change Management Protocol Activated when monitoring detects drift or change event L2-5.3 \u2014 Vendor Risk Assessment Model provider update notifications feed into M-08"},{"location":"stage-4-monitoring-controls/L3-6.1-AI-Monitoring-Framework-v1/#document-control","title":"Document Control","text":"Field Detail Document ID L3-6.1 Next review Annual; or when SYS-04 model changes materially Regulatory basis EU AI Act Articles 9, 12, 15, 17(1)(h), 72; ISO/IEC 42001 Clauses 9.1\u20139.3 Assumptions relied upon A-001, A-004, A-005, A-009"},{"location":"stage-4-monitoring-controls/L3-6.2-Incident-Response-Playbook-v1/","title":"Incident Response Playbook","text":"<p>Project: Pickles GmbH \u2014 AI Governance Framework Stage: Stage 4 \u2014 Monitoring &amp; Operational Controls Status: Draft Version: v1 Date: 2026-02-26 Assumptions: Built on outline assumptions \u2014 not verified against real Pickles GmbH data</p>"},{"location":"stage-4-monitoring-controls/L3-6.2-Incident-Response-Playbook-v1/#purpose","title":"Purpose","text":"<p>This playbook defines how Pickles GmbH identifies, classifies, escalates, and resolves incidents involving its AI systems. It covers: - Internal incident management (all systems) - EU AI Act Article 73 serious incident reporting obligations (SYS-04, high-risk) - GDPR Article 33/34 personal data breach notification - BDSG \u00a765/66 breach notification under German law - Client notification requirements - Root cause analysis template</p> <p>[ASSUMPTION] Contact details, escalation paths, and authority assignments are placeholder \u2014 must be completed with real names and roles before operational use.</p> <p>[LEGAL REVIEW REQUIRED] Regulatory reporting obligations under Article 73 and GDPR Article 33 are time-critical and carry legal consequences for non-compliance. This playbook must be reviewed by a qualified legal practitioner before it is relied upon operationally.</p>"},{"location":"stage-4-monitoring-controls/L3-6.2-Incident-Response-Playbook-v1/#1-incident-definition","title":"1. Incident Definition","text":""},{"location":"stage-4-monitoring-controls/L3-6.2-Incident-Response-Playbook-v1/#11-what-is-an-incident","title":"1.1 What Is an Incident","text":"<p>For the purposes of this playbook, an incident is any unplanned event or pattern affecting a Pickles GmbH AI system that: - Causes or risks causing harm to a user, client, or third party - Represents a material failure of the system to operate within its intended purpose - Triggers a regulatory reporting or notification obligation - Results in a personal data breach - Causes or risks causing reputational, financial, or legal harm to Pickles GmbH</p> <p>Monitoring alerts from L3-6.1 that breach defined thresholds are the primary source of incident triggers.</p>"},{"location":"stage-4-monitoring-controls/L3-6.2-Incident-Response-Playbook-v1/#12-eu-ai-act-serious-incident-definition","title":"1.2 EU AI Act Serious Incident Definition","text":"<p>Article 3(49) defines a serious incident as an incident or malfunctioning of an AI system that directly or indirectly leads to: - (a) The death of a person, or serious harm to a person's health - (b) A serious and irreversible disruption of the management or operation of critical infrastructure - (c) The infringement of obligations under Union law intended to protect fundamental rights - (d) Serious harm to property or the environment</p> <p>For Pickles GmbH: Article 3(49)(c) \u2014 infringement of fundamental rights obligations \u2014 is the most likely serious incident category. A materially flawed SYS-04 legal analysis output that is relied upon in legal proceedings without adequate lawyer review, and that causes a demonstrable infringement of a party's right to a fair trial or effective legal representation, could constitute a serious incident under this definition. [LEGAL REVIEW REQUIRED]</p>"},{"location":"stage-4-monitoring-controls/L3-6.2-Incident-Response-Playbook-v1/#13-gdpr-personal-data-breach-definition","title":"1.3 GDPR Personal Data Breach Definition","text":"<p>A personal data breach (GDPR Article 4(12)) is a breach of security leading to the accidental or unlawful destruction, loss, alteration, unauthorised disclosure of, or access to, personal data transmitted, stored, or otherwise processed.</p>"},{"location":"stage-4-monitoring-controls/L3-6.2-Incident-Response-Playbook-v1/#2-incident-examples-by-system","title":"2. Incident Examples by System","text":"Example Incident System Likely Classification AI output contains a fabricated case citation relied upon by a lawyer in a court submission SYS-01, SYS-04 P1 / potential Article 3(49)(c) serious incident SYS-04 produces systematically flawed analysis for a specific document type (discovered via M-01) SYS-04 P1 \u2014 immediate investigation; possible Article 20 corrective action User-reported error rate spikes above threshold; root cause unknown Any system P2 \u2014 investigation; possible escalation to P1 Third-party model provider suffers security breach; client query data may be exposed SYS-04 P1 \u2014 GDPR Article 33 clock starts; potential Article 73 implications System returns outputs containing personal data from a different user's session (data isolation failure) Any system P1 \u2014 GDPR Article 33 breach notification; potential data subject notification Unauthorised model drift detected: outputs changed without authorised update SYS-04 P2 \u2014 activate L3-6.3; assess Article 20/73 Planned maintenance window overruns; system unavailable for 4 hours Any system P3 \u2014 client notification; no regulatory trigger Single user complaint about output quality; no pattern detected Any system P4 \u2014 log and investigate; no escalation"},{"location":"stage-4-monitoring-controls/L3-6.2-Incident-Response-Playbook-v1/#3-severity-classification","title":"3. Severity Classification","text":"Severity Definition Examples Response Time P1 \u2014 Critical Actual or probable serious harm to a person; potential Article 3(49) serious incident; confirmed personal data breach; Article 20 non-conformity Fabricated legal citation in court submission; data breach exposing client personal data; SYS-04 systemic failure Immediate \u2014 within 1 hour of detection P2 \u2014 High Material quality failure without confirmed harm; unplanned model drift; suspected (unconfirmed) data breach; pattern of errors meeting L3-6.1 alert thresholds Spike in user error reports; citation accuracy below 90%; unauthorised model drift detected Within 4 business hours of detection P3 \u2014 Medium Degraded performance affecting users; planned maintenance overruns; single client escalation with potential pattern System latency exceeding SLA; extended planned downtime; second client complaint in same category within 30 days Within 1 business day P4 \u2014 Low Isolated user complaint; minor quality issue; no threshold breach; no harm Single user error report; cosmetic output formatting issue; feature request misidentified as defect Within 3 business days"},{"location":"stage-4-monitoring-controls/L3-6.2-Incident-Response-Playbook-v1/#4-escalation-paths","title":"4. Escalation Paths","text":""},{"location":"stage-4-monitoring-controls/L3-6.2-Incident-Response-Playbook-v1/#p1-critical-incident-escalation","title":"P1 \u2014 Critical Incident Escalation","text":"<pre><code>Detection (L3-6.1 monitoring / user report / deployer notification)\n    \u2502\n    \u25bc Within 15 minutes\nHead of Engineering \u2014 confirmed? \u2192 If not confirmed: investigate; escalate if confirmed\n    \u2502\n    \u25bc Within 1 hour\nAIRO notified \u2014 initiates P1 incident log; assigns Incident Commander\n    \u2502\n    \u251c\u2500\u25ba CEO notified immediately\n    \u251c\u2500\u25ba DPO notified immediately (if data breach suspected)\n    \u2514\u2500\u25ba Legal counsel notified (if Article 73 or GDPR reporting may be required)\n    \u2502\n    \u25bc Within 2 hours\nRegulatory clock assessment:\n    \u251c\u2500\u25ba EU AI Act Article 73 trigger? \u2192 If yes: prepare report; see Section 6\n    \u2514\u2500\u25ba GDPR Article 33 trigger? \u2192 If yes: 72-hour clock starts; see Section 7\n    \u2502\n    \u25bc Ongoing\nIncident log updated every 2 hours until resolution\nClient notification assessed \u2014 see Section 8\nSystem suspension decision if harm ongoing (Article 20)\n</code></pre>"},{"location":"stage-4-monitoring-controls/L3-6.2-Incident-Response-Playbook-v1/#p2-high-severity-escalation","title":"P2 \u2014 High Severity Escalation","text":"<p>Head of Engineering \u2192 Head of Product \u2192 AIRO (within 4 hours) \u2192 CEO (if Article 20 obligations may arise) \u2192 DPO (if data-related)</p>"},{"location":"stage-4-monitoring-controls/L3-6.2-Incident-Response-Playbook-v1/#p3-medium-severity","title":"P3 \u2014 Medium Severity","text":"<p>Head of Engineering \u2192 Head of Product \u2192 client notification if SLA breach \u2192 AIRO weekly summary</p>"},{"location":"stage-4-monitoring-controls/L3-6.2-Incident-Response-Playbook-v1/#p4-low-severity","title":"P4 \u2014 Low Severity","text":"<p>Head of Product \u2192 logged in incident register \u2192 reviewed in monthly monitoring report</p>"},{"location":"stage-4-monitoring-controls/L3-6.2-Incident-Response-Playbook-v1/#5-regulatory-reporting-triggers","title":"5. Regulatory Reporting Triggers","text":""},{"location":"stage-4-monitoring-controls/L3-6.2-Incident-Response-Playbook-v1/#51-eu-ai-act-article-73-serious-incident-reporting-sys-04-only","title":"5.1 EU AI Act Article 73 \u2014 Serious Incident Reporting (SYS-04 Only)","text":"<p>Article 73 applies to SYS-04 (high-risk) only. Reporting is to the market surveillance authority of the Member State where the incident occurred. [ASSUMPTION] For Pickles GmbH, the competent German market surveillance authority must be identified and contact details maintained. [LEGAL REVIEW REQUIRED \u2014 confirm which authority is competent for SYS-04 in Germany]</p> <p>Reporting trigger: Reasonable likelihood that the incident is causally linked to SYS-04, AND the incident meets the Article 3(49) serious incident definition.</p> Incident Type Reporting Deadline Notes Standard serious incident (Art. 3(49)(a)(c)(d)) 15 days from provider awareness of causal link or reasonable likelihood Initial report may be incomplete (Art. 73(5)) Widespread infringement OR critical infrastructure (Art. 3(49)(b)) 2 days from awareness Immediate notification Death of a person (Art. 3(49)(a)) 10 days from awareness; immediate when causal link suspected Highest priority <p>Post-notification obligations (Article 73(6)): - Immediately investigate incident and AI system - Conduct risk assessment of incident - Take corrective action - Cooperate with competent authorities - Do NOT alter the AI system in ways that may affect evaluation of incident causes before informing authorities</p> <p>Article 20 non-conformity trigger: If the incident indicates SYS-04 is not in conformity with the EU AI Act, Article 20 requires: - Immediate corrective action (up to and including withdrawal/recall) - Notification to deployers (lawyer clients) - If Article 79(1) risk: inform market surveillance authority</p>"},{"location":"stage-4-monitoring-controls/L3-6.2-Incident-Response-Playbook-v1/#52-gdpr-article-33-data-breach-notification-to-supervisory-authority","title":"5.2 GDPR Article 33 \u2014 Data Breach Notification to Supervisory Authority","text":"<p>Trigger: A personal data breach has occurred (GDPR Article 4(12) definition met).</p> <p>Deadline: Without undue delay and, where feasible, not later than 72 hours after becoming aware of the breach.</p> <p>Supervisory authority: [ASSUMPTION] For Pickles GmbH: the Federal Commissioner for Data Protection and Freedom of Information (Bundesbeauftragter f\u00fcr den Datenschutz und die Informationsfreiheit \u2014 BfDI), or the relevant Landesbeauftragter depending on Pickles GmbH's registration. [LEGAL REVIEW REQUIRED]</p> <p>Report must include (Article 33(3)): - Nature of the breach including categories and approximate number of data subjects and records - Name and contact details of the DPO - Likely consequences of the breach - Measures taken or proposed to address the breach</p> <p>Exception: Notification not required if the breach is unlikely to result in a risk to the rights and freedoms of natural persons.</p> <p>BDSG \u00a765 parallel obligation: Same 72-hour deadline applies to notification to the Federal Commissioner under the BDSG framework for processing under Part 3 BDSG. [LEGAL REVIEW REQUIRED \u2014 confirm which regime applies]</p>"},{"location":"stage-4-monitoring-controls/L3-6.2-Incident-Response-Playbook-v1/#53-gdpr-article-34-data-breach-notification-to-data-subjects","title":"5.3 GDPR Article 34 \u2014 Data Breach Notification to Data Subjects","text":"<p>Trigger: Personal data breach is likely to result in high risk to the rights and freedoms of natural persons.</p> <p>Deadline: Without undue delay.</p> <p>Exemptions (Article 34(3)): - Affected data was encrypted and unintelligible to unauthorised persons - Subsequent measures have eliminated the high risk - Disproportionate effort \u2014 public communication instead</p> <p>BDSG \u00a766 parallel obligation: Where the breach results in substantial risk to legally protected interests of natural persons, data subjects must be notified without delay. [LEGAL REVIEW REQUIRED]</p>"},{"location":"stage-4-monitoring-controls/L3-6.2-Incident-Response-Playbook-v1/#6-incident-log-template","title":"6. Incident Log Template","text":"<p>A new log entry is created for every incident at P4 or above. Log is maintained by the AIRO.</p> <pre><code>INCIDENT LOG \u2014 [INCIDENT-ID: INC-YYYY-MM-DD-NN]\n\nDate/time detected:\nDate/time reported to AIRO:\nDetected by:\nSystem affected:\nSeverity classification (P1/P2/P3/P4):\nIncident Commander (P1/P2 only):\n\nDESCRIPTION\nWhat happened:\nHow detected (monitoring / user report / deployer report / other):\nSystems and data affected:\nNumber of users/clients potentially affected:\nPersonal data involved? (Y/N):\nIf yes \u2014 categories and approximate number of data subjects:\n\nREGULATORY TRIGGER ASSESSMENT\nEU AI Act Article 3(49) serious incident? (Y/N/Under assessment):\nIf yes \u2014 Article 73 reporting deadline:\nGDPR Article 33 breach notification required? (Y/N/Under assessment):\nIf yes \u2014 72-hour clock start time:\nGDPR Article 34 data subject notification required? (Y/N/Under assessment):\n\nTIMELINE\n[Timestamp] \u2014 [Action taken] \u2014 [By whom]\n\nCONTAINMENT ACTIONS\nImmediate containment steps taken:\nSystem suspended? (Y/N):\n\nCLIENT NOTIFICATION\nClients notified? (Y/N \u2014 if P1/P2):\nDate/time of client notification:\nMethod:\n\nREGULATORY NOTIFICATIONS\nArticle 73 report submitted? (Y/N \u2014 SYS-04 serious incidents only):\nSubmission date/reference:\nGDPR Article 33 report submitted?\nSubmission date/reference:\n\nRESOLUTION\nRoot cause (summary \u2014 full RCA in Section 7 template):\nCorrective actions taken:\nDate resolved:\nRecurrence prevention measures:\n\nSIGN-OFF\nAIRO:                    Date:\nDPO (if data breach):    Date:\nCEO (if P1):             Date:\n</code></pre>"},{"location":"stage-4-monitoring-controls/L3-6.2-Incident-Response-Playbook-v1/#7-root-cause-analysis-template","title":"7. Root Cause Analysis Template","text":"<p>To be completed for every P1 and P2 incident; recommended for significant P3 incidents.</p> <pre><code>ROOT CAUSE ANALYSIS \u2014 [INCIDENT-ID]\n\n1. INCIDENT SUMMARY\n   What happened:\n   Impact (users affected, data affected, regulatory obligations triggered):\n\n2. TIMELINE OF EVENTS\n   [Chronological sequence from first signal to resolution]\n\n3. CONTRIBUTING FACTORS\n   Technical factors:\n   Process/governance factors:\n   Human factors:\n   Vendor/third-party factors (if applicable):\n\n4. ROOT CAUSE STATEMENT\n   Primary root cause:\n   Secondary contributing causes:\n\n5. WHY THE INCIDENT WAS NOT PREVENTED\n   What detection or prevention mechanisms should have caught this earlier:\n   Why they did not:\n\n6. CORRECTIVE ACTIONS\n   | Action | Owner | Target Date | Status |\n   |--------|-------|-------------|--------|\n   |        |       |             |        |\n\n7. PREVENTIVE MEASURES\n   Changes to monitoring (L3-6.1):\n   Changes to change management (L3-6.3):\n   Changes to vendor contracts (L2-5.3):\n   Changes to system design or documentation:\n\n8. RESIDUAL RISK AFTER CORRECTIVE ACTION\n   Remaining risk:\n   Accepted by (AIRO / CEO):\n\n9. LESSONS LEARNED\n   What would have changed the outcome:\n   Actions to prevent recurrence across other systems:\n\n10. SIGN-OFF\n    Prepared by:           Date:\n    AIRO review:           Date:\n    DPO review (if applicable): Date:\n    CEO approval (P1):     Date:\n</code></pre>"},{"location":"stage-4-monitoring-controls/L3-6.2-Incident-Response-Playbook-v1/#8-client-notification-requirements","title":"8. Client Notification Requirements","text":""},{"location":"stage-4-monitoring-controls/L3-6.2-Incident-Response-Playbook-v1/#81-when-to-notify-clients","title":"8.1 When to Notify Clients","text":"<p>[ASSUMPTION] Pickles GmbH notifies lawyer clients in the following circumstances:</p> Situation Notification Trigger Timing P1 incident affecting client data or outputs Mandatory As soon as practical; before regulatory notification where possible P1 incident where client may have relied on affected outputs Mandatory Within 24 hours of classification System suspension under Article 20 Mandatory Immediately; before or concurrent with suspension GDPR personal data breach involving client data Mandatory (and client's own GDPR Article 33 clock may start) Without undue delay \u2014 client needs information to meet their own obligations as controller P2 quality incident with pattern affecting client's practice area Recommended Within 2 business days P3 SLA breach Per contractual SLA terms Per SLA"},{"location":"stage-4-monitoring-controls/L3-6.2-Incident-Response-Playbook-v1/#82-client-notification-content-p1","title":"8.2 Client Notification Content (P1)","text":"<p>A P1 client notification must include: - Description of the incident in plain language - Systems and outputs affected - Period during which affected outputs were produced - Whether client's data was involved (and what categories if so) - Actions Pickles GmbH has taken - Actions the client should take (e.g., review outputs from the affected period) - Contact point for further information (DPO for data-related; AIRO for AI-related)</p>"},{"location":"stage-4-monitoring-controls/L3-6.2-Incident-Response-Playbook-v1/#9-post-incident-review","title":"9. Post-Incident Review","text":"<p>Every P1 and P2 incident triggers a post-incident review within 30 days of resolution: - AIRO presents RCA findings to CEO and relevant heads - Monitoring thresholds reviewed for adequacy - Playbook updated if gaps identified - If Article 73 was triggered: review whether reporting was timely and complete - ISO/IEC 42001 Clause 10.2 corrective action documented</p>"},{"location":"stage-4-monitoring-controls/L3-6.2-Incident-Response-Playbook-v1/#document-control","title":"Document Control","text":"Field Detail Document ID L3-6.2 Next review Annual; immediately after any P1 incident Regulatory basis EU AI Act Articles 3(49), 20, 73, 79; GDPR Articles 33, 34; BDSG \u00a765, \u00a766 Cross-references L3-6.1 (triggers), L3-6.3 (change management post-incident), L2-5.3 (vendor breach) Assumptions relied upon A-001, A-003, A-008, A-009"},{"location":"stage-4-monitoring-controls/L3-6.3-Model-Change-Management-Protocol-v1/","title":"Model Change Management Protocol","text":"<p>Project: Pickles GmbH \u2014 AI Governance Framework Stage: Stage 4 \u2014 Monitoring &amp; Operational Controls Status: Draft Version: v1 Date: 2026-02-26 Assumptions: Built on outline assumptions \u2014 not verified against real Pickles GmbH data</p>"},{"location":"stage-4-monitoring-controls/L3-6.3-Model-Change-Management-Protocol-v1/#purpose","title":"Purpose","text":"<p>This protocol governs all changes to Pickles GmbH's AI systems \u2014 whether initiated internally (prompt redesign, retraining, architectural changes) or externally (third-party model provider updates). It ensures that:</p> <ul> <li>Changes are tested before production deployment</li> <li>Substantial modifications triggering new EU AI Act conformity assessments are identified before deployment</li> <li>Clients are notified of changes affecting system behaviour</li> <li>A rollback plan exists for every production change</li> <li>The Technical Documentation Pack (L2-4.2) stays current</li> </ul> <p>Regulatory basis: - EU AI Act Article 3(23) \u2014 definition of substantial modification - EU AI Act Article 43(4) \u2014 substantial modification triggers new conformity assessment - EU AI Act Article 17(1)(a) \u2014 QMS must include procedures for management of modifications - EU AI Act Article 9(2) \u2014 risk management system is an iterative process (changes require risk re-evaluation) - EU AI Act Article 6(4) \u2014 self-assessment must be updated if classification changes - ISO/IEC 42001 Clause 10 \u2014 continual improvement and corrective action</p> <p>[ASSUMPTION] The change governance roles and approval thresholds are based on the assumed organisational structure. They must be confirmed against real Pickles GmbH structure before operational use.</p>"},{"location":"stage-4-monitoring-controls/L3-6.3-Model-Change-Management-Protocol-v1/#1-change-classification-framework","title":"1. Change Classification Framework","text":"<p>Every proposed change must first be classified. Classification determines the approval path, testing requirements, and regulatory obligations.</p>"},{"location":"stage-4-monitoring-controls/L3-6.3-Model-Change-Management-Protocol-v1/#11-change-types","title":"1.1 Change Types","text":"Type Description Examples Type A \u2014 Prompt redesign Changes to system prompts, instruction sets, or retrieval query logic \u2014 no model weight changes Revised instruction wording; updated system prompt; modified retrieval parameters Type B \u2014 Configuration change Changes to system configuration, output formatting, safety filters, or operational parameters Adjusting output length limit; enabling/disabling a feature; changing safety filter threshold Type C \u2014 Third-party model update New version of a third-party model API deployed by the provider GPT-4o \u2192 GPT-4o-mini; Claude 3 \u2192 Claude 3.5; model version deprecation Type D \u2014 Fine-tuning / retraining Pickles GmbH fine-tunes, retrains, or trains a model on new data Domain fine-tuning on new legal corpus; RLHF update Type E \u2014 Architecture change Changes to system architecture, infrastructure, or integration patterns Switching from RAG to fine-tuning; replacing vector database; new API integration Type F \u2014 Provider switch Replacing the third-party AI model provider entirely Switching from Provider A to Provider B"},{"location":"stage-4-monitoring-controls/L3-6.3-Model-Change-Management-Protocol-v1/#12-substantial-modification-assessment","title":"1.2 Substantial Modification Assessment","text":"<p>EU AI Act Article 3(23) defines a substantial modification as a change that is: 1. Not foreseen or planned in the initial conformity assessment (see L2-4.2 Section 2.6 \u2014 pre-determined changes); AND 2. Affects compliance with Chapter III Section 2 requirements (Articles 9\u201315), OR modifies the intended purpose of the AI system</p> <p>Article 43(4): pre-determined changes documented in Annex IV technical documentation (L2-4.2 Section 2.6) do NOT constitute substantial modification.</p> <p>Substantial modification classification matrix:</p> Change Type Pre-determined? Affects Ch. III S.2 or intended purpose? Substantial Modification? Minor prompt wording adjustment within existing scope Yes (if documented) No No Prompt change that materially alters output type or scope No Yes (intended purpose affected) Yes Configuration change within pre-defined bounds Yes (if documented) No No Configuration change outside pre-defined bounds No Depends \u2014 assess Assess \u2014 likely Yes Third-party model version update (same capability class) Possible \u2014 if update policy documented May affect accuracy/robustness (Article 15) Assess Major model version change (new capability class) No Yes \u2014 accuracy, robustness, intended purpose Yes Fine-tuning on new domain data No May affect Article 10 data governance compliance Assess \u2014 likely Yes Architecture change affecting core processing No Yes Yes Provider switch No Yes \u2014 new system with different characteristics Yes <p>[LEGAL REVIEW REQUIRED] Substantial modification assessments for SYS-04 have conformity assessment implications. A qualified EU AI Act practitioner must confirm the assessment for any Type C, D, E, or F change before deployment.</p>"},{"location":"stage-4-monitoring-controls/L3-6.3-Model-Change-Management-Protocol-v1/#2-change-request-process","title":"2. Change Request Process","text":""},{"location":"stage-4-monitoring-controls/L3-6.3-Model-Change-Management-Protocol-v1/#21-initiation","title":"2.1 Initiation","text":"<p>Any change to a Pickles GmbH AI system must begin with a Change Request (CR). CRs may be raised by: - Head of Engineering (technical changes) - Head of Product (product changes) - AIRO (governance-driven changes) - Third-party model provider notification (Type C, F) \u2014 received per L2-5.3</p> <p>Change Request must document:</p> <pre><code>CHANGE REQUEST \u2014 [CR-ID: CR-YYYY-MM-DD-NN]\n\nSystem affected:\nChange type (A/B/C/D/E/F):\nDescription of proposed change:\nReason for change:\nPre-determined change? (Y/N \u2014 reference L2-4.2 Section 2.6 if yes):\nRaised by:\nDate raised:\n</code></pre>"},{"location":"stage-4-monitoring-controls/L3-6.3-Model-Change-Management-Protocol-v1/#22-initial-triage","title":"2.2 Initial Triage","text":"<p>The AIRO and Head of Engineering perform initial triage within 2 business days of CR receipt:</p> Triage Question If Yes Is this a pre-determined change (L2-4.2 Section 2.6)? Expedited path \u2014 confirm in writing; proceed to Testing (Step 4) Is this a Type C third-party update with vendor regression data? Use vendor data to supplement internal testing; proceed to Assessment Does the change affect the intended purpose of the system? Substantial modification assessment required Does the change affect SYS-04 (high-risk) accuracy, robustness, or data governance? Substantial modification assessment required; notify Legal"},{"location":"stage-4-monitoring-controls/L3-6.3-Model-Change-Management-Protocol-v1/#3-substantial-modification-assessment","title":"3. Substantial Modification Assessment","text":"<p>For any change not confirmed as pre-determined, complete the following assessment before testing:</p> <pre><code>SUBSTANTIAL MODIFICATION ASSESSMENT \u2014 [CR-ID]\n\n1. Does this change modify the intended purpose of the system?\n   (Intended purpose is defined in L2-4.2 Section 1.1 for each system)\n   Yes / No / Uncertain [LEGAL REVIEW REQUIRED if Uncertain]\n\n2. Does this change affect compliance with any of the following?\n   Article 9 (risk management system): Yes / No\n   Article 10 (data governance \u2014 if retraining): Yes / No\n   Article 12 (logging capabilities): Yes / No\n   Article 13 (transparency to deployers): Yes / No\n   Article 14 (human oversight mechanisms): Yes / No\n   Article 15 (accuracy, robustness, cybersecurity): Yes / No\n\n3. Was this change foreseen and documented in L2-4.2 Section 2.6?\n   Yes (reference: ___) / No\n\n4. CONCLUSION\n   Substantial modification: Yes / No / Requires legal review\n\n   If Yes: New conformity assessment required before deployment (Article 43(4))\n   Approved by (AIRO + Legal): ___        Date: ___\n</code></pre>"},{"location":"stage-4-monitoring-controls/L3-6.3-Model-Change-Management-Protocol-v1/#4-testing-protocol","title":"4. Testing Protocol","text":"<p>All changes \u2014 regardless of classification \u2014 undergo testing before production deployment. The depth of testing scales with change risk.</p>"},{"location":"stage-4-monitoring-controls/L3-6.3-Model-Change-Management-Protocol-v1/#41-testing-tiers","title":"4.1 Testing Tiers","text":"Testing Tier Applies To Minimum Requirements Tier 1 \u2014 Smoke test Type A minor prompt changes; Type B configuration within pre-defined bounds Run benchmark query suite (n=20); confirm output format and quality unchanged; no regressions on known failure modes Tier 2 \u2014 Standard regression Type A major prompt changes; Type B outside pre-defined bounds; Type C minor model updates Full benchmark query suite (n=100); citation accuracy check; latency check; human review of 10 sampled outputs by a qualified legal reviewer [ASSUMPTION] Tier 3 \u2014 Full regression Type C major model updates; Type D (fine-tuning); Type E (architecture); Type F (provider switch) Full benchmark query suite (n=200+); citation accuracy; bias check across document types; latency; safety filter validation; human review of 25+ outputs by qualified legal reviewer; AIRO sign-off before staging deployment Tier 4 \u2014 Full regression + third-party validation Substantial modifications requiring new conformity assessment All Tier 3 requirements + independent third-party accuracy assessment + new Annex IV technical documentation + conformity assessment before production deployment [LEGAL REVIEW REQUIRED]"},{"location":"stage-4-monitoring-controls/L3-6.3-Model-Change-Management-Protocol-v1/#42-benchmark-query-suite","title":"4.2 Benchmark Query Suite","text":"<p>[ASSUMPTION] The benchmark query suite is a curated set of test queries covering: - Standard legal research queries across Pickles GmbH's primary practice area coverage - Known edge cases and failure modes identified in previous incidents and monitoring - Citation-heavy queries (for accuracy testing) - Multilingual queries if system supports multiple languages - Queries designed to probe bias and differential performance</p> <p>The benchmark suite is maintained by the Head of Product and updated after every P1/P2 incident and every major model change. [ASSUMPTION]</p>"},{"location":"stage-4-monitoring-controls/L3-6.3-Model-Change-Management-Protocol-v1/#43-regression-testing-pass-criteria","title":"4.3 Regression Testing Pass Criteria","text":"<p>A change passes regression testing and may proceed to staging if:</p> Criterion Pass Standard Citation accuracy \u226595% on benchmark suite (no regression from previous baseline) Error rate \u22642% expert-identified errors in human review sample Latency P95 response time within 10% of previous baseline No new failure modes No failure modes not present in previous baseline Safety filter No outputs violating content safety requirements Bias check (Tier 3/4) No statistically significant performance degradation in any tested stratum"},{"location":"stage-4-monitoring-controls/L3-6.3-Model-Change-Management-Protocol-v1/#44-staging-deployment","title":"4.4 Staging Deployment","text":"<p>Before production deployment, all Tier 2+ changes must be deployed in a staging environment for a minimum period: - Tier 2: 2 business days - Tier 3: 5 business days - Tier 4: As required by conformity assessment timelines</p>"},{"location":"stage-4-monitoring-controls/L3-6.3-Model-Change-Management-Protocol-v1/#5-sign-off-authority","title":"5. Sign-Off Authority","text":"Change Tier Sign-Off Required Tier 1 Head of Engineering Tier 2 Head of Engineering + Head of Product Tier 3 Head of Engineering + Head of Product + AIRO Tier 4 (Substantial modification) AIRO + CEO + Legal (plus conformity assessment body if applicable) <p>No change to SYS-04 (high-risk) may be deployed to production without AIRO sign-off, regardless of tier.</p>"},{"location":"stage-4-monitoring-controls/L3-6.3-Model-Change-Management-Protocol-v1/#6-rollback-plan","title":"6. Rollback Plan","text":"<p>Every change deployed to production must have a documented rollback plan approved before deployment.</p>"},{"location":"stage-4-monitoring-controls/L3-6.3-Model-Change-Management-Protocol-v1/#61-rollback-requirement","title":"6.1 Rollback Requirement","text":"<pre><code>ROLLBACK PLAN \u2014 [CR-ID]\n\nPrevious version/configuration:\nRollback method (how to revert to previous state):\nRollback owner:\nMaximum rollback time (from decision to complete):\nRollback trigger conditions:\n  - Automatic (monitoring threshold breach): [specify]\n  - Manual (AIRO or Head of Engineering decision): [specify]\nData implications of rollback (any data created during new version that is affected):\nClient notification required on rollback? (Y/N):\n</code></pre>"},{"location":"stage-4-monitoring-controls/L3-6.3-Model-Change-Management-Protocol-v1/#62-rollback-decision-authority","title":"6.2 Rollback Decision Authority","text":"Situation Rollback Decision Authority Automated monitoring alert (L3-6.1) triggering rollback condition Head of Engineering \u2014 may initiate immediately P1 incident linked to recent change AIRO \u2014 may order immediate rollback P2 incident with probable link to recent change AIRO + Head of Engineering \u2014 joint decision Regulatory authority instruction (Article 79) CEO + Legal \u2014 mandatory compliance"},{"location":"stage-4-monitoring-controls/L3-6.3-Model-Change-Management-Protocol-v1/#63-post-rollback-actions","title":"6.3 Post-Rollback Actions","text":"<p>Following any rollback: 1. Incident log opened (minimum P2) 2. Root cause analysis initiated (L3-6.2 RCA template) 3. Technical documentation updated to record rolled-back change (L2-4.2 Section 6) 4. CR closed as failed; new CR required for revised approach</p>"},{"location":"stage-4-monitoring-controls/L3-6.3-Model-Change-Management-Protocol-v1/#7-specific-change-scenarios","title":"7. Specific Change Scenarios","text":""},{"location":"stage-4-monitoring-controls/L3-6.3-Model-Change-Management-Protocol-v1/#71-third-party-model-provider-update-type-c","title":"7.1 Third-Party Model Provider Update (Type C)","text":"<p>When a provider notifies Pickles GmbH of a model update per L2-5.3 Section 7:</p> Step Action Owner Timing 1 Log provider notification; open CR Head of Engineering Day 0 2 Review provider release notes; classify as minor or major update Head of Engineering + Head of Product Day 1\u20132 3 Assign testing tier (Tier 2 for minor; Tier 3 for major) AIRO Day 2 4 Run regression testing in isolated environment Head of Engineering Per tier requirements 5 Substantial modification assessment AIRO + Legal During testing 6 Staging deployment and monitoring Head of Engineering Post-testing 7 Sign-off and production deployment Per Section 5 After staging 8 Update L2-4.2 Section 6 (lifecycle change log) Head of Engineering At deployment 9 Client notification if behaviour materially changes Head of Product Before or at deployment"},{"location":"stage-4-monitoring-controls/L3-6.3-Model-Change-Management-Protocol-v1/#72-prompt-redesign-type-a","title":"7.2 Prompt Redesign (Type A)","text":"<p>Minor prompt changes may follow an expedited path if they are documented as pre-determined in L2-4.2 Section 2.6. All others follow the standard CR process with Tier 1 or Tier 2 testing.</p>"},{"location":"stage-4-monitoring-controls/L3-6.3-Model-Change-Management-Protocol-v1/#73-provider-switch-type-f","title":"7.3 Provider Switch (Type F)","text":"<p>A complete provider switch is always a substantial modification requiring Tier 4 testing and new conformity assessment for SYS-04. Additionally: - New DPA must be executed with the new provider (L2-5.3) - \u00a743e BRAO service agreement required - SCCs assessed if new provider is non-EEA - Client notification required before switch</p>"},{"location":"stage-4-monitoring-controls/L3-6.3-Model-Change-Management-Protocol-v1/#74-retraining-fine-tuning-type-d","title":"7.4 Retraining / Fine-Tuning (Type D)","text":"<p>Any retraining or fine-tuning on new data requires: - Data governance review under EU AI Act Article 10 (training data quality, bias examination) - L2-4.2 Section 2.4 (training data) updated - Bias assessment (M-05) run on new model before production - Tier 3 or Tier 4 testing depending on scope</p>"},{"location":"stage-4-monitoring-controls/L3-6.3-Model-Change-Management-Protocol-v1/#8-documentation-updates-required-after-any-change","title":"8. Documentation Updates Required After Any Change","text":"Document Section to Update Trigger L2-4.2 Technical Documentation Pack Section 6 \u2014 lifecycle changes Every production change L2-4.2 Technical Documentation Pack Section 2.1 \u2014 development methods; Section 2.4 \u2014 training data Type D, F changes L2-4.2 Technical Documentation Pack Section 2.6 \u2014 pre-determined changes If new change type should be pre-determined in future L3-6.1 AI Monitoring Framework Benchmark baselines After every Tier 3+ change ASSUMPTIONS-LOG.md Update relevant assumptions if architecture confirmed If change reveals or confirms assumptions"},{"location":"stage-4-monitoring-controls/L3-6.3-Model-Change-Management-Protocol-v1/#9-change-log","title":"9. Change Log","text":"CR-ID Date Type System Description Tier Substantial? Outcome \u2014 \u2014 \u2014 \u2014 No changes recorded yet \u2014 \u2014 \u2014"},{"location":"stage-4-monitoring-controls/L3-6.3-Model-Change-Management-Protocol-v1/#document-control","title":"Document Control","text":"Field Detail Document ID L3-6.3 Next review Annual; after any Tier 4 change; after any P1 incident linked to a change Regulatory basis EU AI Act Articles 3(23), 6(4), 9, 17(1)(a), 43(4); ISO/IEC 42001 Clause 10 Cross-references L2-4.2 (technical documentation), L2-5.3 (vendor update notifications), L3-6.1 (monitoring drift), L3-6.2 (incident response post-change) Assumptions relied upon A-001, A-004, A-009"},{"location":"stage-5-commercial-packaging/L4-7.1-AI-Governance-Information-Pack-v1/","title":"AI Governance Information Pack","text":"<p>Project: Pickles GmbH \u2014 AI Governance Framework Stage: Stage 5 \u2014 Commercial Packaging Status: Draft Version: v1 Date: 2026-02-26 Assumptions: Built on outline assumptions \u2014 not verified against real Pickles GmbH data  </p>"},{"location":"stage-5-commercial-packaging/L4-7.1-AI-Governance-Information-Pack-v1/#1-executive-summary","title":"1. Executive Summary","text":"<p>Pickles GmbH [ASSUMPTION] is a German legal technology provider offering AI-powered tools designed to support qualified legal professionals in research, drafting, summarisation, and structured legal analysis. Its systems are designed as assistive tools for lawyers and in-house legal teams \u2014 not as autonomous legal decision-makers.</p> <p>AI governance is central to the trustworthiness of legal AI. Under Regulation (EU) 2024/1689 (EU AI Act), Regulation (EU) 2016/679 (GDPR), the German Federal Data Protection Act (BDSG), and professional rules applicable to German lawyers (BRAO/BRAK), AI systems used in legal contexts must be carefully controlled, documented, and subject to meaningful human oversight. In addition, GDPR Article 5 requires accountability and demonstrable compliance with data protection principles.</p> <p>This Information Pack summarises Pickles GmbH\u2019s AI governance architecture as implemented through its multi-stage AI Governance Framework (Stages 1\u20134). It explains how systems are classified, documented, monitored, and reviewed, and how regulatory obligations \u2014 including EU AI Act Articles 9, 11, 13, 14, 31, 72; GDPR Articles 5, 22, 28, 32, 33, 35; and relevant BRAO/BRAK provisions \u2014 are operationalised.</p> <p>This document is intended for non-technical legal procurement teams evaluating Pickles GmbH as a vendor. It provides a structured overview of compliance posture, risk management, transparency measures, and professional safeguards.</p>"},{"location":"stage-5-commercial-packaging/L4-7.1-AI-Governance-Information-Pack-v1/#2-ai-architecture-overview","title":"2. AI Architecture Overview","text":""},{"location":"stage-5-commercial-packaging/L4-7.1-AI-Governance-Information-Pack-v1/#21-assumed-product-portfolio","title":"2.1 Assumed Product Portfolio","text":"<p>[ASSUMPTION] Based on the AI System Inventory (L1-3.1) and EU AI Act Risk Mapping Matrix (L2-4.1), Pickles GmbH operates the following AI system categories:</p> <ul> <li> <p>Legal Research Assistant (SYS-01)   AI-supported retrieval and summarisation of case law and legislation.</p> </li> <li> <p>Document Drafting Tool (SYS-02)   AI-assisted drafting and auto-completion of contracts and legal documents.</p> </li> <li> <p>Document Summarisation Tool (SYS-03)   AI summarisation of lengthy legal documents and judgments.</p> </li> <li> <p>Legal Analysis Tool (SYS-04)   AI-supported structured legal analysis applied to specific fact patterns.</p> </li> </ul> <p>These descriptions are provisional and must be verified against the actual production architecture. [LEGAL REVIEW REQUIRED]</p>"},{"location":"stage-5-commercial-packaging/L4-7.1-AI-Governance-Information-Pack-v1/#22-architectural-principles","title":"2.2 Architectural Principles","text":"<p>Across all systems, the following architectural principles apply:</p> <ol> <li> <p>Registration Before Deployment    No AI system may be deployed without prior registration in the AI System Inventory (EU AI Act Article 11; L1-3.1).</p> </li> <li> <p>Gate-Based Intake Process    All systems must pass a six-gate approval workflow before production deployment (L1-3.3).</p> </li> <li> <p>Defined Intended Purpose    Each system\u2019s intended purpose is documented in technical documentation in line with Annex IV and Article 13(3)(b)(i) EU AI Act (L2-4.2).</p> </li> <li> <p>Human-in-the-Loop Design    System outputs cannot bypass mandatory lawyer review prior to client-facing use (EU AI Act Article 14; GDPR Article 22; L1-3.4).</p> </li> </ol>"},{"location":"stage-5-commercial-packaging/L4-7.1-AI-Governance-Information-Pack-v1/#3-eu-ai-act-compliance","title":"3. EU AI Act Compliance","text":""},{"location":"stage-5-commercial-packaging/L4-7.1-AI-Governance-Information-Pack-v1/#31-risk-classification-approach","title":"3.1 Risk Classification Approach","text":"<p>Pickles GmbH applies a structured Risk Classification Framework (L1-3.2) aligned to:</p> <ul> <li>EU AI Act Article 6 (High-risk classification)</li> <li>Annex III (High-risk categories)</li> <li>Recitals 53 and 61 (legal AI interpretation)</li> </ul> <p>Under Annex III Point 8(a), AI systems used by judicial authorities to apply law to concrete facts are classified as high-risk. [ASSUMPTION] Pickles GmbH sells to lawyers rather than judicial authorities; however, classification boundaries require legal review. [LEGAL REVIEW REQUIRED]</p> <p>Where a system is determined to be high-risk:</p> <ul> <li>Article 9 \u2014 A continuous risk management system is implemented.</li> <li>Article 11 &amp; Annex IV \u2014 Full technical documentation is maintained.</li> <li>Article 13 \u2014 Instructions for use and transparency documentation are provided.</li> <li>Article 14 \u2014 Effective human oversight is designed into the system.</li> <li>Article 72 \u2014 Post-market monitoring is mandatory.</li> <li>Article 73 \u2014 Serious incidents must be reported.</li> </ul>"},{"location":"stage-5-commercial-packaging/L4-7.1-AI-Governance-Information-Pack-v1/#32-technical-documentation","title":"3.2 Technical Documentation","text":"<p>For each system, Pickles GmbH prepares documentation structured to Annex IV requirements (L2-4.2), including:</p> <ul> <li>Intended purpose</li> <li>System architecture overview</li> <li>Training and validation approach [ASSUMPTION]</li> <li>Known limitations and accuracy constraints</li> <li>Human oversight mechanisms</li> <li>Logging and monitoring design (Article 12)</li> </ul> <p>Documentation is version-controlled and updated upon substantial modification (Article 3(23); Article 43(4)).</p>"},{"location":"stage-5-commercial-packaging/L4-7.1-AI-Governance-Information-Pack-v1/#33-transparency-measures","title":"3.3 Transparency Measures","text":"<p>Transparency is addressed at three levels (L2-4.3):</p> <ul> <li>System-Level Transparency (Article 13) \u2014 Deployer-facing instructions.</li> <li>User-Level Transparency (Article 50) \u2014 Disclosure when interacting with AI; labelling of AI-generated content (effective 2 August 2026).</li> <li>Professional Transparency \u2014 Alignment with BRAK Position Paper obligations.</li> </ul>"},{"location":"stage-5-commercial-packaging/L4-7.1-AI-Governance-Information-Pack-v1/#4-human-oversight-model","title":"4. Human Oversight Model","text":"<p>Human oversight is governed by the Human Oversight Policy (L1-3.4).</p>"},{"location":"stage-5-commercial-packaging/L4-7.1-AI-Governance-Information-Pack-v1/#41-core-principle","title":"4.1 Core Principle","text":"<p>No AI output may constitute final legal advice without review and authorisation by a qualified lawyer.</p> <p>This principle reflects:</p> <ul> <li>EU AI Act Article 14 (Human oversight)</li> <li>GDPR Article 22 (No solely automated decisions with legal effects)</li> <li>BRAO \u00a743a(2) (Independent professional judgement)</li> </ul>"},{"location":"stage-5-commercial-packaging/L4-7.1-AI-Governance-Information-Pack-v1/#42-prohibited-practices","title":"4.2 Prohibited Practices","text":"<p>Prohibited practices include:</p> <ul> <li>Direct delivery of AI-generated advice to clients without review.</li> <li>Designing workflows that bypass human review.</li> <li>Representing AI output as independent legal advice.</li> </ul> <p>[LEGAL REVIEW REQUIRED] The exact application of GDPR Article 22 in AI-assisted legal workflows must be assessed in context.</p>"},{"location":"stage-5-commercial-packaging/L4-7.1-AI-Governance-Information-Pack-v1/#5-data-protection-summary","title":"5. Data Protection Summary","text":""},{"location":"stage-5-commercial-packaging/L4-7.1-AI-Governance-Information-Pack-v1/#51-controller-processor-model","title":"5.1 Controller / Processor Model","text":"<p>Based on the Data Flow Map (L2-5.1):</p> <ul> <li>Pickles GmbH acts as data controller for employee and account data. [ASSUMPTION]</li> <li>Pickles GmbH acts as data processor for client-submitted legal documents. [ASSUMPTION]</li> <li>Third-party model providers may act as sub-processors (GDPR Article 28(2)). [ASSUMPTION]</li> </ul> <p>[LEGAL REVIEW REQUIRED] Role allocation must be verified per GDPR Article 4(7)\u2013(8).</p>"},{"location":"stage-5-commercial-packaging/L4-7.1-AI-Governance-Information-Pack-v1/#52-lawful-basis","title":"5.2 Lawful Basis","text":"<p>Lawyer clients, as controllers, determine lawful basis under GDPR Article 6. Where special categories of data (Article 9) are processed, additional conditions apply.</p>"},{"location":"stage-5-commercial-packaging/L4-7.1-AI-Governance-Information-Pack-v1/#53-dpia-status","title":"5.3 DPIA Status","text":"<p>The DPIA Assessment (L2-5.2) confirms:</p> <ul> <li>High-risk systems require DPIA consideration (GDPR Article 35).</li> <li>SYS-04 is treated as requiring full DPIA. [ASSUMPTION]</li> </ul>"},{"location":"stage-5-commercial-packaging/L4-7.1-AI-Governance-Information-Pack-v1/#54-security-measures","title":"5.4 Security Measures","text":"<p>Security controls are implemented in line with GDPR Article 32 and BDSG \u00a764, including:</p> <ul> <li>Encryption in transit (TLS 1.3+) [ASSUMPTION]</li> <li>Access controls and role-based permissions [ASSUMPTION]</li> <li>Sub-processor due diligence (L2-5.3)</li> </ul>"},{"location":"stage-5-commercial-packaging/L4-7.1-AI-Governance-Information-Pack-v1/#6-monitoring-quality-assurance","title":"6. Monitoring &amp; Quality Assurance","text":"<p>Monitoring is governed by the AI Monitoring Framework (L3-6.1).</p>"},{"location":"stage-5-commercial-packaging/L4-7.1-AI-Governance-Information-Pack-v1/#61-key-metrics","title":"6.1 Key Metrics","text":"<p>Monitored metrics include:</p> <ul> <li>Hallucination / factual error rate</li> <li>Citation integrity</li> <li>User-reported accuracy concerns</li> <li>Incident frequency</li> <li>Model drift indicators</li> </ul> <p>For high-risk systems, Article 72 requires structured post-market monitoring.</p>"},{"location":"stage-5-commercial-packaging/L4-7.1-AI-Governance-Information-Pack-v1/#62-incident-handling","title":"6.2 Incident Handling","text":"<p>The Incident Response Playbook (L3-6.2) defines:</p> <ul> <li>Severity levels (P1\u2013P4)</li> <li>GDPR Article 33/34 breach notification timelines</li> <li>EU AI Act Article 73 serious incident reporting</li> </ul>"},{"location":"stage-5-commercial-packaging/L4-7.1-AI-Governance-Information-Pack-v1/#63-change-management","title":"6.3 Change Management","text":"<p>The Model Change Management Protocol (L3-6.3) governs:</p> <ul> <li>Change classification (Types A\u2013F)</li> <li>Substantial modification assessment (Article 3(23))</li> <li>Conformity reassessment triggers (Article 43(4))</li> </ul>"},{"location":"stage-5-commercial-packaging/L4-7.1-AI-Governance-Information-Pack-v1/#7-professional-standards","title":"7. Professional Standards","text":"<p>Pickles GmbH aligns its governance architecture with:</p> <ul> <li>BRAO \u00a743a(2) \u2014 Independent legal judgement</li> <li>BRAO \u00a743e \u2014 IT outsourcing safeguards</li> <li>BRAK AI Position Paper (December 2024)</li> </ul> <p>Where third-party providers are used, confidentiality obligations consistent with \u00a743e BRAO are required (L2-5.3).</p>"},{"location":"stage-5-commercial-packaging/L4-7.1-AI-Governance-Information-Pack-v1/#8-contact-further-information","title":"8. Contact &amp; Further Information","text":"<p>Pickles GmbH [ASSUMPTION] Registered Address: [Placeholder] Email: compliance@pickles.example [ASSUMPTION] Data Protection Officer: dpo@pickles.example [ASSUMPTION]  </p> <p>Further documentation (under NDA where appropriate) may include:</p> <ul> <li>Technical Documentation Packs (Annex IV format)</li> <li>DPIA summaries</li> <li>Sub-processor list</li> <li>Monitoring dashboard extracts</li> <li>Incident management summaries</li> </ul> <p>End of Document 1</p>"},{"location":"stage-5-commercial-packaging/L4-7.2-Enterprise-Sales-Enablement-Kit-v1/","title":"Enterprise Sales Enablement Kit","text":"<p>Project: Pickles GmbH \u2014 AI Governance Framework Stage: Stage 5 \u2014 Commercial Packaging Status: Draft Version: v1 Date: 2026-02-26 Assumptions: Built on outline assumptions \u2014 not verified against real Pickles GmbH data  </p>"},{"location":"stage-5-commercial-packaging/L4-7.2-Enterprise-Sales-Enablement-Kit-v1/#1-how-to-use-this-document","title":"1. How to Use This Document","text":"<p>This document provides pre-drafted responses to common enterprise procurement, security, and regulatory questionnaires. Each answer references underlying governance framework documents and relevant regulatory provisions.</p> <p>Sales teams should:</p> <ol> <li>Adapt language only where necessary for client context.</li> <li>Avoid altering regulatory citations.</li> <li>Escalate unusual or high-risk requests to Legal or the AI Risk and Information Officer. [ASSUMPTION]</li> <li>Flag any question implying judicial authority use for legal review. [LEGAL REVIEW REQUIRED]</li> </ol>"},{"location":"stage-5-commercial-packaging/L4-7.2-Enterprise-Sales-Enablement-Kit-v1/#2-security-questionnaire-responses","title":"2. Security Questionnaire Responses","text":""},{"location":"stage-5-commercial-packaging/L4-7.2-Enterprise-Sales-Enablement-Kit-v1/#q-how-is-data-encrypted-in-transit-and-at-rest","title":"Q: How is data encrypted in transit and at rest?","text":"<p>A: All client communications are encrypted in transit using modern TLS protocols (minimum TLS 1.3) [ASSUMPTION]. Data at rest within hosting infrastructure is encrypted using industry-standard encryption mechanisms. These measures align with GDPR Article 32(1)(a), which requires appropriate technical and organisational measures to ensure confidentiality and integrity. Source: L2-5.1 Data Flow Map</p>"},{"location":"stage-5-commercial-packaging/L4-7.2-Enterprise-Sales-Enablement-Kit-v1/#q-do-you-use-third-party-sub-processors","title":"Q: Do you use third-party sub-processors?","text":"<p>A: Yes, where required for hosting or AI model inference [ASSUMPTION]. All sub-processors are assessed under GDPR Article 28(2) and must enter into written agreements consistent with Article 28(3). Where international transfers occur, appropriate safeguards under Articles 44 and 46 are required. Source: L2-5.3 Vendor Model Risk Assessment</p>"},{"location":"stage-5-commercial-packaging/L4-7.2-Enterprise-Sales-Enablement-Kit-v1/#q-how-do-you-manage-ai-model-provider-risk","title":"Q: How do you manage AI model provider risk?","text":"<p>A: Third-party model providers must execute GDPR Article 28-compliant DPAs and confidentiality agreements consistent with \u00a743e BRAO. EU AI Act Article 25(4) requires written agreements across the AI value chain for high-risk systems. Source: L2-5.3</p>"},{"location":"stage-5-commercial-packaging/L4-7.2-Enterprise-Sales-Enablement-Kit-v1/#q-do-you-log-system-activity","title":"Q: Do you log system activity?","text":"<p>A: Yes. High-risk systems implement automatic event logging in accordance with EU AI Act Article 12. Logging supports traceability, monitoring (Article 72), and incident response. Source: L3-6.1</p>"},{"location":"stage-5-commercial-packaging/L4-7.2-Enterprise-Sales-Enablement-Kit-v1/#q-what-is-your-incident-response-timeline","title":"Q: What is your incident response timeline?","text":"<p>A: Personal data breaches are assessed under GDPR Article 33, requiring supervisory authority notification within 72 hours where applicable. Serious incidents under EU AI Act Article 73 must be reported without undue delay. Source: L3-6.2</p>"},{"location":"stage-5-commercial-packaging/L4-7.2-Enterprise-Sales-Enablement-Kit-v1/#q-how-do-you-prevent-unauthorised-automated-decisions","title":"Q: How do you prevent unauthorised automated decisions?","text":"<p>A: Systems are designed to require human lawyer review before any AI-generated output may form final legal advice. This addresses GDPR Article 22(1) and EU AI Act Article 14 human oversight requirements. Source: L1-3.4</p>"},{"location":"stage-5-commercial-packaging/L4-7.2-Enterprise-Sales-Enablement-Kit-v1/#q-is-there-a-formal-change-management-process","title":"Q: Is there a formal change management process?","text":"<p>A: Yes. All changes are classified under a structured protocol. Substantial modifications (EU AI Act Article 3(23)) trigger reassessment and, where required, new conformity assessment under Article 43(4). Source: L3-6.3</p>"},{"location":"stage-5-commercial-packaging/L4-7.2-Enterprise-Sales-Enablement-Kit-v1/#q-how-do-you-monitor-model-performance","title":"Q: How do you monitor model performance?","text":"<p>A: Performance metrics such as hallucination rate, error patterns, and user-reported concerns are monitored continuously. For high-risk systems, post-market monitoring is mandatory under Article 72. Source: L3-6.1</p>"},{"location":"stage-5-commercial-packaging/L4-7.2-Enterprise-Sales-Enablement-Kit-v1/#3-eu-ai-act-compliance-responses","title":"3. EU AI Act Compliance Responses","text":""},{"location":"stage-5-commercial-packaging/L4-7.2-Enterprise-Sales-Enablement-Kit-v1/#q-how-do-you-determine-ai-system-risk-classification","title":"Q: How do you determine AI system risk classification?","text":"<p>A: Risk classification follows EU AI Act Article 6 and Annex III, interpreted through a structured internal framework. Legal AI use cases referencing Recital 61 are reviewed for potential high-risk status. Source: L1-3.2</p>"},{"location":"stage-5-commercial-packaging/L4-7.2-Enterprise-Sales-Enablement-Kit-v1/#q-do-your-systems-require-ce-marking","title":"Q: Do your systems require CE marking?","text":"<p>A: Only AI systems classified as high-risk under Article 6 and Annex III require conformity assessment and CE marking (Articles 16\u201323). Current classification assumptions must be legally verified. [LEGAL REVIEW REQUIRED] Source: L2-4.1</p>"},{"location":"stage-5-commercial-packaging/L4-7.2-Enterprise-Sales-Enablement-Kit-v1/#q-how-do-you-meet-transparency-obligations","title":"Q: How do you meet transparency obligations?","text":"<p>A: Transparency obligations are implemented in line with Article 13 (deployer instructions) and Article 50 (AI interaction disclosure and synthetic content labelling, effective 2 August 2026). Source: L2-4.3</p>"},{"location":"stage-5-commercial-packaging/L4-7.2-Enterprise-Sales-Enablement-Kit-v1/#q-is-there-a-formal-risk-management-system","title":"Q: Is there a formal risk management system?","text":"<p>A: Yes. High-risk systems implement a lifecycle risk management system consistent with Article 9, including identification, mitigation, and continuous monitoring. Source: L3-6.1</p>"},{"location":"stage-5-commercial-packaging/L4-7.2-Enterprise-Sales-Enablement-Kit-v1/#q-how-are-substantial-modifications-managed","title":"Q: How are substantial modifications managed?","text":"<p>A: Substantial modifications are identified under Article 3(23). Where compliance with Articles 9\u201315 may be affected, Article 43(4) requires reassessment prior to deployment. Source: L3-6.3</p>"},{"location":"stage-5-commercial-packaging/L4-7.2-Enterprise-Sales-Enablement-Kit-v1/#q-what-logging-obligations-apply-to-your-systems","title":"Q: What logging obligations apply to your systems?","text":"<p>A: High-risk AI systems implement automatic logging under EU AI Act Article 12. Logs record operational events including timestamps, model version, and error conditions, supporting post-market monitoring under Article 72 and incident traceability. Source: L3-6.1 AI Monitoring Framework</p>"},{"location":"stage-5-commercial-packaging/L4-7.2-Enterprise-Sales-Enablement-Kit-v1/#q-are-your-systems-subject-to-the-eu-ai-act-prohibited-practices-list","title":"Q: Are your systems subject to the EU AI Act prohibited practices list?","text":"<p>A: EU AI Act Article 5 prohibits specific AI practices including subliminal manipulation, exploitation of vulnerabilities, social scoring by public authorities, and real-time remote biometric identification in public spaces. No Pickles GmbH system is designed for any prohibited purpose. All new systems are assessed against Article 5 at intake (L1-3.3). Source: L1-3.2 Risk Classification Framework</p>"},{"location":"stage-5-commercial-packaging/L4-7.2-Enterprise-Sales-Enablement-Kit-v1/#q-what-obligations-apply-across-the-ai-supply-chain","title":"Q: What obligations apply across the AI supply chain?","text":"<p>A: EU AI Act Article 25 sets out responsibilities where multiple parties contribute to an AI system. [ASSUMPTION] Pickles GmbH agreements with third-party model providers include written provisions addressing Article 25(4) requirements for high-risk systems, including allocation of compliance obligations and documentation access rights. Source: L2-5.3 Vendor Model Risk Assessment</p>"},{"location":"stage-5-commercial-packaging/L4-7.2-Enterprise-Sales-Enablement-Kit-v1/#4-data-handling-responses","title":"4. Data Handling Responses","text":""},{"location":"stage-5-commercial-packaging/L4-7.2-Enterprise-Sales-Enablement-Kit-v1/#q-what-is-your-role-under-gdpr","title":"Q: What is your role under GDPR?","text":"<p>A: [ASSUMPTION] Pickles GmbH acts as processor for client-submitted legal documents (Article 4(8)) and controller for its own account data (Article 4(7)). Final allocation requires contract verification. [LEGAL REVIEW REQUIRED] Source: L2-5.1</p>"},{"location":"stage-5-commercial-packaging/L4-7.2-Enterprise-Sales-Enablement-Kit-v1/#q-do-you-conduct-dpias","title":"Q: Do you conduct DPIAs?","text":"<p>A: Yes. DPIA screening is performed under Article 35. High-risk systems require full DPIA assessment. Source: L2-5.2</p>"},{"location":"stage-5-commercial-packaging/L4-7.2-Enterprise-Sales-Enablement-Kit-v1/#q-how-do-you-handle-international-transfers","title":"Q: How do you handle international transfers?","text":"<p>A: Transfers outside the EEA require safeguards under Articles 44 and 46 GDPR, including Standard Contractual Clauses where applicable. Source: L2-5.3</p>"},{"location":"stage-5-commercial-packaging/L4-7.2-Enterprise-Sales-Enablement-Kit-v1/#q-what-are-your-retention-policies","title":"Q: What are your retention policies?","text":"<p>A: Retention is governed by purpose limitation and storage limitation principles under GDPR Article 5(1)(b)\u2013(e). Specific periods are documented in the Data Flow Map. [ASSUMPTION] Source: L2-5.1</p>"},{"location":"stage-5-commercial-packaging/L4-7.2-Enterprise-Sales-Enablement-Kit-v1/#q-how-do-you-notify-clients-of-a-personal-data-breach","title":"Q: How do you notify clients of a personal data breach?","text":"<p>A: As data processor, Pickles GmbH notifies the controller without undue delay upon becoming aware of a personal data breach, consistent with GDPR Article 33(2). [ASSUMPTION] Notification includes sufficient detail for the controller to meet its Article 33 and Article 34 obligations. Timelines and procedures are set out in the Incident Response Playbook. Source: L3-6.2 Incident Response Playbook</p>"},{"location":"stage-5-commercial-packaging/L4-7.2-Enterprise-Sales-Enablement-Kit-v1/#q-how-do-you-handle-data-subject-rights-requests","title":"Q: How do you handle data subject rights requests?","text":"<p>A: Pickles GmbH assists the controller in responding to data subject rights under GDPR Articles 15-22, consistent with the processor obligation at Article 28(3)(e). [ASSUMPTION] Rights addressed include access, rectification, erasure, restriction, and portability. Procedures and response timelines are set out in the DPA. Source: L2-5.1 Data Flow Map</p>"},{"location":"stage-5-commercial-packaging/L4-7.2-Enterprise-Sales-Enablement-Kit-v1/#q-do-you-use-client-data-to-train-ai-models","title":"Q: Do you use client data to train AI models?","text":"<p>A: [ASSUMPTION] Pickles GmbH does not use client-submitted documents or query data for model training, fine-tuning, or model development. This prohibition is a required contractual control documented in the DPA and vendor model agreements. Each model provider must contractually confirm this restriction. [LEGAL REVIEW REQUIRED] Source: L2-5.2 DPIA Assessment; L2-5.3 Vendor Model Risk Assessment</p>"},{"location":"stage-5-commercial-packaging/L4-7.2-Enterprise-Sales-Enablement-Kit-v1/#q-have-you-designated-a-data-protection-officer","title":"Q: Have you designated a Data Protection Officer?","text":"<p>A: [ASSUMPTION] Pickles GmbH has designated a Data Protection Officer under BDSG Section 38, given the nature and scale of its personal data processing activities. DPO contact details are included in client DPAs. The DPO designation threshold must be confirmed against actual staffing and processing scope. [LEGAL REVIEW REQUIRED] Source: L2-5.2 DPIA Assessment</p>"},{"location":"stage-5-commercial-packaging/L4-7.2-Enterprise-Sales-Enablement-Kit-v1/#q-what-safeguards-apply-to-international-data-transfers","title":"Q: What safeguards apply to international data transfers?","text":"<p>A: Where sub-processors or AI model providers are located outside the EEA, data transfers are governed by GDPR Articles 44 and 46. [ASSUMPTION] Standard Contractual Clauses (2021 Commission Decision) are used where applicable, supplemented by transfer impact assessments for each sub-processor. [LEGAL REVIEW REQUIRED] Source: L2-5.3 Vendor Model Risk Assessment</p>"},{"location":"stage-5-commercial-packaging/L4-7.2-Enterprise-Sales-Enablement-Kit-v1/#5-professional-liability-responses","title":"5. Professional Liability Responses","text":""},{"location":"stage-5-commercial-packaging/L4-7.2-Enterprise-Sales-Enablement-Kit-v1/#q-does-your-system-replace-lawyer-judgement","title":"Q: Does your system replace lawyer judgement?","text":"<p>A: No. Under BRAO \u00a743a(1) and EU AI Act Article 14, AI systems are assistive tools. Final responsibility remains with the qualified lawyer. Source: L1-3.4</p>"},{"location":"stage-5-commercial-packaging/L4-7.2-Enterprise-Sales-Enablement-Kit-v1/#q-how-do-you-protect-attorney-client-confidentiality","title":"Q: How do you protect attorney-client confidentiality?","text":"<p>A: Vendor selection includes \u00a743e BRAO-compliant confidentiality obligations and strict purpose limitation clauses. Source: L2-5.3</p>"},{"location":"stage-5-commercial-packaging/L4-7.2-Enterprise-Sales-Enablement-Kit-v1/#q-who-is-responsible-for-ai-output","title":"Q: Who is responsible for AI output?","text":"<p>A: AI outputs are advisory tools; responsibility for client-facing advice rests with the instructing lawyer. System documentation clarifies intended purpose per Article 13(3)(b)(i). Source: L2-4.2</p>"},{"location":"stage-5-commercial-packaging/L4-7.2-Enterprise-Sales-Enablement-Kit-v1/#q-do-you-carry-professional-indemnity-insurance","title":"Q: Do you carry professional indemnity insurance?","text":"<p>A: [ASSUMPTION] Pickles GmbH maintains professional indemnity insurance appropriate for a legal technology provider. Specific coverage details and policy limits are available on request under NDA. Procurement teams should conduct their own assessment of whether coverage is adequate for their specific deployment context. [LEGAL REVIEW REQUIRED] Source: Commercial arrangements [ASSUMPTION]</p>"},{"location":"stage-5-commercial-packaging/L4-7.2-Enterprise-Sales-Enablement-Kit-v1/#q-what-are-the-limits-of-pickles-gmbh-contractual-liability","title":"Q: What are the limits of Pickles GmbH contractual liability?","text":"<p>A: [ASSUMPTION] Contractual liability is subject to limitations set out in the master services agreement. Because Pickles GmbH systems are assistive tools, clients bear professional responsibility for advice provided to their own clients. Contractual limitation clauses should be reviewed by legal counsel before contract execution. [LEGAL REVIEW REQUIRED] Source: Commercial terms [ASSUMPTION]</p>"},{"location":"stage-5-commercial-packaging/L4-7.2-Enterprise-Sales-Enablement-Kit-v1/#q-what-happens-if-a-client-suffers-loss-due-to-an-ai-error","title":"Q: What happens if a client suffers loss due to an AI error?","text":"<p>A: Responsibility for legal advice given to end clients rests with the qualified lawyer. Where an AI system error contributes to a client loss, the allocation of liability between Pickles GmbH contractual liability and the lawyer professional liability must be assessed case by case against applicable contract terms and professional rules. [LEGAL REVIEW REQUIRED] [ASSUMPTION] Source: L1-3.4 Human Oversight Policy; Commercial terms [ASSUMPTION]</p>"},{"location":"stage-5-commercial-packaging/L4-7.2-Enterprise-Sales-Enablement-Kit-v1/#q-how-are-accuracy-complaints-handled","title":"Q: How are accuracy complaints handled?","text":"<p>A: [ASSUMPTION] Clients may raise accuracy concerns or formal complaints through the Pickles GmbH incident reporting channel. All complaints are logged, investigated under the Incident Response Playbook (L3-6.2), and responded to within defined SLA timelines. Unresolved complaints may be escalated to the AI Risk and Information Officer (AIRO). Source: L3-6.2 Incident Response Playbook</p>"},{"location":"stage-5-commercial-packaging/L4-7.2-Enterprise-Sales-Enablement-Kit-v1/#6-appendix-document-cross-references","title":"6. Appendix: Document Cross-References","text":"Topic Framework Document AI System Registration L1-3.1 Risk Classification L1-3.2 Intake Workflow L1-3.3 Human Oversight L1-3.4 EU AI Act Mapping L2-4.1 Technical Documentation L2-4.2 Transparency Framework L2-4.3 Data Flow &amp; Roles L2-5.1 DPIA L2-5.2 Vendor Risk L2-5.3 Monitoring L3-6.1 Incident Response L3-6.2 Change Management L3-6.3 <p>End of Document 2</p>"}]}